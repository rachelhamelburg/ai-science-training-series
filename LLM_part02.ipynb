{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachelhamelburg/ai-science-training-series/blob/main/LLM_part02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1tOS7oWba4s"
      },
      "source": [
        "# Large language models (LLMs): Part II\n",
        "\n",
        "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
        "\n",
        "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
        "\n",
        "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86chC5sREiHd"
      },
      "source": [
        "## Overview\n",
        "1. Training and inference using Hugging Face\n",
        "2. Elements of an LLM\n",
        "3. Attention mechanisms\n",
        "4. Positional encoding\n",
        "5. Output layers\n",
        "6. Training loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8DTr56dEiHd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEVeMiL4EiHd"
      },
      "source": [
        "## LLM training and inference using HuggingFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9WFwiNdEiHd"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/hf-logo-with-title.png?raw=1\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
        "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
        "Refer to the following links for more information :\n",
        "\n",
        "https://huggingface.co/docs/hub/index\n",
        "\n",
        "https://huggingface.co/docs/transformers/en/index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuJLa-E0EiHd"
      },
      "source": [
        "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89RVoCgbEiHd"
      },
      "source": [
        "### Inference\n",
        "\n",
        "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_Token')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8OhxXK8-FFKj",
        "outputId": "c3f5ccac-4261-45dc-a455-7f48a6999012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "OM0lPuuXEiHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18083bbb-6d98-4c41-898e-7dcf4b7c8eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"My dog really wanted to get up and go with us and we've been through a bunch of tough\"},\n",
              " {'generated_text': 'My dog really wanted to sit still and think about how sweet my dog was. This was the best'},\n",
              " {'generated_text': \"My dog really wanted to take it. She didn't see anything wrong and she went home. She\"},\n",
              " {'generated_text': 'My dog really wanted to get inside and they told me to hold one hand so there was no sign'},\n",
              " {'generated_text': 'My dog really wanted to get some money after it was attacked,\" said her father.\\n\\nThe'}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
        "input_text = \"My dog really wanted to\"\n",
        "from transformers import pipeline\n",
        "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
        "generator(input_text, max_length=20, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGtBd3uSEiHd"
      },
      "source": [
        "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn3UvF7aEiHd"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Ew-HJyEiHd"
      },
      "source": [
        "We can also load in our own dataset and train a model with this data as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TFiro7vGEiHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2588c0-5f43-467f-ecc7-cf411d9b26dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m286.7/290.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m567.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7S2bwa9EiHe"
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wd2QrlKEiHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6117253c-c736-41c9-be1b-df799705f77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "train_dataset,test_dataset,data_collator = load_dataset('sample_data/train_input.txt','sample_data/test_input.txt', tokenizer)\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 40, # Number of update steps between two evaluations.\n",
        "    save_steps=80, # after # steps model is saved\n",
        "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx1pt1a2EiHe"
      },
      "source": [
        "## What is going on below the hood?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB4BEDmYEiHe"
      },
      "source": [
        "There are two components that are \"black-boxes\" here:\n",
        "1. The method for tokenization\n",
        "2. The model that generates novel text.\n",
        "\n",
        "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIwv5rmVEiHe"
      },
      "source": [
        "Today we will take a closer look at how the model is designed to deal with language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVjlrRWAEiHe"
      },
      "source": [
        "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "e8Q8QtKxEiHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aafdb28-f5e5-4c38-8989-29ec52130601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8K2dcMkEiHe"
      },
      "source": [
        "## General elements of an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2GOPMTQEiHe"
      },
      "source": [
        "GPT-2 is an example of the popular Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cig2mvfguetQ"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/decoder_only_block.png?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee8pkSX7EiHe"
      },
      "source": [
        "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
        "\n",
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/transformer-decoder-intro.png?raw=1\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "Image credit: https://jalammar.github.io/illustrated-gpt2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crkhNX9PEiHe"
      },
      "source": [
        "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers:\n",
        "1. Masked Self-Attention and\n",
        "2. Feed Forward Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjrlB3i4EiHe"
      },
      "source": [
        "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyUQGlWrEiHe"
      },
      "source": [
        "In this lecture, we will\n",
        "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
        "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
        "* Third, discuss outputting real text/sequences from the models.\n",
        "* Fourth, build a training loop for a mini-LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbGu93btEiHe"
      },
      "source": [
        "**Let's set up all the imports we will need**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8Zd4rOy3EiHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fbc4ac-0850-4307-b64e-62c52052b1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a1ae6b34610>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "## IMPORTS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowLYFlCrDrr"
      },
      "source": [
        "## Attention mechanisms\n",
        "\n",
        "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
        "\n",
        "`”The animal didn't cross the street because it was too tired”`\n",
        "\n",
        "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
        "\n",
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/viz-bert-voc-verbs.png?raw=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
        "\n",
        "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9qF6ZoEiHf"
      },
      "source": [
        "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
        "\n",
        "For example, when we read the sentence:\n",
        "`”The animal didn't cross the street because it was too tired”`\n",
        "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
        "\n",
        "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
        "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
        "\n",
        "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B6X6CVrEiHf"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/transformer_self-attention_visualization.png?raw=1\" alt=\"Drawing\" style=\"width: 300px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGbAi0cJ7x3a"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jNDwChhEiHf"
      },
      "source": [
        "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
        "1. Query: the word representation we score other words against using the other word's keys\n",
        "2. Key: labels for the words in a sequence that we match against the query\n",
        "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value.\n",
        "\n",
        "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsM3qij0EiHf"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/self-attention-example-folders-3.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "Image credit: https://jalammar.github.io/illustrated-gpt2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdig9SeYEiHf"
      },
      "source": [
        "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBAp5YIcEiHf"
      },
      "outputs": [],
      "source": [
        "C = 32 # channels\n",
        "head_size = 16\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzf9VE_AqWeR"
      },
      "source": [
        "The algorithm for self-attention is as follows:\n",
        "\n",
        "1. Generate query, key and value vectors for each word\n",
        "2. Calculate a score for each word in the input sentence against each other.\n",
        "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
        "4. Multiply each value vector by the softmax score.\n",
        "5. Sum up the weighted value vectors to produce the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utZi5HPbEiHf"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/self-attention-output.png?raw=1\" alt=\"Drawing\" style=\"width: 450px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOwm-NkXA8U3"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVXDd8SEiHm"
      },
      "source": [
        "Let's see how attention is performed in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSxMboW-EiHm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
        "\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
        "q = query(x) # (B, T, 16)\n",
        "v = value(x)\n",
        "\n",
        "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
        "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
        "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
        "\n",
        "out = wei @ v # aggregate the attention scores and value vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "kYOHOyA7EiHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4a5bc9-f8c7-48ac-9f91-ee065ea9c08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
            "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
            "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
            "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
            "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
            "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
            "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
            "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
            "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
            "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
            "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
            "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
            "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
            "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
            "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
            "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwyFlxKW6oA"
      },
      "source": [
        "### Multi-head attention\n",
        "\n",
        "In practice, multiple attention heads are used which\n",
        "1. Expands the model’s ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
        "2. Have multiple “representation subspaces”. Have multiple sets of Query/Key/Value weight matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkG7iQtkEiHm"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/transformer_multi-headed_self-attention-recap.png?raw=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oHsezdVBIaf"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rVresLmEiHm"
      },
      "source": [
        "### Let's see attention mechanisms in action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yocn9Fm7EiHm"
      },
      "source": [
        "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f2CwiJ4FEiHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4598e5eb-f93c-42ed-886f-7a48e7d43e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/157.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m122.9/157.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.2)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.34.66-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.4.2)\n",
            "Collecting botocore<1.35.0,>=1.34.66 (from boto3->bertviz)\n",
            "  Downloading botocore-1.34.66-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.66->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.66->boto3->bertviz) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
            "Successfully installed bertviz-1.4.0 boto3-1.34.66 botocore-1.34.66 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bertviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i8wglKFEiHn"
      },
      "source": [
        "Let's load in the model, GPT2 and look at the attention mechanisms.\n",
        "\n",
        "**Hint... click on the different blocks in the visualization to see the attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "RXjZ6_7_EiHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "8d87e69b-a8ea-4b35-a3a6-07997aa01b88"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bertviz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1eada2c04cda>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Suppress standard warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertviz'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
        "\n",
        "from bertviz import model_view\n",
        "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
        "\n",
        "model_name = 'openai-community/gpt2'\n",
        "input_text = \"No, I am your father\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
        "outputs = model(inputs)  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
        "model_view(attention, tokens)  # Display model view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSPcvYjDEiHn"
      },
      "source": [
        "## Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFq78-kjbrWp"
      },
      "source": [
        "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
        "\n",
        "Consider the following two sentences to see why this is important:\n",
        "\n",
        "``The man ate the sandwich.``\n",
        "\n",
        "``The sandwich ate the man.``\n",
        "\n",
        "Clearly, these are two vastly different situations even though they have the same words. The Transformer can\n",
        "\n",
        "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOimbcM2EiHn"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/positional_encoding.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em43_vjcEiHn"
      },
      "source": [
        "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal.\n",
        "\n",
        "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noPUQP3sEiHn"
      },
      "outputs": [],
      "source": [
        "vocab_size = 65\n",
        "n_embd = 64\n",
        "\n",
        "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "position_embedding_table = nn.Embedding(block_size, n_embd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-cjbmFDEiHn"
      },
      "source": [
        "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn-bUP65EiHn"
      },
      "source": [
        "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADWiuXYLEiHn"
      },
      "source": [
        "Let's look at token embedding alone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "Ee3DPCSCEiHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47318bbe-5dca-4d02-9551-f6eceed7c208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.7221, -0.9629, -2.0578,  1.9740,  0.7434,  1.1139,  0.6926,  0.0296,\n",
            "         0.6405, -1.6464,  0.4935,  0.7485,  0.9238, -0.4940,  0.4814, -0.3859,\n",
            "        -0.3094,  1.1066, -0.2891,  0.1891,  2.0440, -0.7945, -0.4331,  0.3007,\n",
            "         1.4317,  0.2881, -0.4343,  0.4280,  1.2469,  1.4047, -0.3404, -2.2190,\n",
            "         0.4893,  0.0398, -0.2717, -2.2400, -0.0029, -1.4251,  0.7330,  0.3551,\n",
            "         0.1472, -1.1895, -0.8407,  0.3134, -0.6709, -0.8176,  0.6929, -0.6374,\n",
            "         0.3174,  0.4837, -0.0073, -1.5924,  1.8606, -1.2910, -0.1594,  0.3111,\n",
            "        -0.1536, -0.3414, -0.0170, -0.1633,  0.2794,  0.6755,  0.7066, -1.6665],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
        "x = token_embedding_table(x)\n",
        "print(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1U1tUQDEiHn"
      },
      "source": [
        "And token + positional embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "wdcaFMqvEiHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23776ec-3595-4d73-dda5-632935df69cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4326, -1.6287, -0.8684,  3.0704,  0.3646,  1.9826,  0.7582, -0.1918,\n",
            "         1.0491, -2.2562, -0.4931, -0.7808,  1.7206, -1.0297,  2.0798, -1.3427,\n",
            "        -0.7896, -0.1746,  0.0926,  0.0543,  2.3831, -0.6208,  0.3902,  0.1097,\n",
            "         1.0455, -1.4557,  0.3402,  2.6717,  1.8380,  1.2628, -0.4831, -4.6023,\n",
            "         0.6959,  1.0347,  0.5903, -0.7541,  0.4682, -0.3895,  2.1526,  0.6272,\n",
            "        -0.8558, -0.8434,  0.1311, -1.0272, -2.0580,  0.0584,  0.3442, -0.3464,\n",
            "        -0.3444,  2.3134, -1.1142, -1.4629,  3.3503, -2.0594,  1.4105,  0.4558,\n",
            "        -1.3366,  1.9283,  1.5187,  0.3906,  1.1448, -0.8422,  2.2692, -0.7949],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
        "x= position_embedding_table(x) + token_embedding_table(x)\n",
        "print(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKGfL7GUEiHn"
      },
      "source": [
        "You can see a clear offset between these two embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKI0DOz-EiHn"
      },
      "source": [
        "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF1HzH9xNJ7S"
      },
      "source": [
        "## Output layers\n",
        "\n",
        "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
        "\n",
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/transformer-decoder-intro.png?raw=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
        "\n",
        "Using a final Linear layer and a Softmax Layer.\n",
        "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
        "\n",
        "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide – each cell corresponds to the score of a unique word.\n",
        "\n",
        "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7vD9tZ7EiHn"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/transformer_decoder_output_softmax.png?raw=1\" alt=\"Drawing\" style=\"width: 450px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6r-z8dN_RV"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK8q67P03yr4"
      },
      "source": [
        "## Training\n",
        "\n",
        "How does an LLM improve over time?\n",
        "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths.\n",
        "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths.\n",
        "For example, when translating the sentence: “je suis étudiant” into “i am a student” as can be seen in the example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J5BOampEiHn"
      },
      "source": [
        "<img src=\"https://github.com/rachelhamelburg/ai-science-training-series/blob/main/05_llm_part2/images/output_target_probability_distributions.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cjHnst5EiHo"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeHpN46nEiHo"
      },
      "source": [
        "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
        "\n",
        "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
        "\n",
        "where p(x) represents the true distribution and q(x) represents the predicted distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XkQAcIhtEiHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9476927f-1059-44da-bcbb-55bd30108d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9119)\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import functional as F\n",
        "logits = torch.tensor([0.5, 0.1, 0.3])\n",
        "targets = torch.tensor([1.0, 0.0, 0.0])\n",
        "loss = F.cross_entropy(logits, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msoDce8lEiHo"
      },
      "source": [
        "Another important metric commonly used in LLMs is **perplexity**.\n",
        "\n",
        "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bNlSe5DEiHo"
      },
      "source": [
        "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
        "\n",
        "$\\text{perplexity} = exp(\\text{CE})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFH0p0YREiHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad0fa96-e64d-4c54-d78d-e8ec0c29ab3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4891)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djqvzUF5EiHo"
      },
      "source": [
        "In this example, we are using cross entropy loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRYcITftEiHo"
      },
      "source": [
        "## Let's train a mini-LLM from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkPINbrZEiHo"
      },
      "source": [
        "### Set up hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BfGwrVzEiHo"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 10\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwguWFYxEiHo"
      },
      "source": [
        "### Load in data and create train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13UaxNg8EiHo"
      },
      "source": [
        "We're going to be using the tiny Shakespeare dataset.\n",
        "Data is tokenized according to a simple character based tokenizer.\n",
        "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BATNqKLwEiHo"
      },
      "outputs": [],
      "source": [
        "with open('sample_data/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hda0K8jEiHo"
      },
      "source": [
        "### Set up the components of the Decoder block:\n",
        "* MultiHeadAttention\n",
        "* FeedForward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gglSGbBmEiHo"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C) 16,32,16\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3iQLT-tEiHo"
      },
      "source": [
        "### Combine components into the Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCQVgA_UEiHo"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))    # Communication\n",
        "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4jN_egEiHo"
      },
      "source": [
        "### Set up the full Transformer model\n",
        "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUgX3_LaEiHo"
      },
      "outputs": [],
      "source": [
        "# super simple language model\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30rTaaItEiHp"
      },
      "source": [
        "We will be training a larger LLM on distributed resources in session 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3D2wZeKEiHp"
      },
      "source": [
        "## Homework\n",
        "\n",
        "1. In this notebook, we learned the various components of an LLM.\n",
        "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
        "      \n",
        "    Hint: this function might be useful for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxQsQSmPEiHp"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkzGqQ9FEiHp"
      },
      "source": [
        "2. Run the same training loop but modify one of the hyperparameters from this list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_FRnTFkEiHp"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsK0cZzUEiHp"
      },
      "source": [
        "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jJDy6jxEiHp"
      },
      "source": [
        "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay-TJ114EiHp"
      },
      "source": [
        "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDXLTusqxXHf"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znx218XPEiHp"
      },
      "source": [
        "Here are some recommendations for further reading and additional code for review.\n",
        "\n",
        "* \"The Illustrated Transformer\" by Jay Alammar\n",
        "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
        "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
        "* \"A gentle introduction to positional encoding\"\n",
        "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
        "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "model = LanguageModel().to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x, y = get_batch('train')\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if iteration % eval_interval == 0:\n",
        "        print(f\"Iteration {iteration}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "    if iteration % eval_iters == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_losses_dict = estimate_loss()\n",
        "            train_loss = val_losses_dict['train']\n",
        "            val_loss = val_losses_dict['val']\n",
        "\n",
        "            # Calculate perplexity\n",
        "            train_perplexity = torch.exp(torch.tensor(train_loss))\n",
        "            val_perplexity = torch.exp(torch.tensor(val_loss))\n",
        "\n",
        "            # Print perplexity\n",
        "            print(f\"Iteration {iteration}, Train Perplexity: {train_perplexity}, Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "            # Append perplexity values to lists for tracking\n",
        "            train_losses.append(train_perplexity)\n",
        "            val_losses.append(val_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glcQcLt9ehm9",
        "outputId": "6f82e844-63fd-43f0-a16f-2123de5adaf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.339982986450195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-72e0d06030b9>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss))\n",
            "<ipython-input-32-72e0d06030b9>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Train Perplexity: 62.67686462402344, Validation Perplexity: 63.04446792602539\n",
            "Iteration 10, Loss: 3.5614423751831055\n",
            "Iteration 20, Loss: 3.29185152053833\n",
            "Iteration 30, Loss: 2.9861342906951904\n",
            "Iteration 40, Loss: 2.9324193000793457\n",
            "Iteration 50, Loss: 2.791506290435791\n",
            "Iteration 60, Loss: 2.770407199859619\n",
            "Iteration 70, Loss: 2.6707444190979004\n",
            "Iteration 80, Loss: 2.725066661834717\n",
            "Iteration 90, Loss: 2.642359972000122\n",
            "Iteration 100, Loss: 2.7209291458129883\n",
            "Iteration 110, Loss: 2.5634562969207764\n",
            "Iteration 120, Loss: 2.584496021270752\n",
            "Iteration 130, Loss: 2.4745805263519287\n",
            "Iteration 140, Loss: 2.5432801246643066\n",
            "Iteration 150, Loss: 2.6095685958862305\n",
            "Iteration 160, Loss: 2.458785057067871\n",
            "Iteration 170, Loss: 2.5549862384796143\n",
            "Iteration 180, Loss: 2.51290225982666\n",
            "Iteration 190, Loss: 2.5785038471221924\n",
            "Iteration 200, Loss: 2.5731167793273926\n",
            "Iteration 200, Train Perplexity: 12.09229850769043, Validation Perplexity: 12.085458755493164\n",
            "Iteration 210, Loss: 2.4532413482666016\n",
            "Iteration 220, Loss: 2.5067732334136963\n",
            "Iteration 230, Loss: 2.3923938274383545\n",
            "Iteration 240, Loss: 2.37491512298584\n",
            "Iteration 250, Loss: 2.457151412963867\n",
            "Iteration 260, Loss: 2.434710741043091\n",
            "Iteration 270, Loss: 2.4428350925445557\n",
            "Iteration 280, Loss: 2.522252321243286\n",
            "Iteration 290, Loss: 2.512864589691162\n",
            "Iteration 300, Loss: 2.437514066696167\n",
            "Iteration 310, Loss: 2.3790910243988037\n",
            "Iteration 320, Loss: 2.4150407314300537\n",
            "Iteration 330, Loss: 2.299412250518799\n",
            "Iteration 340, Loss: 2.438626527786255\n",
            "Iteration 350, Loss: 2.4171011447906494\n",
            "Iteration 360, Loss: 2.391601085662842\n",
            "Iteration 370, Loss: 2.3868136405944824\n",
            "Iteration 380, Loss: 2.3980464935302734\n",
            "Iteration 390, Loss: 2.3565258979797363\n",
            "Iteration 400, Loss: 2.2933623790740967\n",
            "Iteration 400, Train Perplexity: 10.462848663330078, Validation Perplexity: 10.561015129089355\n",
            "Iteration 410, Loss: 2.305624485015869\n",
            "Iteration 420, Loss: 2.3280417919158936\n",
            "Iteration 430, Loss: 2.285844564437866\n",
            "Iteration 440, Loss: 2.2895686626434326\n",
            "Iteration 450, Loss: 2.357403516769409\n",
            "Iteration 460, Loss: 2.3634443283081055\n",
            "Iteration 470, Loss: 2.374937057495117\n",
            "Iteration 480, Loss: 2.324484348297119\n",
            "Iteration 490, Loss: 2.328596591949463\n",
            "Iteration 500, Loss: 2.3028459548950195\n",
            "Iteration 510, Loss: 2.2920303344726562\n",
            "Iteration 520, Loss: 2.2715885639190674\n",
            "Iteration 530, Loss: 2.3174073696136475\n",
            "Iteration 540, Loss: 2.3834388256073\n",
            "Iteration 550, Loss: 2.209540367126465\n",
            "Iteration 560, Loss: 2.2647898197174072\n",
            "Iteration 570, Loss: 2.250427722930908\n",
            "Iteration 580, Loss: 2.248134136199951\n",
            "Iteration 590, Loss: 2.373978614807129\n",
            "Iteration 600, Loss: 2.356513500213623\n",
            "Iteration 600, Train Perplexity: 9.438366889953613, Validation Perplexity: 9.645469665527344\n",
            "Iteration 610, Loss: 2.2923316955566406\n",
            "Iteration 620, Loss: 2.191532611846924\n",
            "Iteration 630, Loss: 2.2063229084014893\n",
            "Iteration 640, Loss: 2.196972608566284\n",
            "Iteration 650, Loss: 2.2718658447265625\n",
            "Iteration 660, Loss: 2.266139507293701\n",
            "Iteration 670, Loss: 2.135354518890381\n",
            "Iteration 680, Loss: 2.2195816040039062\n",
            "Iteration 690, Loss: 2.221102476119995\n",
            "Iteration 700, Loss: 2.1579418182373047\n",
            "Iteration 710, Loss: 2.2369332313537598\n",
            "Iteration 720, Loss: 2.1875991821289062\n",
            "Iteration 730, Loss: 2.106285333633423\n",
            "Iteration 740, Loss: 2.1931684017181396\n",
            "Iteration 750, Loss: 2.1526262760162354\n",
            "Iteration 760, Loss: 2.156669855117798\n",
            "Iteration 770, Loss: 2.110729932785034\n",
            "Iteration 780, Loss: 2.096325635910034\n",
            "Iteration 790, Loss: 2.2477290630340576\n",
            "Iteration 800, Loss: 2.158937454223633\n",
            "Iteration 800, Train Perplexity: 8.740988731384277, Validation Perplexity: 8.88642692565918\n",
            "Iteration 810, Loss: 2.095651149749756\n",
            "Iteration 820, Loss: 2.1659505367279053\n",
            "Iteration 830, Loss: 2.1323885917663574\n",
            "Iteration 840, Loss: 2.1418700218200684\n",
            "Iteration 850, Loss: 2.056267023086548\n",
            "Iteration 860, Loss: 2.0646722316741943\n",
            "Iteration 870, Loss: 2.0891754627227783\n",
            "Iteration 880, Loss: 2.042036294937134\n",
            "Iteration 890, Loss: 2.1845338344573975\n",
            "Iteration 900, Loss: 2.0665578842163086\n",
            "Iteration 910, Loss: 2.107145071029663\n",
            "Iteration 920, Loss: 2.072341203689575\n",
            "Iteration 930, Loss: 2.1653733253479004\n",
            "Iteration 940, Loss: 2.0865955352783203\n",
            "Iteration 950, Loss: 2.1094419956207275\n",
            "Iteration 960, Loss: 2.1881513595581055\n",
            "Iteration 970, Loss: 2.0658977031707764\n",
            "Iteration 980, Loss: 2.0992181301116943\n",
            "Iteration 990, Loss: 2.1746625900268555\n",
            "Iteration 1000, Loss: 2.1372482776641846\n",
            "Iteration 1000, Train Perplexity: 8.190743446350098, Validation Perplexity: 8.50727653503418\n",
            "Iteration 1010, Loss: 2.042520046234131\n",
            "Iteration 1020, Loss: 2.106391668319702\n",
            "Iteration 1030, Loss: 2.002049207687378\n",
            "Iteration 1040, Loss: 2.025362491607666\n",
            "Iteration 1050, Loss: 2.080820322036743\n",
            "Iteration 1060, Loss: 1.9549480676651\n",
            "Iteration 1070, Loss: 2.099750518798828\n",
            "Iteration 1080, Loss: 1.957919955253601\n",
            "Iteration 1090, Loss: 2.150620460510254\n",
            "Iteration 1100, Loss: 2.0074992179870605\n",
            "Iteration 1110, Loss: 2.0892508029937744\n",
            "Iteration 1120, Loss: 2.0921051502227783\n",
            "Iteration 1130, Loss: 2.0674805641174316\n",
            "Iteration 1140, Loss: 2.0718414783477783\n",
            "Iteration 1150, Loss: 2.145268678665161\n",
            "Iteration 1160, Loss: 2.0905702114105225\n",
            "Iteration 1170, Loss: 2.019850015640259\n",
            "Iteration 1180, Loss: 2.0449466705322266\n",
            "Iteration 1190, Loss: 2.0264205932617188\n",
            "Iteration 1200, Loss: 1.947178840637207\n",
            "Iteration 1200, Train Perplexity: 7.733476161956787, Validation Perplexity: 8.14086627960205\n",
            "Iteration 1210, Loss: 2.0251824855804443\n",
            "Iteration 1220, Loss: 2.0679595470428467\n",
            "Iteration 1230, Loss: 2.031019926071167\n",
            "Iteration 1240, Loss: 2.086787700653076\n",
            "Iteration 1250, Loss: 2.148273229598999\n",
            "Iteration 1260, Loss: 2.091400384902954\n",
            "Iteration 1270, Loss: 1.983617901802063\n",
            "Iteration 1280, Loss: 2.0477633476257324\n",
            "Iteration 1290, Loss: 2.0211758613586426\n",
            "Iteration 1300, Loss: 2.086345911026001\n",
            "Iteration 1310, Loss: 2.0416252613067627\n",
            "Iteration 1320, Loss: 2.0383963584899902\n",
            "Iteration 1330, Loss: 1.865264654159546\n",
            "Iteration 1340, Loss: 1.9826463460922241\n",
            "Iteration 1350, Loss: 1.9901107549667358\n",
            "Iteration 1360, Loss: 2.0034139156341553\n",
            "Iteration 1370, Loss: 1.981476902961731\n",
            "Iteration 1380, Loss: 1.9777730703353882\n",
            "Iteration 1390, Loss: 1.926193118095398\n",
            "Iteration 1400, Loss: 1.9930630922317505\n",
            "Iteration 1400, Train Perplexity: 7.3896284103393555, Validation Perplexity: 7.75433349609375\n",
            "Iteration 1410, Loss: 1.9911866188049316\n",
            "Iteration 1420, Loss: 2.178748369216919\n",
            "Iteration 1430, Loss: 1.9514000415802002\n",
            "Iteration 1440, Loss: 2.1080515384674072\n",
            "Iteration 1450, Loss: 1.9341639280319214\n",
            "Iteration 1460, Loss: 2.082207679748535\n",
            "Iteration 1470, Loss: 2.105822801589966\n",
            "Iteration 1480, Loss: 1.8738815784454346\n",
            "Iteration 1490, Loss: 1.994811773300171\n",
            "Iteration 1500, Loss: 1.9197628498077393\n",
            "Iteration 1510, Loss: 2.016512393951416\n",
            "Iteration 1520, Loss: 1.9557267427444458\n",
            "Iteration 1530, Loss: 1.7806845903396606\n",
            "Iteration 1540, Loss: 1.9539189338684082\n",
            "Iteration 1550, Loss: 1.8766149282455444\n",
            "Iteration 1560, Loss: 1.9027290344238281\n",
            "Iteration 1570, Loss: 1.9608433246612549\n",
            "Iteration 1580, Loss: 2.0037434101104736\n",
            "Iteration 1590, Loss: 1.8935887813568115\n",
            "Iteration 1600, Loss: 1.926864743232727\n",
            "Iteration 1600, Train Perplexity: 7.1037516593933105, Validation Perplexity: 7.669118404388428\n",
            "Iteration 1610, Loss: 1.9402114152908325\n",
            "Iteration 1620, Loss: 1.9976931810379028\n",
            "Iteration 1630, Loss: 2.004523992538452\n",
            "Iteration 1640, Loss: 2.045487642288208\n",
            "Iteration 1650, Loss: 2.0012118816375732\n",
            "Iteration 1660, Loss: 1.9788761138916016\n",
            "Iteration 1670, Loss: 1.8638362884521484\n",
            "Iteration 1680, Loss: 1.872075080871582\n",
            "Iteration 1690, Loss: 1.9476711750030518\n",
            "Iteration 1700, Loss: 2.096500873565674\n",
            "Iteration 1710, Loss: 1.8164118528366089\n",
            "Iteration 1720, Loss: 1.786749243736267\n",
            "Iteration 1730, Loss: 1.9577877521514893\n",
            "Iteration 1740, Loss: 1.861084222793579\n",
            "Iteration 1750, Loss: 1.8994020223617554\n",
            "Iteration 1760, Loss: 1.9112186431884766\n",
            "Iteration 1770, Loss: 2.0677812099456787\n",
            "Iteration 1780, Loss: 2.04931902885437\n",
            "Iteration 1790, Loss: 1.9398750066757202\n",
            "Iteration 1800, Loss: 1.9298561811447144\n",
            "Iteration 1800, Train Perplexity: 6.765284538269043, Validation Perplexity: 7.349818706512451\n",
            "Iteration 1810, Loss: 1.9405139684677124\n",
            "Iteration 1820, Loss: 1.8681706190109253\n",
            "Iteration 1830, Loss: 1.9134008884429932\n",
            "Iteration 1840, Loss: 1.82961905002594\n",
            "Iteration 1850, Loss: 1.788953185081482\n",
            "Iteration 1860, Loss: 1.9006528854370117\n",
            "Iteration 1870, Loss: 1.960800290107727\n",
            "Iteration 1880, Loss: 1.914778232574463\n",
            "Iteration 1890, Loss: 1.881250262260437\n",
            "Iteration 1900, Loss: 1.924044132232666\n",
            "Iteration 1910, Loss: 1.9254083633422852\n",
            "Iteration 1920, Loss: 1.883576512336731\n",
            "Iteration 1930, Loss: 1.8112562894821167\n",
            "Iteration 1940, Loss: 1.8613324165344238\n",
            "Iteration 1950, Loss: 1.9770480394363403\n",
            "Iteration 1960, Loss: 1.9536921977996826\n",
            "Iteration 1970, Loss: 1.9658994674682617\n",
            "Iteration 1980, Loss: 1.9029390811920166\n",
            "Iteration 1990, Loss: 1.809795618057251\n",
            "Iteration 2000, Loss: 1.9068214893341064\n",
            "Iteration 2000, Train Perplexity: 6.599155426025391, Validation Perplexity: 7.351537704467773\n",
            "Iteration 2010, Loss: 1.8550810813903809\n",
            "Iteration 2020, Loss: 1.9050768613815308\n",
            "Iteration 2030, Loss: 1.79522705078125\n",
            "Iteration 2040, Loss: 1.8779397010803223\n",
            "Iteration 2050, Loss: 1.9992201328277588\n",
            "Iteration 2060, Loss: 1.8320300579071045\n",
            "Iteration 2070, Loss: 1.853325366973877\n",
            "Iteration 2080, Loss: 1.8374212980270386\n",
            "Iteration 2090, Loss: 1.922334909439087\n",
            "Iteration 2100, Loss: 1.7210261821746826\n",
            "Iteration 2110, Loss: 1.9269052743911743\n",
            "Iteration 2120, Loss: 1.9060558080673218\n",
            "Iteration 2130, Loss: 1.7837666273117065\n",
            "Iteration 2140, Loss: 1.9746818542480469\n",
            "Iteration 2150, Loss: 1.8718087673187256\n",
            "Iteration 2160, Loss: 1.790937900543213\n",
            "Iteration 2170, Loss: 1.8290470838546753\n",
            "Iteration 2180, Loss: 1.805894374847412\n",
            "Iteration 2190, Loss: 1.6384443044662476\n",
            "Iteration 2200, Loss: 1.8152918815612793\n",
            "Iteration 2200, Train Perplexity: 6.324912071228027, Validation Perplexity: 7.0858283042907715\n",
            "Iteration 2210, Loss: 1.7724888324737549\n",
            "Iteration 2220, Loss: 1.7034211158752441\n",
            "Iteration 2230, Loss: 1.9013419151306152\n",
            "Iteration 2240, Loss: 1.8589750528335571\n",
            "Iteration 2250, Loss: 1.840612769126892\n",
            "Iteration 2260, Loss: 1.7816914319992065\n",
            "Iteration 2270, Loss: 1.7025296688079834\n",
            "Iteration 2280, Loss: 1.7903454303741455\n",
            "Iteration 2290, Loss: 1.8206850290298462\n",
            "Iteration 2300, Loss: 1.8733381032943726\n",
            "Iteration 2310, Loss: 1.7829961776733398\n",
            "Iteration 2320, Loss: 1.7768386602401733\n",
            "Iteration 2330, Loss: 1.7851319313049316\n",
            "Iteration 2340, Loss: 1.9241093397140503\n",
            "Iteration 2350, Loss: 1.8916490077972412\n",
            "Iteration 2360, Loss: 1.9070936441421509\n",
            "Iteration 2370, Loss: 1.8315846920013428\n",
            "Iteration 2380, Loss: 1.9190468788146973\n",
            "Iteration 2390, Loss: 1.8652867078781128\n",
            "Iteration 2400, Loss: 1.7989004850387573\n",
            "Iteration 2400, Train Perplexity: 6.234393119812012, Validation Perplexity: 6.988193511962891\n",
            "Iteration 2410, Loss: 1.753940463066101\n",
            "Iteration 2420, Loss: 1.7176004648208618\n",
            "Iteration 2430, Loss: 1.8003431558609009\n",
            "Iteration 2440, Loss: 1.8337805271148682\n",
            "Iteration 2450, Loss: 1.694481611251831\n",
            "Iteration 2460, Loss: 1.8523682355880737\n",
            "Iteration 2470, Loss: 1.760582447052002\n",
            "Iteration 2480, Loss: 1.879565954208374\n",
            "Iteration 2490, Loss: 1.9199682474136353\n",
            "Iteration 2500, Loss: 1.8382549285888672\n",
            "Iteration 2510, Loss: 1.8515117168426514\n",
            "Iteration 2520, Loss: 1.7988152503967285\n",
            "Iteration 2530, Loss: 1.7797867059707642\n",
            "Iteration 2540, Loss: 1.9029637575149536\n",
            "Iteration 2550, Loss: 1.732971429824829\n",
            "Iteration 2560, Loss: 1.8518611192703247\n",
            "Iteration 2570, Loss: 1.8065636157989502\n",
            "Iteration 2580, Loss: 1.8686894178390503\n",
            "Iteration 2590, Loss: 1.710047721862793\n",
            "Iteration 2600, Loss: 1.9151536226272583\n",
            "Iteration 2600, Train Perplexity: 6.077842712402344, Validation Perplexity: 6.893647193908691\n",
            "Iteration 2610, Loss: 1.9009125232696533\n",
            "Iteration 2620, Loss: 1.908265471458435\n",
            "Iteration 2630, Loss: 1.7382808923721313\n",
            "Iteration 2640, Loss: 1.8456079959869385\n",
            "Iteration 2650, Loss: 1.7377030849456787\n",
            "Iteration 2660, Loss: 1.836533546447754\n",
            "Iteration 2670, Loss: 1.6749966144561768\n",
            "Iteration 2680, Loss: 1.783506155014038\n",
            "Iteration 2690, Loss: 1.783440351486206\n",
            "Iteration 2700, Loss: 1.7664566040039062\n",
            "Iteration 2710, Loss: 1.761680245399475\n",
            "Iteration 2720, Loss: 1.9064300060272217\n",
            "Iteration 2730, Loss: 1.8405919075012207\n",
            "Iteration 2740, Loss: 1.8704122304916382\n",
            "Iteration 2750, Loss: 1.8052384853363037\n",
            "Iteration 2760, Loss: 1.8150101900100708\n",
            "Iteration 2770, Loss: 1.8213354349136353\n",
            "Iteration 2780, Loss: 1.8300162553787231\n",
            "Iteration 2790, Loss: 1.8911354541778564\n",
            "Iteration 2800, Loss: 1.8162992000579834\n",
            "Iteration 2800, Train Perplexity: 5.960371971130371, Validation Perplexity: 6.785617351531982\n",
            "Iteration 2810, Loss: 1.740364670753479\n",
            "Iteration 2820, Loss: 1.7810708284378052\n",
            "Iteration 2830, Loss: 1.7756762504577637\n",
            "Iteration 2840, Loss: 1.7604622840881348\n",
            "Iteration 2850, Loss: 1.935610055923462\n",
            "Iteration 2860, Loss: 1.8784228563308716\n",
            "Iteration 2870, Loss: 1.7481114864349365\n",
            "Iteration 2880, Loss: 1.7658822536468506\n",
            "Iteration 2890, Loss: 1.7799146175384521\n",
            "Iteration 2900, Loss: 1.896983027458191\n",
            "Iteration 2910, Loss: 1.8070710897445679\n",
            "Iteration 2920, Loss: 1.6858586072921753\n",
            "Iteration 2930, Loss: 1.760635495185852\n",
            "Iteration 2940, Loss: 1.6941161155700684\n",
            "Iteration 2950, Loss: 1.803452491760254\n",
            "Iteration 2960, Loss: 1.486185908317566\n",
            "Iteration 2970, Loss: 1.6844031810760498\n",
            "Iteration 2980, Loss: 1.8582614660263062\n",
            "Iteration 2990, Loss: 1.6880340576171875\n",
            "Iteration 3000, Loss: 1.7085144519805908\n",
            "Iteration 3000, Train Perplexity: 5.922375202178955, Validation Perplexity: 6.762377738952637\n",
            "Iteration 3010, Loss: 1.710835337638855\n",
            "Iteration 3020, Loss: 1.8427605628967285\n",
            "Iteration 3030, Loss: 1.812248945236206\n",
            "Iteration 3040, Loss: 1.7358429431915283\n",
            "Iteration 3050, Loss: 1.799208164215088\n",
            "Iteration 3060, Loss: 1.8481420278549194\n",
            "Iteration 3070, Loss: 1.9531574249267578\n",
            "Iteration 3080, Loss: 1.7980893850326538\n",
            "Iteration 3090, Loss: 1.8188856840133667\n",
            "Iteration 3100, Loss: 1.6844171285629272\n",
            "Iteration 3110, Loss: 1.6663403511047363\n",
            "Iteration 3120, Loss: 1.7402420043945312\n",
            "Iteration 3130, Loss: 1.7389297485351562\n",
            "Iteration 3140, Loss: 1.6259899139404297\n",
            "Iteration 3150, Loss: 1.6418360471725464\n",
            "Iteration 3160, Loss: 1.844578504562378\n",
            "Iteration 3170, Loss: 1.729249358177185\n",
            "Iteration 3180, Loss: 1.6938785314559937\n",
            "Iteration 3190, Loss: 1.7634925842285156\n",
            "Iteration 3200, Loss: 1.7754453420639038\n",
            "Iteration 3200, Train Perplexity: 5.7449212074279785, Validation Perplexity: 6.63128662109375\n",
            "Iteration 3210, Loss: 1.670082688331604\n",
            "Iteration 3220, Loss: 1.7870656251907349\n",
            "Iteration 3230, Loss: 1.8808605670928955\n",
            "Iteration 3240, Loss: 1.7472994327545166\n",
            "Iteration 3250, Loss: 1.7469643354415894\n",
            "Iteration 3260, Loss: 1.7014760971069336\n",
            "Iteration 3270, Loss: 1.7230206727981567\n",
            "Iteration 3280, Loss: 1.852914571762085\n",
            "Iteration 3290, Loss: 1.660452127456665\n",
            "Iteration 3300, Loss: 1.6722359657287598\n",
            "Iteration 3310, Loss: 1.7393786907196045\n",
            "Iteration 3320, Loss: 1.6893166303634644\n",
            "Iteration 3330, Loss: 1.7131775617599487\n",
            "Iteration 3340, Loss: 1.7134339809417725\n",
            "Iteration 3350, Loss: 1.7969286441802979\n",
            "Iteration 3360, Loss: 1.6330538988113403\n",
            "Iteration 3370, Loss: 1.8114774227142334\n",
            "Iteration 3380, Loss: 1.6691498756408691\n",
            "Iteration 3390, Loss: 1.7246861457824707\n",
            "Iteration 3400, Loss: 1.7726938724517822\n",
            "Iteration 3400, Train Perplexity: 5.730042934417725, Validation Perplexity: 6.660060405731201\n",
            "Iteration 3410, Loss: 1.7809369564056396\n",
            "Iteration 3420, Loss: 1.7956169843673706\n",
            "Iteration 3430, Loss: 1.7873317003250122\n",
            "Iteration 3440, Loss: 1.7668241262435913\n",
            "Iteration 3450, Loss: 1.7347909212112427\n",
            "Iteration 3460, Loss: 1.611540675163269\n",
            "Iteration 3470, Loss: 1.7019027471542358\n",
            "Iteration 3480, Loss: 1.8036017417907715\n",
            "Iteration 3490, Loss: 1.5412341356277466\n",
            "Iteration 3500, Loss: 1.7191907167434692\n",
            "Iteration 3510, Loss: 1.725351095199585\n",
            "Iteration 3520, Loss: 1.6880961656570435\n",
            "Iteration 3530, Loss: 1.7271114587783813\n",
            "Iteration 3540, Loss: 1.789076566696167\n",
            "Iteration 3550, Loss: 1.6182509660720825\n",
            "Iteration 3560, Loss: 1.7411627769470215\n",
            "Iteration 3570, Loss: 1.7118422985076904\n",
            "Iteration 3580, Loss: 1.7070097923278809\n",
            "Iteration 3590, Loss: 1.7022454738616943\n",
            "Iteration 3600, Loss: 1.6226081848144531\n",
            "Iteration 3600, Train Perplexity: 5.68849515914917, Validation Perplexity: 6.581284999847412\n",
            "Iteration 3610, Loss: 1.7539368867874146\n",
            "Iteration 3620, Loss: 1.8108060359954834\n",
            "Iteration 3630, Loss: 1.7377780675888062\n",
            "Iteration 3640, Loss: 1.712125301361084\n",
            "Iteration 3650, Loss: 1.611971378326416\n",
            "Iteration 3660, Loss: 1.6823694705963135\n",
            "Iteration 3670, Loss: 1.6977779865264893\n",
            "Iteration 3680, Loss: 1.7278249263763428\n",
            "Iteration 3690, Loss: 1.675010323524475\n",
            "Iteration 3700, Loss: 1.6889961957931519\n",
            "Iteration 3710, Loss: 1.7367699146270752\n",
            "Iteration 3720, Loss: 1.7040818929672241\n",
            "Iteration 3730, Loss: 1.7768986225128174\n",
            "Iteration 3740, Loss: 1.6643613576889038\n",
            "Iteration 3750, Loss: 1.6143689155578613\n",
            "Iteration 3760, Loss: 1.8850575685501099\n",
            "Iteration 3770, Loss: 1.7039512395858765\n",
            "Iteration 3780, Loss: 1.7913930416107178\n",
            "Iteration 3790, Loss: 1.7483322620391846\n",
            "Iteration 3800, Loss: 1.796603798866272\n",
            "Iteration 3800, Train Perplexity: 5.637547492980957, Validation Perplexity: 6.620321273803711\n",
            "Iteration 3810, Loss: 1.719123363494873\n",
            "Iteration 3820, Loss: 1.6313180923461914\n",
            "Iteration 3830, Loss: 1.6539041996002197\n",
            "Iteration 3840, Loss: 1.6789156198501587\n",
            "Iteration 3850, Loss: 1.6341277360916138\n",
            "Iteration 3860, Loss: 1.689497709274292\n",
            "Iteration 3870, Loss: 1.8417041301727295\n",
            "Iteration 3880, Loss: 1.7408077716827393\n",
            "Iteration 3890, Loss: 1.6802564859390259\n",
            "Iteration 3900, Loss: 1.5891207456588745\n",
            "Iteration 3910, Loss: 1.5853254795074463\n",
            "Iteration 3920, Loss: 1.7045892477035522\n",
            "Iteration 3930, Loss: 1.624768853187561\n",
            "Iteration 3940, Loss: 1.813826322555542\n",
            "Iteration 3950, Loss: 1.7077678442001343\n",
            "Iteration 3960, Loss: 1.7582454681396484\n",
            "Iteration 3970, Loss: 1.6811884641647339\n",
            "Iteration 3980, Loss: 1.6743170022964478\n",
            "Iteration 3990, Loss: 1.762765645980835\n",
            "Iteration 4000, Loss: 1.6364319324493408\n",
            "Iteration 4000, Train Perplexity: 5.51873254776001, Validation Perplexity: 6.531402587890625\n",
            "Iteration 4010, Loss: 1.5819238424301147\n",
            "Iteration 4020, Loss: 1.5129210948944092\n",
            "Iteration 4030, Loss: 1.746095895767212\n",
            "Iteration 4040, Loss: 1.7107784748077393\n",
            "Iteration 4050, Loss: 1.73786199092865\n",
            "Iteration 4060, Loss: 1.6947777271270752\n",
            "Iteration 4070, Loss: 1.6719410419464111\n",
            "Iteration 4080, Loss: 1.6226117610931396\n",
            "Iteration 4090, Loss: 1.494083046913147\n",
            "Iteration 4100, Loss: 1.7237541675567627\n",
            "Iteration 4110, Loss: 1.6805366277694702\n",
            "Iteration 4120, Loss: 1.583162784576416\n",
            "Iteration 4130, Loss: 1.633269190788269\n",
            "Iteration 4140, Loss: 1.6453932523727417\n",
            "Iteration 4150, Loss: 1.693902850151062\n",
            "Iteration 4160, Loss: 1.6020852327346802\n",
            "Iteration 4170, Loss: 1.8187675476074219\n",
            "Iteration 4180, Loss: 1.8447846174240112\n",
            "Iteration 4190, Loss: 1.6832138299942017\n",
            "Iteration 4200, Loss: 1.7199591398239136\n",
            "Iteration 4200, Train Perplexity: 5.411125659942627, Validation Perplexity: 6.40945291519165\n",
            "Iteration 4210, Loss: 1.7049849033355713\n",
            "Iteration 4220, Loss: 1.6300228834152222\n",
            "Iteration 4230, Loss: 1.736236572265625\n",
            "Iteration 4240, Loss: 1.9085195064544678\n",
            "Iteration 4250, Loss: 1.6190760135650635\n",
            "Iteration 4260, Loss: 1.6114778518676758\n",
            "Iteration 4270, Loss: 1.6616342067718506\n",
            "Iteration 4280, Loss: 1.6666160821914673\n",
            "Iteration 4290, Loss: 1.7911827564239502\n",
            "Iteration 4300, Loss: 1.7887508869171143\n",
            "Iteration 4310, Loss: 1.729363203048706\n",
            "Iteration 4320, Loss: 1.6641548871994019\n",
            "Iteration 4330, Loss: 1.742781162261963\n",
            "Iteration 4340, Loss: 1.6740139722824097\n",
            "Iteration 4350, Loss: 1.5798594951629639\n",
            "Iteration 4360, Loss: 1.643809199333191\n",
            "Iteration 4370, Loss: 1.7826651334762573\n",
            "Iteration 4380, Loss: 1.657300591468811\n",
            "Iteration 4390, Loss: 1.7052117586135864\n",
            "Iteration 4400, Loss: 1.7973597049713135\n",
            "Iteration 4400, Train Perplexity: 5.46579647064209, Validation Perplexity: 6.349352836608887\n",
            "Iteration 4410, Loss: 1.6156516075134277\n",
            "Iteration 4420, Loss: 1.7512311935424805\n",
            "Iteration 4430, Loss: 1.7403851747512817\n",
            "Iteration 4440, Loss: 1.5889604091644287\n",
            "Iteration 4450, Loss: 1.6184048652648926\n",
            "Iteration 4460, Loss: 1.615637183189392\n",
            "Iteration 4470, Loss: 1.7403371334075928\n",
            "Iteration 4480, Loss: 1.6217316389083862\n",
            "Iteration 4490, Loss: 1.5957789421081543\n",
            "Iteration 4500, Loss: 1.635189175605774\n",
            "Iteration 4510, Loss: 1.6127694845199585\n",
            "Iteration 4520, Loss: 1.6508393287658691\n",
            "Iteration 4530, Loss: 1.7103986740112305\n",
            "Iteration 4540, Loss: 1.6715364456176758\n",
            "Iteration 4550, Loss: 1.8178930282592773\n",
            "Iteration 4560, Loss: 1.5500975847244263\n",
            "Iteration 4570, Loss: 1.6601775884628296\n",
            "Iteration 4580, Loss: 1.6681283712387085\n",
            "Iteration 4590, Loss: 1.5205683708190918\n",
            "Iteration 4600, Loss: 1.7714213132858276\n",
            "Iteration 4600, Train Perplexity: 5.409067153930664, Validation Perplexity: 6.291803359985352\n",
            "Iteration 4610, Loss: 1.6476548910140991\n",
            "Iteration 4620, Loss: 1.6500216722488403\n",
            "Iteration 4630, Loss: 1.601558804512024\n",
            "Iteration 4640, Loss: 1.56044340133667\n",
            "Iteration 4650, Loss: 1.6335803270339966\n",
            "Iteration 4660, Loss: 1.648187518119812\n",
            "Iteration 4670, Loss: 1.7231910228729248\n",
            "Iteration 4680, Loss: 1.6651020050048828\n",
            "Iteration 4690, Loss: 1.8339771032333374\n",
            "Iteration 4700, Loss: 1.7792434692382812\n",
            "Iteration 4710, Loss: 1.659429669380188\n",
            "Iteration 4720, Loss: 1.5786162614822388\n",
            "Iteration 4730, Loss: 1.5092847347259521\n",
            "Iteration 4740, Loss: 1.6624928712844849\n",
            "Iteration 4750, Loss: 1.6053903102874756\n",
            "Iteration 4760, Loss: 1.6498936414718628\n",
            "Iteration 4770, Loss: 1.5910321474075317\n",
            "Iteration 4780, Loss: 1.486863374710083\n",
            "Iteration 4790, Loss: 1.60027277469635\n",
            "Iteration 4800, Loss: 1.869115948677063\n",
            "Iteration 4800, Train Perplexity: 5.36179256439209, Validation Perplexity: 6.292377471923828\n",
            "Iteration 4810, Loss: 1.594679594039917\n",
            "Iteration 4820, Loss: 1.6994582414627075\n",
            "Iteration 4830, Loss: 1.807936668395996\n",
            "Iteration 4840, Loss: 1.6487632989883423\n",
            "Iteration 4850, Loss: 1.634513258934021\n",
            "Iteration 4860, Loss: 1.6973483562469482\n",
            "Iteration 4870, Loss: 1.546954870223999\n",
            "Iteration 4880, Loss: 1.6768828630447388\n",
            "Iteration 4890, Loss: 1.6349620819091797\n",
            "Iteration 4900, Loss: 1.6578541994094849\n",
            "Iteration 4910, Loss: 1.601592779159546\n",
            "Iteration 4920, Loss: 1.5827282667160034\n",
            "Iteration 4930, Loss: 1.5049375295639038\n",
            "Iteration 4940, Loss: 1.7553412914276123\n",
            "Iteration 4950, Loss: 1.751720905303955\n",
            "Iteration 4960, Loss: 1.617328405380249\n",
            "Iteration 4970, Loss: 1.548416256904602\n",
            "Iteration 4980, Loss: 1.6180706024169922\n",
            "Iteration 4990, Loss: 1.660585880279541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Perplexity', marker='o')\n",
        "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Perplexity', marker='x')\n",
        "plt.title('Perplexity over Training Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "GeGyLnKzgW9f",
        "outputId": "ff48bc25-9a14-4d6c-c974-55ff69bba6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before changing any of the parameters, my loss at Iteration 4990 is 1.66... which is not too bad! But when I change n_emb to 32, here's what happens:"
      ],
      "metadata": {
        "id": "Clxc6DLljUzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "n_embd = 32\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "model = LanguageModel().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    x, y = get_batch('train')\n",
        "\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if iteration % eval_interval == 0:\n",
        "        print(f\"Iteration {iteration}, Loss: {loss.item()}\")\n",
        "\n",
        "    if iteration % eval_iters == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_losses_dict = estimate_loss()\n",
        "            train_loss = val_losses_dict['train']\n",
        "            val_loss = val_losses_dict['val']\n",
        "\n",
        "            train_perplexity = torch.exp(torch.tensor(train_loss))\n",
        "            val_perplexity = torch.exp(torch.tensor(val_loss))\n",
        "\n",
        "            print(f\"Iteration {iteration}, Train Perplexity: {train_perplexity}, Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "            train_losses.append(train_perplexity)\n",
        "            val_losses.append(val_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KfvpP9KiyfT",
        "outputId": "d0eb13b0-b9c4-4749-aa5e-d340cdd9b77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.32530403137207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-ee64c8fd55eb>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss))\n",
            "<ipython-input-34-ee64c8fd55eb>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Train Perplexity: 69.31764221191406, Validation Perplexity: 68.49778747558594\n",
            "Iteration 10, Loss: 3.778050422668457\n",
            "Iteration 20, Loss: 3.545621633529663\n",
            "Iteration 30, Loss: 3.4726545810699463\n",
            "Iteration 40, Loss: 3.230602264404297\n",
            "Iteration 50, Loss: 3.2125587463378906\n",
            "Iteration 60, Loss: 3.179661273956299\n",
            "Iteration 70, Loss: 3.1532695293426514\n",
            "Iteration 80, Loss: 3.019929885864258\n",
            "Iteration 90, Loss: 3.061314821243286\n",
            "Iteration 100, Loss: 3.0616135597229004\n",
            "Iteration 110, Loss: 2.817584991455078\n",
            "Iteration 120, Loss: 2.852285385131836\n",
            "Iteration 130, Loss: 2.8200466632843018\n",
            "Iteration 140, Loss: 2.869016170501709\n",
            "Iteration 150, Loss: 2.769960880279541\n",
            "Iteration 160, Loss: 2.6772778034210205\n",
            "Iteration 170, Loss: 2.719855308532715\n",
            "Iteration 180, Loss: 2.6661484241485596\n",
            "Iteration 190, Loss: 2.6867988109588623\n",
            "Iteration 200, Loss: 2.7883992195129395\n",
            "Iteration 200, Train Perplexity: 14.447015762329102, Validation Perplexity: 14.701911926269531\n",
            "Iteration 210, Loss: 2.6779489517211914\n",
            "Iteration 220, Loss: 2.6092095375061035\n",
            "Iteration 230, Loss: 2.6481332778930664\n",
            "Iteration 240, Loss: 2.65218448638916\n",
            "Iteration 250, Loss: 2.5734786987304688\n",
            "Iteration 260, Loss: 2.6190123558044434\n",
            "Iteration 270, Loss: 2.515374183654785\n",
            "Iteration 280, Loss: 2.4860312938690186\n",
            "Iteration 290, Loss: 2.5324010848999023\n",
            "Iteration 300, Loss: 2.679105281829834\n",
            "Iteration 310, Loss: 2.5960452556610107\n",
            "Iteration 320, Loss: 2.7141425609588623\n",
            "Iteration 330, Loss: 2.5441551208496094\n",
            "Iteration 340, Loss: 2.4428765773773193\n",
            "Iteration 350, Loss: 2.569629430770874\n",
            "Iteration 360, Loss: 2.5475094318389893\n",
            "Iteration 370, Loss: 2.4427011013031006\n",
            "Iteration 380, Loss: 2.5261504650115967\n",
            "Iteration 390, Loss: 2.551527976989746\n",
            "Iteration 400, Loss: 2.579267740249634\n",
            "Iteration 400, Train Perplexity: 12.407380104064941, Validation Perplexity: 12.419952392578125\n",
            "Iteration 410, Loss: 2.517681121826172\n",
            "Iteration 420, Loss: 2.5071043968200684\n",
            "Iteration 430, Loss: 2.5380802154541016\n",
            "Iteration 440, Loss: 2.6136014461517334\n",
            "Iteration 450, Loss: 2.516876459121704\n",
            "Iteration 460, Loss: 2.518704891204834\n",
            "Iteration 470, Loss: 2.338660717010498\n",
            "Iteration 480, Loss: 2.467590570449829\n",
            "Iteration 490, Loss: 2.483940362930298\n",
            "Iteration 500, Loss: 2.571504592895508\n",
            "Iteration 510, Loss: 2.5403964519500732\n",
            "Iteration 520, Loss: 2.3796818256378174\n",
            "Iteration 530, Loss: 2.40051007270813\n",
            "Iteration 540, Loss: 2.518328905105591\n",
            "Iteration 550, Loss: 2.4824464321136475\n",
            "Iteration 560, Loss: 2.378408908843994\n",
            "Iteration 570, Loss: 2.554342269897461\n",
            "Iteration 580, Loss: 2.3571488857269287\n",
            "Iteration 590, Loss: 2.3294870853424072\n",
            "Iteration 600, Loss: 2.441931962966919\n",
            "Iteration 600, Train Perplexity: 11.285536766052246, Validation Perplexity: 11.454625129699707\n",
            "Iteration 610, Loss: 2.373727560043335\n",
            "Iteration 620, Loss: 2.3728201389312744\n",
            "Iteration 630, Loss: 2.5102405548095703\n",
            "Iteration 640, Loss: 2.4234585762023926\n",
            "Iteration 650, Loss: 2.499481678009033\n",
            "Iteration 660, Loss: 2.450052261352539\n",
            "Iteration 670, Loss: 2.4066720008850098\n",
            "Iteration 680, Loss: 2.5387070178985596\n",
            "Iteration 690, Loss: 2.457167148590088\n",
            "Iteration 700, Loss: 2.4379513263702393\n",
            "Iteration 710, Loss: 2.400496244430542\n",
            "Iteration 720, Loss: 2.5497958660125732\n",
            "Iteration 730, Loss: 2.3687713146209717\n",
            "Iteration 740, Loss: 2.3608648777008057\n",
            "Iteration 750, Loss: 2.3848626613616943\n",
            "Iteration 760, Loss: 2.3167104721069336\n",
            "Iteration 770, Loss: 2.417858600616455\n",
            "Iteration 780, Loss: 2.3926126956939697\n",
            "Iteration 790, Loss: 2.341902256011963\n",
            "Iteration 800, Loss: 2.3847551345825195\n",
            "Iteration 800, Train Perplexity: 10.723759651184082, Validation Perplexity: 10.769786834716797\n",
            "Iteration 810, Loss: 2.2542800903320312\n",
            "Iteration 820, Loss: 2.2705299854278564\n",
            "Iteration 830, Loss: 2.3672330379486084\n",
            "Iteration 840, Loss: 2.3614699840545654\n",
            "Iteration 850, Loss: 2.3395607471466064\n",
            "Iteration 860, Loss: 2.341785430908203\n",
            "Iteration 870, Loss: 2.479740619659424\n",
            "Iteration 880, Loss: 2.3482186794281006\n",
            "Iteration 890, Loss: 2.387338638305664\n",
            "Iteration 900, Loss: 2.3539512157440186\n",
            "Iteration 910, Loss: 2.3925118446350098\n",
            "Iteration 920, Loss: 2.294414758682251\n",
            "Iteration 930, Loss: 2.3057401180267334\n",
            "Iteration 940, Loss: 2.329817295074463\n",
            "Iteration 950, Loss: 2.2839365005493164\n",
            "Iteration 960, Loss: 2.3469977378845215\n",
            "Iteration 970, Loss: 2.2655115127563477\n",
            "Iteration 980, Loss: 2.410269260406494\n",
            "Iteration 990, Loss: 2.412118911743164\n",
            "Iteration 1000, Loss: 2.353239059448242\n",
            "Iteration 1000, Train Perplexity: 10.24017333984375, Validation Perplexity: 10.473640441894531\n",
            "Iteration 1010, Loss: 2.283149003982544\n",
            "Iteration 1020, Loss: 2.2707176208496094\n",
            "Iteration 1030, Loss: 2.322232246398926\n",
            "Iteration 1040, Loss: 2.3935985565185547\n",
            "Iteration 1050, Loss: 2.306175947189331\n",
            "Iteration 1060, Loss: 2.277837038040161\n",
            "Iteration 1070, Loss: 2.3564987182617188\n",
            "Iteration 1080, Loss: 2.3541994094848633\n",
            "Iteration 1090, Loss: 2.3354320526123047\n",
            "Iteration 1100, Loss: 2.2496650218963623\n",
            "Iteration 1110, Loss: 2.3017337322235107\n",
            "Iteration 1120, Loss: 2.34770131111145\n",
            "Iteration 1130, Loss: 2.208834648132324\n",
            "Iteration 1140, Loss: 2.3112375736236572\n",
            "Iteration 1150, Loss: 2.2944705486297607\n",
            "Iteration 1160, Loss: 2.232424736022949\n",
            "Iteration 1170, Loss: 2.276116371154785\n",
            "Iteration 1180, Loss: 2.2566230297088623\n",
            "Iteration 1190, Loss: 2.2446138858795166\n",
            "Iteration 1200, Loss: 2.3072617053985596\n",
            "Iteration 1200, Train Perplexity: 9.839982986450195, Validation Perplexity: 10.097713470458984\n",
            "Iteration 1210, Loss: 2.231764554977417\n",
            "Iteration 1220, Loss: 2.3095123767852783\n",
            "Iteration 1230, Loss: 2.1411314010620117\n",
            "Iteration 1240, Loss: 2.2370808124542236\n",
            "Iteration 1250, Loss: 2.1988108158111572\n",
            "Iteration 1260, Loss: 2.2938122749328613\n",
            "Iteration 1270, Loss: 2.237515926361084\n",
            "Iteration 1280, Loss: 2.247281789779663\n",
            "Iteration 1290, Loss: 2.2877962589263916\n",
            "Iteration 1300, Loss: 2.274893283843994\n",
            "Iteration 1310, Loss: 2.2652673721313477\n",
            "Iteration 1320, Loss: 2.2234737873077393\n",
            "Iteration 1330, Loss: 2.2475194931030273\n",
            "Iteration 1340, Loss: 2.2032477855682373\n",
            "Iteration 1350, Loss: 2.3134372234344482\n",
            "Iteration 1360, Loss: 2.3380141258239746\n",
            "Iteration 1370, Loss: 2.2620081901550293\n",
            "Iteration 1380, Loss: 2.2825334072113037\n",
            "Iteration 1390, Loss: 2.1864209175109863\n",
            "Iteration 1400, Loss: 2.3035671710968018\n",
            "Iteration 1400, Train Perplexity: 9.519189834594727, Validation Perplexity: 9.602982521057129\n",
            "Iteration 1410, Loss: 2.1432571411132812\n",
            "Iteration 1420, Loss: 2.2047462463378906\n",
            "Iteration 1430, Loss: 2.244659900665283\n",
            "Iteration 1440, Loss: 2.4246227741241455\n",
            "Iteration 1450, Loss: 2.276324987411499\n",
            "Iteration 1460, Loss: 2.2859644889831543\n",
            "Iteration 1470, Loss: 2.286137342453003\n",
            "Iteration 1480, Loss: 2.1543595790863037\n",
            "Iteration 1490, Loss: 2.177522659301758\n",
            "Iteration 1500, Loss: 2.162825345993042\n",
            "Iteration 1510, Loss: 2.2191131114959717\n",
            "Iteration 1520, Loss: 2.2023587226867676\n",
            "Iteration 1530, Loss: 2.2167270183563232\n",
            "Iteration 1540, Loss: 2.0837278366088867\n",
            "Iteration 1550, Loss: 2.1662819385528564\n",
            "Iteration 1560, Loss: 2.2036142349243164\n",
            "Iteration 1570, Loss: 2.124364137649536\n",
            "Iteration 1580, Loss: 2.212681770324707\n",
            "Iteration 1590, Loss: 2.224475860595703\n",
            "Iteration 1600, Loss: 2.129318952560425\n",
            "Iteration 1600, Train Perplexity: 9.226911544799805, Validation Perplexity: 9.507048606872559\n",
            "Iteration 1610, Loss: 2.1570141315460205\n",
            "Iteration 1620, Loss: 2.248006820678711\n",
            "Iteration 1630, Loss: 2.2115187644958496\n",
            "Iteration 1640, Loss: 2.151846170425415\n",
            "Iteration 1650, Loss: 2.2958250045776367\n",
            "Iteration 1660, Loss: 2.2356743812561035\n",
            "Iteration 1670, Loss: 2.2362546920776367\n",
            "Iteration 1680, Loss: 2.1804473400115967\n",
            "Iteration 1690, Loss: 2.158416986465454\n",
            "Iteration 1700, Loss: 2.179091453552246\n",
            "Iteration 1710, Loss: 2.3381683826446533\n",
            "Iteration 1720, Loss: 2.12339186668396\n",
            "Iteration 1730, Loss: 2.1567394733428955\n",
            "Iteration 1740, Loss: 2.2409121990203857\n",
            "Iteration 1750, Loss: 2.1855854988098145\n",
            "Iteration 1760, Loss: 2.215684652328491\n",
            "Iteration 1770, Loss: 2.1691925525665283\n",
            "Iteration 1780, Loss: 2.2480342388153076\n",
            "Iteration 1790, Loss: 2.205507278442383\n",
            "Iteration 1800, Loss: 2.1174283027648926\n",
            "Iteration 1800, Train Perplexity: 8.866875648498535, Validation Perplexity: 9.24901294708252\n",
            "Iteration 1810, Loss: 2.2901558876037598\n",
            "Iteration 1820, Loss: 2.205782651901245\n",
            "Iteration 1830, Loss: 2.20578932762146\n",
            "Iteration 1840, Loss: 2.2916932106018066\n",
            "Iteration 1850, Loss: 2.2618942260742188\n",
            "Iteration 1860, Loss: 2.1115939617156982\n",
            "Iteration 1870, Loss: 2.2143378257751465\n",
            "Iteration 1880, Loss: 2.1236982345581055\n",
            "Iteration 1890, Loss: 1.9969244003295898\n",
            "Iteration 1900, Loss: 2.1668500900268555\n",
            "Iteration 1910, Loss: 2.2677712440490723\n",
            "Iteration 1920, Loss: 2.205564498901367\n",
            "Iteration 1930, Loss: 2.2063651084899902\n",
            "Iteration 1940, Loss: 2.1653358936309814\n",
            "Iteration 1950, Loss: 2.2395424842834473\n",
            "Iteration 1960, Loss: 2.1434624195098877\n",
            "Iteration 1970, Loss: 2.1911351680755615\n",
            "Iteration 1980, Loss: 2.2911219596862793\n",
            "Iteration 1990, Loss: 2.134267807006836\n",
            "Iteration 2000, Loss: 2.127655267715454\n",
            "Iteration 2000, Train Perplexity: 8.576910972595215, Validation Perplexity: 8.927505493164062\n",
            "Iteration 2010, Loss: 2.0251998901367188\n",
            "Iteration 2020, Loss: 2.2383840084075928\n",
            "Iteration 2030, Loss: 2.1119017601013184\n",
            "Iteration 2040, Loss: 2.0363848209381104\n",
            "Iteration 2050, Loss: 2.2066776752471924\n",
            "Iteration 2060, Loss: 2.2080459594726562\n",
            "Iteration 2070, Loss: 2.0595152378082275\n",
            "Iteration 2080, Loss: 2.1373252868652344\n",
            "Iteration 2090, Loss: 2.207926034927368\n",
            "Iteration 2100, Loss: 2.088404893875122\n",
            "Iteration 2110, Loss: 2.13476824760437\n",
            "Iteration 2120, Loss: 2.141927480697632\n",
            "Iteration 2130, Loss: 2.0603013038635254\n",
            "Iteration 2140, Loss: 2.0958073139190674\n",
            "Iteration 2150, Loss: 2.1634178161621094\n",
            "Iteration 2160, Loss: 2.1135354042053223\n",
            "Iteration 2170, Loss: 2.006279945373535\n",
            "Iteration 2180, Loss: 2.1321113109588623\n",
            "Iteration 2190, Loss: 2.1484529972076416\n",
            "Iteration 2200, Loss: 2.115753412246704\n",
            "Iteration 2200, Train Perplexity: 8.400812149047852, Validation Perplexity: 8.770401954650879\n",
            "Iteration 2210, Loss: 2.0043420791625977\n",
            "Iteration 2220, Loss: 2.202268600463867\n",
            "Iteration 2230, Loss: 2.0963761806488037\n",
            "Iteration 2240, Loss: 2.147289514541626\n",
            "Iteration 2250, Loss: 2.224120616912842\n",
            "Iteration 2260, Loss: 2.1155428886413574\n",
            "Iteration 2270, Loss: 2.069654703140259\n",
            "Iteration 2280, Loss: 2.189614772796631\n",
            "Iteration 2290, Loss: 2.172477960586548\n",
            "Iteration 2300, Loss: 2.2122089862823486\n",
            "Iteration 2310, Loss: 2.090491533279419\n",
            "Iteration 2320, Loss: 2.170017957687378\n",
            "Iteration 2330, Loss: 2.0865893363952637\n",
            "Iteration 2340, Loss: 2.170289993286133\n",
            "Iteration 2350, Loss: 2.0959813594818115\n",
            "Iteration 2360, Loss: 2.0552351474761963\n",
            "Iteration 2370, Loss: 2.1432888507843018\n",
            "Iteration 2380, Loss: 2.1673693656921387\n",
            "Iteration 2390, Loss: 2.045544385910034\n",
            "Iteration 2400, Loss: 2.110940456390381\n",
            "Iteration 2400, Train Perplexity: 8.088907241821289, Validation Perplexity: 8.642827033996582\n",
            "Iteration 2410, Loss: 2.1354856491088867\n",
            "Iteration 2420, Loss: 2.140958786010742\n",
            "Iteration 2430, Loss: 2.0781590938568115\n",
            "Iteration 2440, Loss: 2.011240243911743\n",
            "Iteration 2450, Loss: 2.084763765335083\n",
            "Iteration 2460, Loss: 2.135732889175415\n",
            "Iteration 2470, Loss: 2.0386879444122314\n",
            "Iteration 2480, Loss: 2.146530866622925\n",
            "Iteration 2490, Loss: 2.0953447818756104\n",
            "Iteration 2500, Loss: 2.16555118560791\n",
            "Iteration 2510, Loss: 2.0680301189422607\n",
            "Iteration 2520, Loss: 2.0519981384277344\n",
            "Iteration 2530, Loss: 2.1937267780303955\n",
            "Iteration 2540, Loss: 2.137657642364502\n",
            "Iteration 2550, Loss: 2.0453293323516846\n",
            "Iteration 2560, Loss: 1.9954440593719482\n",
            "Iteration 2570, Loss: 2.1759109497070312\n",
            "Iteration 2580, Loss: 2.1020615100860596\n",
            "Iteration 2590, Loss: 2.2276980876922607\n",
            "Iteration 2600, Loss: 2.185396909713745\n",
            "Iteration 2600, Train Perplexity: 7.970578193664551, Validation Perplexity: 8.36959457397461\n",
            "Iteration 2610, Loss: 2.003237247467041\n",
            "Iteration 2620, Loss: 2.102527379989624\n",
            "Iteration 2630, Loss: 2.159930467605591\n",
            "Iteration 2640, Loss: 2.125515937805176\n",
            "Iteration 2650, Loss: 2.072134017944336\n",
            "Iteration 2660, Loss: 2.074496269226074\n",
            "Iteration 2670, Loss: 2.0784828662872314\n",
            "Iteration 2680, Loss: 2.0417542457580566\n",
            "Iteration 2690, Loss: 2.2043261528015137\n",
            "Iteration 2700, Loss: 2.0911543369293213\n",
            "Iteration 2710, Loss: 2.051734209060669\n",
            "Iteration 2720, Loss: 1.915129542350769\n",
            "Iteration 2730, Loss: 2.1243510246276855\n",
            "Iteration 2740, Loss: 2.064074993133545\n",
            "Iteration 2750, Loss: 2.1104483604431152\n",
            "Iteration 2760, Loss: 2.0853512287139893\n",
            "Iteration 2770, Loss: 2.015974760055542\n",
            "Iteration 2780, Loss: 2.1627299785614014\n",
            "Iteration 2790, Loss: 2.0825695991516113\n",
            "Iteration 2800, Loss: 2.0552890300750732\n",
            "Iteration 2800, Train Perplexity: 7.760201930999756, Validation Perplexity: 8.275784492492676\n",
            "Iteration 2810, Loss: 2.124711275100708\n",
            "Iteration 2820, Loss: 2.0518689155578613\n",
            "Iteration 2830, Loss: 2.090773105621338\n",
            "Iteration 2840, Loss: 2.0080416202545166\n",
            "Iteration 2850, Loss: 2.1093108654022217\n",
            "Iteration 2860, Loss: 1.960108995437622\n",
            "Iteration 2870, Loss: 2.0362324714660645\n",
            "Iteration 2880, Loss: 2.096909761428833\n",
            "Iteration 2890, Loss: 2.0537431240081787\n",
            "Iteration 2900, Loss: 2.0845282077789307\n",
            "Iteration 2910, Loss: 1.9239161014556885\n",
            "Iteration 2920, Loss: 2.0935893058776855\n",
            "Iteration 2930, Loss: 2.047523260116577\n",
            "Iteration 2940, Loss: 2.0632216930389404\n",
            "Iteration 2950, Loss: 2.0405080318450928\n",
            "Iteration 2960, Loss: 1.9384582042694092\n",
            "Iteration 2970, Loss: 1.9979088306427002\n",
            "Iteration 2980, Loss: 2.002112627029419\n",
            "Iteration 2990, Loss: 2.10131573677063\n",
            "Iteration 3000, Loss: 1.9701924324035645\n",
            "Iteration 3000, Train Perplexity: 7.734014511108398, Validation Perplexity: 8.255413055419922\n",
            "Iteration 3010, Loss: 2.041111469268799\n",
            "Iteration 3020, Loss: 1.9935415983200073\n",
            "Iteration 3030, Loss: 2.049372911453247\n",
            "Iteration 3040, Loss: 1.889214277267456\n",
            "Iteration 3050, Loss: 1.9741023778915405\n",
            "Iteration 3060, Loss: 1.9973641633987427\n",
            "Iteration 3070, Loss: 2.0555312633514404\n",
            "Iteration 3080, Loss: 2.0688180923461914\n",
            "Iteration 3090, Loss: 1.973578929901123\n",
            "Iteration 3100, Loss: 2.0918688774108887\n",
            "Iteration 3110, Loss: 1.9555268287658691\n",
            "Iteration 3120, Loss: 1.8824970722198486\n",
            "Iteration 3130, Loss: 2.0708060264587402\n",
            "Iteration 3140, Loss: 2.0254642963409424\n",
            "Iteration 3150, Loss: 2.0533387660980225\n",
            "Iteration 3160, Loss: 1.976763129234314\n",
            "Iteration 3170, Loss: 2.09252667427063\n",
            "Iteration 3180, Loss: 2.089244842529297\n",
            "Iteration 3190, Loss: 2.044881820678711\n",
            "Iteration 3200, Loss: 2.085799217224121\n",
            "Iteration 3200, Train Perplexity: 7.577672481536865, Validation Perplexity: 8.012690544128418\n",
            "Iteration 3210, Loss: 2.079301118850708\n",
            "Iteration 3220, Loss: 2.0618739128112793\n",
            "Iteration 3230, Loss: 2.047215700149536\n",
            "Iteration 3240, Loss: 1.8950012922286987\n",
            "Iteration 3250, Loss: 2.0796029567718506\n",
            "Iteration 3260, Loss: 2.111392021179199\n",
            "Iteration 3270, Loss: 2.1972098350524902\n",
            "Iteration 3280, Loss: 2.11575984954834\n",
            "Iteration 3290, Loss: 1.986735224723816\n",
            "Iteration 3300, Loss: 1.9862321615219116\n",
            "Iteration 3310, Loss: 1.9339157342910767\n",
            "Iteration 3320, Loss: 1.9854387044906616\n",
            "Iteration 3330, Loss: 2.0835587978363037\n",
            "Iteration 3340, Loss: 1.983497977256775\n",
            "Iteration 3350, Loss: 2.1686370372772217\n",
            "Iteration 3360, Loss: 2.0003671646118164\n",
            "Iteration 3370, Loss: 1.877164602279663\n",
            "Iteration 3380, Loss: 1.9990147352218628\n",
            "Iteration 3390, Loss: 2.1162936687469482\n",
            "Iteration 3400, Loss: 2.0113422870635986\n",
            "Iteration 3400, Train Perplexity: 7.438817977905273, Validation Perplexity: 8.021037101745605\n",
            "Iteration 3410, Loss: 2.0141241550445557\n",
            "Iteration 3420, Loss: 2.055657148361206\n",
            "Iteration 3430, Loss: 1.849137783050537\n",
            "Iteration 3440, Loss: 1.9969054460525513\n",
            "Iteration 3450, Loss: 2.0044851303100586\n",
            "Iteration 3460, Loss: 1.9937127828598022\n",
            "Iteration 3470, Loss: 2.0019335746765137\n",
            "Iteration 3480, Loss: 1.8901841640472412\n",
            "Iteration 3490, Loss: 1.9874591827392578\n",
            "Iteration 3500, Loss: 2.0828657150268555\n",
            "Iteration 3510, Loss: 1.9678837060928345\n",
            "Iteration 3520, Loss: 2.0910704135894775\n",
            "Iteration 3530, Loss: 1.928619146347046\n",
            "Iteration 3540, Loss: 1.9938764572143555\n",
            "Iteration 3550, Loss: 1.9335978031158447\n",
            "Iteration 3560, Loss: 1.9605381488800049\n",
            "Iteration 3570, Loss: 2.0003280639648438\n",
            "Iteration 3580, Loss: 1.9921082258224487\n",
            "Iteration 3590, Loss: 1.9648412466049194\n",
            "Iteration 3600, Loss: 2.065727472305298\n",
            "Iteration 3600, Train Perplexity: 7.337560653686523, Validation Perplexity: 7.913054466247559\n",
            "Iteration 3610, Loss: 1.9367704391479492\n",
            "Iteration 3620, Loss: 1.9355559349060059\n",
            "Iteration 3630, Loss: 1.9269778728485107\n",
            "Iteration 3640, Loss: 2.0675711631774902\n",
            "Iteration 3650, Loss: 1.9721734523773193\n",
            "Iteration 3660, Loss: 1.9548938274383545\n",
            "Iteration 3670, Loss: 2.0234696865081787\n",
            "Iteration 3680, Loss: 2.004474401473999\n",
            "Iteration 3690, Loss: 2.0241222381591797\n",
            "Iteration 3700, Loss: 1.9829362630844116\n",
            "Iteration 3710, Loss: 1.8718807697296143\n",
            "Iteration 3720, Loss: 1.9973348379135132\n",
            "Iteration 3730, Loss: 1.9427250623703003\n",
            "Iteration 3740, Loss: 1.88785982131958\n",
            "Iteration 3750, Loss: 1.8888806104660034\n",
            "Iteration 3760, Loss: 1.9764516353607178\n",
            "Iteration 3770, Loss: 1.9399391412734985\n",
            "Iteration 3780, Loss: 1.999572992324829\n",
            "Iteration 3790, Loss: 1.9472650289535522\n",
            "Iteration 3800, Loss: 1.9896888732910156\n",
            "Iteration 3800, Train Perplexity: 7.175480842590332, Validation Perplexity: 7.813286781311035\n",
            "Iteration 3810, Loss: 2.1768860816955566\n",
            "Iteration 3820, Loss: 1.9417552947998047\n",
            "Iteration 3830, Loss: 1.8999416828155518\n",
            "Iteration 3840, Loss: 1.8461527824401855\n",
            "Iteration 3850, Loss: 1.873561978340149\n",
            "Iteration 3860, Loss: 1.8701279163360596\n",
            "Iteration 3870, Loss: 1.9671564102172852\n",
            "Iteration 3880, Loss: 1.908408761024475\n",
            "Iteration 3890, Loss: 2.0683417320251465\n",
            "Iteration 3900, Loss: 1.9050228595733643\n",
            "Iteration 3910, Loss: 2.0077366828918457\n",
            "Iteration 3920, Loss: 1.89165198802948\n",
            "Iteration 3930, Loss: 2.0427091121673584\n",
            "Iteration 3940, Loss: 1.8792636394500732\n",
            "Iteration 3950, Loss: 1.9666436910629272\n",
            "Iteration 3960, Loss: 1.9916086196899414\n",
            "Iteration 3970, Loss: 2.0224251747131348\n",
            "Iteration 3980, Loss: 1.904062032699585\n",
            "Iteration 3990, Loss: 1.9379856586456299\n",
            "Iteration 4000, Loss: 1.9403882026672363\n",
            "Iteration 4000, Train Perplexity: 7.125513553619385, Validation Perplexity: 7.834167003631592\n",
            "Iteration 4010, Loss: 1.8822641372680664\n",
            "Iteration 4020, Loss: 1.9599753618240356\n",
            "Iteration 4030, Loss: 2.0211732387542725\n",
            "Iteration 4040, Loss: 1.8543399572372437\n",
            "Iteration 4050, Loss: 1.9084877967834473\n",
            "Iteration 4060, Loss: 1.8535407781600952\n",
            "Iteration 4070, Loss: 1.950356364250183\n",
            "Iteration 4080, Loss: 2.0581512451171875\n",
            "Iteration 4090, Loss: 1.9496817588806152\n",
            "Iteration 4100, Loss: 2.004794120788574\n",
            "Iteration 4110, Loss: 1.9514726400375366\n",
            "Iteration 4120, Loss: 1.9327925443649292\n",
            "Iteration 4130, Loss: 1.950222373008728\n",
            "Iteration 4140, Loss: 2.0847365856170654\n",
            "Iteration 4150, Loss: 2.0424327850341797\n",
            "Iteration 4160, Loss: 1.9111305475234985\n",
            "Iteration 4170, Loss: 1.8642377853393555\n",
            "Iteration 4180, Loss: 1.805911660194397\n",
            "Iteration 4190, Loss: 1.9754438400268555\n",
            "Iteration 4200, Loss: 1.9554980993270874\n",
            "Iteration 4200, Train Perplexity: 6.9785051345825195, Validation Perplexity: 7.654703140258789\n",
            "Iteration 4210, Loss: 1.9533191919326782\n",
            "Iteration 4220, Loss: 2.1178598403930664\n",
            "Iteration 4230, Loss: 2.014310359954834\n",
            "Iteration 4240, Loss: 1.99345064163208\n",
            "Iteration 4250, Loss: 1.9681280851364136\n",
            "Iteration 4260, Loss: 1.8371177911758423\n",
            "Iteration 4270, Loss: 2.080488681793213\n",
            "Iteration 4280, Loss: 1.9173829555511475\n",
            "Iteration 4290, Loss: 1.8483773469924927\n",
            "Iteration 4300, Loss: 1.896769642829895\n",
            "Iteration 4310, Loss: 2.0158839225769043\n",
            "Iteration 4320, Loss: 1.7662570476531982\n",
            "Iteration 4330, Loss: 1.8335542678833008\n",
            "Iteration 4340, Loss: 1.9711943864822388\n",
            "Iteration 4350, Loss: 1.9655766487121582\n",
            "Iteration 4360, Loss: 1.8513567447662354\n",
            "Iteration 4370, Loss: 1.959704041481018\n",
            "Iteration 4380, Loss: 1.9240520000457764\n",
            "Iteration 4390, Loss: 2.0884923934936523\n",
            "Iteration 4400, Loss: 2.0188114643096924\n",
            "Iteration 4400, Train Perplexity: 6.892899513244629, Validation Perplexity: 7.644858360290527\n",
            "Iteration 4410, Loss: 1.9941442012786865\n",
            "Iteration 4420, Loss: 1.7541199922561646\n",
            "Iteration 4430, Loss: 1.9557355642318726\n",
            "Iteration 4440, Loss: 1.9079856872558594\n",
            "Iteration 4450, Loss: 1.8369706869125366\n",
            "Iteration 4460, Loss: 1.935606598854065\n",
            "Iteration 4470, Loss: 1.99923837184906\n",
            "Iteration 4480, Loss: 1.8310143947601318\n",
            "Iteration 4490, Loss: 1.7802852392196655\n",
            "Iteration 4500, Loss: 1.870131254196167\n",
            "Iteration 4510, Loss: 1.7642557621002197\n",
            "Iteration 4520, Loss: 2.0362906455993652\n",
            "Iteration 4530, Loss: 1.8735156059265137\n",
            "Iteration 4540, Loss: 2.0543925762176514\n",
            "Iteration 4550, Loss: 1.9883416891098022\n",
            "Iteration 4560, Loss: 2.0324370861053467\n",
            "Iteration 4570, Loss: 1.9150584936141968\n",
            "Iteration 4580, Loss: 1.9614503383636475\n",
            "Iteration 4590, Loss: 2.0053257942199707\n",
            "Iteration 4600, Loss: 1.8028528690338135\n",
            "Iteration 4600, Train Perplexity: 6.850231170654297, Validation Perplexity: 7.659313201904297\n",
            "Iteration 4610, Loss: 1.9577769041061401\n",
            "Iteration 4620, Loss: 1.9506837129592896\n",
            "Iteration 4630, Loss: 1.867356300354004\n",
            "Iteration 4640, Loss: 1.8675459623336792\n",
            "Iteration 4650, Loss: 1.878818154335022\n",
            "Iteration 4660, Loss: 1.8738746643066406\n",
            "Iteration 4670, Loss: 1.9609804153442383\n",
            "Iteration 4680, Loss: 1.9847400188446045\n",
            "Iteration 4690, Loss: 1.9670889377593994\n",
            "Iteration 4700, Loss: 2.000626564025879\n",
            "Iteration 4710, Loss: 1.8902888298034668\n",
            "Iteration 4720, Loss: 1.915370225906372\n",
            "Iteration 4730, Loss: 2.010085105895996\n",
            "Iteration 4740, Loss: 1.797083854675293\n",
            "Iteration 4750, Loss: 1.871497631072998\n",
            "Iteration 4760, Loss: 1.911333680152893\n",
            "Iteration 4770, Loss: 1.996935486793518\n",
            "Iteration 4780, Loss: 2.0425381660461426\n",
            "Iteration 4790, Loss: 1.8881808519363403\n",
            "Iteration 4800, Loss: 1.829842209815979\n",
            "Iteration 4800, Train Perplexity: 6.7889323234558105, Validation Perplexity: 7.637115955352783\n",
            "Iteration 4810, Loss: 1.8891850709915161\n",
            "Iteration 4820, Loss: 1.891710638999939\n",
            "Iteration 4830, Loss: 1.8939980268478394\n",
            "Iteration 4840, Loss: 1.8470815420150757\n",
            "Iteration 4850, Loss: 1.972984790802002\n",
            "Iteration 4860, Loss: 1.9372265338897705\n",
            "Iteration 4870, Loss: 1.9598016738891602\n",
            "Iteration 4880, Loss: 1.9678915739059448\n",
            "Iteration 4890, Loss: 1.9717572927474976\n",
            "Iteration 4900, Loss: 1.9339793920516968\n",
            "Iteration 4910, Loss: 1.903182029724121\n",
            "Iteration 4920, Loss: 1.8169243335723877\n",
            "Iteration 4930, Loss: 1.9430081844329834\n",
            "Iteration 4940, Loss: 1.8578500747680664\n",
            "Iteration 4950, Loss: 1.8499751091003418\n",
            "Iteration 4960, Loss: 1.9350241422653198\n",
            "Iteration 4970, Loss: 1.9409136772155762\n",
            "Iteration 4980, Loss: 1.9108010530471802\n",
            "Iteration 4990, Loss: 1.9290494918823242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Perplexity', marker='o')\n",
        "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Perplexity', marker='x')\n",
        "plt.title('Perplexity over Training Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "MzY1IxCfjHpW",
        "outputId": "b26b5546-7be0-44a1-a9b4-a290f8007111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the loss falls at a slower rate, and overall is  higher than it was with a higher n_embd value...but I wouldn't say a loss of 1.9 is astronomically higher. It's evident by the amount of fluctuation across iteration steps, as well as the very minor decrease in perplexity that the model is not exhibiting a lot of confidence. It is definitely less confident than when nemb = 64. And this makes sense, because as we raise the number of embeddings, the model learns a richer set of representations. If our dataset was super small, then it would be pretty important to have a relatively smaller number of embeddings, because we would want to avoid overfitting. However, I don't think the change to 32 is quite enough to make a major difference, especially with the size of our dataset.\n"
      ],
      "metadata": {
        "id": "BWychihygXh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we return nemb back to 64 (because it was better :)) and change the number of attention heads to 8, this is the result:"
      ],
      "metadata": {
        "id": "Vd8PqlwWliKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "n_embd = 64\n",
        "n_head = 8 ## so head_size = 16\n",
        "n_layer = 4\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "model = LanguageModel().to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    x, y = get_batch('train')\n",
        "\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if iteration % eval_interval == 0:\n",
        "        print(f\"Iteration {iteration}, Loss: {loss.item()}\")\n",
        "\n",
        "    if iteration % eval_iters == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_losses_dict = estimate_loss()\n",
        "            train_loss = val_losses_dict['train']\n",
        "            val_loss = val_losses_dict['val']\n",
        "\n",
        "            train_perplexity = torch.exp(torch.tensor(train_loss))\n",
        "            val_perplexity = torch.exp(torch.tensor(val_loss))\n",
        "\n",
        "\n",
        "            print(f\"Iteration {iteration}, Train Perplexity: {train_perplexity}, Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "\n",
        "            train_losses.append(train_perplexity)\n",
        "            val_losses.append(val_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o3XAFrilRB0",
        "outputId": "0d4c5f07-e270-49e9-a8f1-bf7651eccd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.2976250648498535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-aa284c825da0>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss))\n",
            "<ipython-input-37-aa284c825da0>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Train Perplexity: 63.45515441894531, Validation Perplexity: 63.773685455322266\n",
            "Iteration 10, Loss: 3.491778612136841\n",
            "Iteration 20, Loss: 3.247375965118408\n",
            "Iteration 30, Loss: 3.1719677448272705\n",
            "Iteration 40, Loss: 2.927828311920166\n",
            "Iteration 50, Loss: 2.8484935760498047\n",
            "Iteration 60, Loss: 2.7860679626464844\n",
            "Iteration 70, Loss: 2.64005184173584\n",
            "Iteration 80, Loss: 2.770197868347168\n",
            "Iteration 90, Loss: 2.7008962631225586\n",
            "Iteration 100, Loss: 2.5564165115356445\n",
            "Iteration 110, Loss: 2.5048985481262207\n",
            "Iteration 120, Loss: 2.5680642127990723\n",
            "Iteration 130, Loss: 2.6981163024902344\n",
            "Iteration 140, Loss: 2.6500449180603027\n",
            "Iteration 150, Loss: 2.6021525859832764\n",
            "Iteration 160, Loss: 2.5535573959350586\n",
            "Iteration 170, Loss: 2.528975486755371\n",
            "Iteration 180, Loss: 2.550412654876709\n",
            "Iteration 190, Loss: 2.4979794025421143\n",
            "Iteration 200, Loss: 2.4807660579681396\n",
            "Iteration 200, Train Perplexity: 12.200849533081055, Validation Perplexity: 12.241522789001465\n",
            "Iteration 210, Loss: 2.4034297466278076\n",
            "Iteration 220, Loss: 2.4522714614868164\n",
            "Iteration 230, Loss: 2.414801836013794\n",
            "Iteration 240, Loss: 2.505599021911621\n",
            "Iteration 250, Loss: 2.443885564804077\n",
            "Iteration 260, Loss: 2.3524279594421387\n",
            "Iteration 270, Loss: 2.541778087615967\n",
            "Iteration 280, Loss: 2.4548697471618652\n",
            "Iteration 290, Loss: 2.387523651123047\n",
            "Iteration 300, Loss: 2.40325665473938\n",
            "Iteration 310, Loss: 2.585049629211426\n",
            "Iteration 320, Loss: 2.5052924156188965\n",
            "Iteration 330, Loss: 2.3506662845611572\n",
            "Iteration 340, Loss: 2.412233591079712\n",
            "Iteration 350, Loss: 2.5239458084106445\n",
            "Iteration 360, Loss: 2.4255170822143555\n",
            "Iteration 370, Loss: 2.4686295986175537\n",
            "Iteration 380, Loss: 2.3746438026428223\n",
            "Iteration 390, Loss: 2.411132335662842\n",
            "Iteration 400, Loss: 2.3982982635498047\n",
            "Iteration 400, Train Perplexity: 10.662809371948242, Validation Perplexity: 10.726492881774902\n",
            "Iteration 410, Loss: 2.337280750274658\n",
            "Iteration 420, Loss: 2.3611690998077393\n",
            "Iteration 430, Loss: 2.391843557357788\n",
            "Iteration 440, Loss: 2.3311767578125\n",
            "Iteration 450, Loss: 2.210400342941284\n",
            "Iteration 460, Loss: 2.263573408126831\n",
            "Iteration 470, Loss: 2.281013250350952\n",
            "Iteration 480, Loss: 2.3122739791870117\n",
            "Iteration 490, Loss: 2.322441577911377\n",
            "Iteration 500, Loss: 2.3252527713775635\n",
            "Iteration 510, Loss: 2.280529499053955\n",
            "Iteration 520, Loss: 2.348862886428833\n",
            "Iteration 530, Loss: 2.2263343334198\n",
            "Iteration 540, Loss: 2.275144577026367\n",
            "Iteration 550, Loss: 2.287930965423584\n",
            "Iteration 560, Loss: 2.2813665866851807\n",
            "Iteration 570, Loss: 2.3055477142333984\n",
            "Iteration 580, Loss: 2.2993714809417725\n",
            "Iteration 590, Loss: 2.29115629196167\n",
            "Iteration 600, Loss: 2.2368154525756836\n",
            "Iteration 600, Train Perplexity: 9.839515686035156, Validation Perplexity: 9.920743942260742\n",
            "Iteration 610, Loss: 2.198399782180786\n",
            "Iteration 620, Loss: 2.31703782081604\n",
            "Iteration 630, Loss: 2.242292642593384\n",
            "Iteration 640, Loss: 2.1970081329345703\n",
            "Iteration 650, Loss: 2.197585344314575\n",
            "Iteration 660, Loss: 2.3400685787200928\n",
            "Iteration 670, Loss: 2.158541679382324\n",
            "Iteration 680, Loss: 2.4188780784606934\n",
            "Iteration 690, Loss: 2.2314915657043457\n",
            "Iteration 700, Loss: 2.2076919078826904\n",
            "Iteration 710, Loss: 2.232722043991089\n",
            "Iteration 720, Loss: 2.1261136531829834\n",
            "Iteration 730, Loss: 2.251566171646118\n",
            "Iteration 740, Loss: 2.3854992389678955\n",
            "Iteration 750, Loss: 2.242426633834839\n",
            "Iteration 760, Loss: 2.1258111000061035\n",
            "Iteration 770, Loss: 2.2817904949188232\n",
            "Iteration 780, Loss: 2.1983559131622314\n",
            "Iteration 790, Loss: 2.1475119590759277\n",
            "Iteration 800, Loss: 2.143284320831299\n",
            "Iteration 800, Train Perplexity: 9.167487144470215, Validation Perplexity: 9.37105655670166\n",
            "Iteration 810, Loss: 2.14229416847229\n",
            "Iteration 820, Loss: 2.3122713565826416\n",
            "Iteration 830, Loss: 2.159965753555298\n",
            "Iteration 840, Loss: 2.2668848037719727\n",
            "Iteration 850, Loss: 2.1395814418792725\n",
            "Iteration 860, Loss: 2.1510543823242188\n",
            "Iteration 870, Loss: 2.2481043338775635\n",
            "Iteration 880, Loss: 2.1686081886291504\n",
            "Iteration 890, Loss: 2.143411636352539\n",
            "Iteration 900, Loss: 2.1788361072540283\n",
            "Iteration 910, Loss: 2.2090132236480713\n",
            "Iteration 920, Loss: 2.224031448364258\n",
            "Iteration 930, Loss: 2.208315372467041\n",
            "Iteration 940, Loss: 2.198347568511963\n",
            "Iteration 950, Loss: 2.213423490524292\n",
            "Iteration 960, Loss: 2.091519832611084\n",
            "Iteration 970, Loss: 2.050806760787964\n",
            "Iteration 980, Loss: 2.114572048187256\n",
            "Iteration 990, Loss: 2.1729462146759033\n",
            "Iteration 1000, Loss: 2.1490848064422607\n",
            "Iteration 1000, Train Perplexity: 8.537989616394043, Validation Perplexity: 8.871468544006348\n",
            "Iteration 1010, Loss: 2.1519625186920166\n",
            "Iteration 1020, Loss: 2.242018222808838\n",
            "Iteration 1030, Loss: 2.0871880054473877\n",
            "Iteration 1040, Loss: 2.242215871810913\n",
            "Iteration 1050, Loss: 2.088125467300415\n",
            "Iteration 1060, Loss: 2.1681103706359863\n",
            "Iteration 1070, Loss: 2.0873539447784424\n",
            "Iteration 1080, Loss: 2.199634313583374\n",
            "Iteration 1090, Loss: 2.1013987064361572\n",
            "Iteration 1100, Loss: 2.103327512741089\n",
            "Iteration 1110, Loss: 2.206852674484253\n",
            "Iteration 1120, Loss: 2.19806170463562\n",
            "Iteration 1130, Loss: 2.0172016620635986\n",
            "Iteration 1140, Loss: 2.1380014419555664\n",
            "Iteration 1150, Loss: 2.122614622116089\n",
            "Iteration 1160, Loss: 2.020456552505493\n",
            "Iteration 1170, Loss: 2.005446195602417\n",
            "Iteration 1180, Loss: 2.116243362426758\n",
            "Iteration 1190, Loss: 2.0843868255615234\n",
            "Iteration 1200, Loss: 2.0792744159698486\n",
            "Iteration 1200, Train Perplexity: 8.026517868041992, Validation Perplexity: 8.318852424621582\n",
            "Iteration 1210, Loss: 2.296074151992798\n",
            "Iteration 1220, Loss: 2.15268611907959\n",
            "Iteration 1230, Loss: 2.065497636795044\n",
            "Iteration 1240, Loss: 2.034406900405884\n",
            "Iteration 1250, Loss: 2.0617516040802\n",
            "Iteration 1260, Loss: 2.0322582721710205\n",
            "Iteration 1270, Loss: 2.0787365436553955\n",
            "Iteration 1280, Loss: 2.1174657344818115\n",
            "Iteration 1290, Loss: 2.0264036655426025\n",
            "Iteration 1300, Loss: 2.121669054031372\n",
            "Iteration 1310, Loss: 2.0096659660339355\n",
            "Iteration 1320, Loss: 2.0957043170928955\n",
            "Iteration 1330, Loss: 2.000566244125366\n",
            "Iteration 1340, Loss: 2.0921976566314697\n",
            "Iteration 1350, Loss: 2.013256788253784\n",
            "Iteration 1360, Loss: 1.9089736938476562\n",
            "Iteration 1370, Loss: 1.9763295650482178\n",
            "Iteration 1380, Loss: 1.9540759325027466\n",
            "Iteration 1390, Loss: 1.9828495979309082\n",
            "Iteration 1400, Loss: 2.028873920440674\n",
            "Iteration 1400, Train Perplexity: 7.6053900718688965, Validation Perplexity: 8.019878387451172\n",
            "Iteration 1410, Loss: 2.055169105529785\n",
            "Iteration 1420, Loss: 2.0425002574920654\n",
            "Iteration 1430, Loss: 2.038881301879883\n",
            "Iteration 1440, Loss: 2.1627414226531982\n",
            "Iteration 1450, Loss: 2.0050365924835205\n",
            "Iteration 1460, Loss: 2.063124418258667\n",
            "Iteration 1470, Loss: 2.0913796424865723\n",
            "Iteration 1480, Loss: 2.003660202026367\n",
            "Iteration 1490, Loss: 1.9709874391555786\n",
            "Iteration 1500, Loss: 2.072481393814087\n",
            "Iteration 1510, Loss: 2.1011037826538086\n",
            "Iteration 1520, Loss: 2.030611753463745\n",
            "Iteration 1530, Loss: 1.993270993232727\n",
            "Iteration 1540, Loss: 2.019643545150757\n",
            "Iteration 1550, Loss: 2.0040338039398193\n",
            "Iteration 1560, Loss: 1.9943128824234009\n",
            "Iteration 1570, Loss: 2.012495756149292\n",
            "Iteration 1580, Loss: 2.004584312438965\n",
            "Iteration 1590, Loss: 2.009674549102783\n",
            "Iteration 1600, Loss: 2.0483899116516113\n",
            "Iteration 1600, Train Perplexity: 7.418810844421387, Validation Perplexity: 7.955258846282959\n",
            "Iteration 1610, Loss: 1.9564214944839478\n",
            "Iteration 1620, Loss: 1.9877959489822388\n",
            "Iteration 1630, Loss: 1.9323639869689941\n",
            "Iteration 1640, Loss: 2.0321028232574463\n",
            "Iteration 1650, Loss: 1.9901647567749023\n",
            "Iteration 1660, Loss: 1.912434697151184\n",
            "Iteration 1670, Loss: 1.9620591402053833\n",
            "Iteration 1680, Loss: 1.8520952463150024\n",
            "Iteration 1690, Loss: 1.997459053993225\n",
            "Iteration 1700, Loss: 1.9677999019622803\n",
            "Iteration 1710, Loss: 1.981661081314087\n",
            "Iteration 1720, Loss: 1.9612538814544678\n",
            "Iteration 1730, Loss: 2.0688834190368652\n",
            "Iteration 1740, Loss: 1.9735749959945679\n",
            "Iteration 1750, Loss: 2.0018413066864014\n",
            "Iteration 1760, Loss: 1.908098578453064\n",
            "Iteration 1770, Loss: 1.9815412759780884\n",
            "Iteration 1780, Loss: 1.9267630577087402\n",
            "Iteration 1790, Loss: 1.9189618825912476\n",
            "Iteration 1800, Loss: 1.974840760231018\n",
            "Iteration 1800, Train Perplexity: 7.121419906616211, Validation Perplexity: 7.706099987030029\n",
            "Iteration 1810, Loss: 1.9173915386199951\n",
            "Iteration 1820, Loss: 1.9458922147750854\n",
            "Iteration 1830, Loss: 1.935084581375122\n",
            "Iteration 1840, Loss: 2.0047318935394287\n",
            "Iteration 1850, Loss: 2.0812439918518066\n",
            "Iteration 1860, Loss: 1.9040148258209229\n",
            "Iteration 1870, Loss: 1.8926392793655396\n",
            "Iteration 1880, Loss: 1.9895436763763428\n",
            "Iteration 1890, Loss: 1.8906564712524414\n",
            "Iteration 1900, Loss: 1.8979169130325317\n",
            "Iteration 1910, Loss: 1.9581542015075684\n",
            "Iteration 1920, Loss: 1.9830366373062134\n",
            "Iteration 1930, Loss: 1.946544885635376\n",
            "Iteration 1940, Loss: 1.9076083898544312\n",
            "Iteration 1950, Loss: 1.9102269411087036\n",
            "Iteration 1960, Loss: 1.9077359437942505\n",
            "Iteration 1970, Loss: 1.9385567903518677\n",
            "Iteration 1980, Loss: 2.116060495376587\n",
            "Iteration 1990, Loss: 1.85797917842865\n",
            "Iteration 2000, Loss: 2.082803249359131\n",
            "Iteration 2000, Train Perplexity: 6.934573173522949, Validation Perplexity: 7.536003112792969\n",
            "Iteration 2010, Loss: 1.9023369550704956\n",
            "Iteration 2020, Loss: 1.840463638305664\n",
            "Iteration 2030, Loss: 1.9405430555343628\n",
            "Iteration 2040, Loss: 1.9862383604049683\n",
            "Iteration 2050, Loss: 1.9264132976531982\n",
            "Iteration 2060, Loss: 2.0392792224884033\n",
            "Iteration 2070, Loss: 1.9438087940216064\n",
            "Iteration 2080, Loss: 1.9686975479125977\n",
            "Iteration 2090, Loss: 1.8585565090179443\n",
            "Iteration 2100, Loss: 1.8657678365707397\n",
            "Iteration 2110, Loss: 2.015537738800049\n",
            "Iteration 2120, Loss: 1.8268629312515259\n",
            "Iteration 2130, Loss: 2.0326693058013916\n",
            "Iteration 2140, Loss: 1.8661458492279053\n",
            "Iteration 2150, Loss: 1.8881776332855225\n",
            "Iteration 2160, Loss: 1.811270833015442\n",
            "Iteration 2170, Loss: 1.8319400548934937\n",
            "Iteration 2180, Loss: 1.9843984842300415\n",
            "Iteration 2190, Loss: 1.856284260749817\n",
            "Iteration 2200, Loss: 1.9155769348144531\n",
            "Iteration 2200, Train Perplexity: 6.587825298309326, Validation Perplexity: 7.347644329071045\n",
            "Iteration 2210, Loss: 1.8844941854476929\n",
            "Iteration 2220, Loss: 1.8981143236160278\n",
            "Iteration 2230, Loss: 1.829464077949524\n",
            "Iteration 2240, Loss: 1.831909418106079\n",
            "Iteration 2250, Loss: 1.982557773590088\n",
            "Iteration 2260, Loss: 1.7770051956176758\n",
            "Iteration 2270, Loss: 1.8409650325775146\n",
            "Iteration 2280, Loss: 1.9300659894943237\n",
            "Iteration 2290, Loss: 1.8874505758285522\n",
            "Iteration 2300, Loss: 1.906140685081482\n",
            "Iteration 2310, Loss: 1.7782008647918701\n",
            "Iteration 2320, Loss: 1.7920340299606323\n",
            "Iteration 2330, Loss: 1.8018678426742554\n",
            "Iteration 2340, Loss: 1.795996069908142\n",
            "Iteration 2350, Loss: 1.8965591192245483\n",
            "Iteration 2360, Loss: 1.7906781435012817\n",
            "Iteration 2370, Loss: 1.929006576538086\n",
            "Iteration 2380, Loss: 1.9524786472320557\n",
            "Iteration 2390, Loss: 1.9584605693817139\n",
            "Iteration 2400, Loss: 1.9084163904190063\n",
            "Iteration 2400, Train Perplexity: 6.482895374298096, Validation Perplexity: 7.1653523445129395\n",
            "Iteration 2410, Loss: 1.8432974815368652\n",
            "Iteration 2420, Loss: 1.7113796472549438\n",
            "Iteration 2430, Loss: 1.9142186641693115\n",
            "Iteration 2440, Loss: 1.8752175569534302\n",
            "Iteration 2450, Loss: 1.832376480102539\n",
            "Iteration 2460, Loss: 1.8956016302108765\n",
            "Iteration 2470, Loss: 1.8509056568145752\n",
            "Iteration 2480, Loss: 1.8720167875289917\n",
            "Iteration 2490, Loss: 1.813850998878479\n",
            "Iteration 2500, Loss: 1.9188023805618286\n",
            "Iteration 2510, Loss: 1.9656645059585571\n",
            "Iteration 2520, Loss: 1.7724955081939697\n",
            "Iteration 2530, Loss: 1.8175253868103027\n",
            "Iteration 2540, Loss: 1.9537063837051392\n",
            "Iteration 2550, Loss: 1.912002682685852\n",
            "Iteration 2560, Loss: 1.799003005027771\n",
            "Iteration 2570, Loss: 1.6876311302185059\n",
            "Iteration 2580, Loss: 1.8167041540145874\n",
            "Iteration 2590, Loss: 1.9266690015792847\n",
            "Iteration 2600, Loss: 1.9143873453140259\n",
            "Iteration 2600, Train Perplexity: 6.328699588775635, Validation Perplexity: 7.104011535644531\n",
            "Iteration 2610, Loss: 1.892462968826294\n",
            "Iteration 2620, Loss: 1.7392412424087524\n",
            "Iteration 2630, Loss: 1.6717299222946167\n",
            "Iteration 2640, Loss: 1.9200336933135986\n",
            "Iteration 2650, Loss: 1.883502721786499\n",
            "Iteration 2660, Loss: 1.7549594640731812\n",
            "Iteration 2670, Loss: 1.8851770162582397\n",
            "Iteration 2680, Loss: 1.6848070621490479\n",
            "Iteration 2690, Loss: 1.8932431936264038\n",
            "Iteration 2700, Loss: 1.8602643013000488\n",
            "Iteration 2710, Loss: 1.8208259344100952\n",
            "Iteration 2720, Loss: 1.7719687223434448\n",
            "Iteration 2730, Loss: 1.8360744714736938\n",
            "Iteration 2740, Loss: 1.881814956665039\n",
            "Iteration 2750, Loss: 1.7773774862289429\n",
            "Iteration 2760, Loss: 1.8461490869522095\n",
            "Iteration 2770, Loss: 1.961205005645752\n",
            "Iteration 2780, Loss: 1.908929467201233\n",
            "Iteration 2790, Loss: 1.7754639387130737\n",
            "Iteration 2800, Loss: 1.7963773012161255\n",
            "Iteration 2800, Train Perplexity: 6.144081115722656, Validation Perplexity: 6.996953010559082\n",
            "Iteration 2810, Loss: 1.8280909061431885\n",
            "Iteration 2820, Loss: 1.9642250537872314\n",
            "Iteration 2830, Loss: 1.824050784111023\n",
            "Iteration 2840, Loss: 1.8512966632843018\n",
            "Iteration 2850, Loss: 1.7781596183776855\n",
            "Iteration 2860, Loss: 1.7509639263153076\n",
            "Iteration 2870, Loss: 1.851523995399475\n",
            "Iteration 2880, Loss: 1.8920143842697144\n",
            "Iteration 2890, Loss: 1.768471360206604\n",
            "Iteration 2900, Loss: 1.7738956212997437\n",
            "Iteration 2910, Loss: 1.9992280006408691\n",
            "Iteration 2920, Loss: 1.732253074645996\n",
            "Iteration 2930, Loss: 1.84494149684906\n",
            "Iteration 2940, Loss: 1.8792049884796143\n",
            "Iteration 2950, Loss: 1.8339320421218872\n",
            "Iteration 2960, Loss: 1.8228657245635986\n",
            "Iteration 2970, Loss: 1.889572262763977\n",
            "Iteration 2980, Loss: 1.7837458848953247\n",
            "Iteration 2990, Loss: 1.910291314125061\n",
            "Iteration 3000, Loss: 1.853982925415039\n",
            "Iteration 3000, Train Perplexity: 6.070249557495117, Validation Perplexity: 6.912341117858887\n",
            "Iteration 3010, Loss: 1.8055402040481567\n",
            "Iteration 3020, Loss: 1.8475778102874756\n",
            "Iteration 3030, Loss: 1.8342232704162598\n",
            "Iteration 3040, Loss: 1.926015019416809\n",
            "Iteration 3050, Loss: 1.6933791637420654\n",
            "Iteration 3060, Loss: 1.8404287099838257\n",
            "Iteration 3070, Loss: 1.7920337915420532\n",
            "Iteration 3080, Loss: 1.795462965965271\n",
            "Iteration 3090, Loss: 1.7859296798706055\n",
            "Iteration 3100, Loss: 1.73175847530365\n",
            "Iteration 3110, Loss: 1.8813313245773315\n",
            "Iteration 3120, Loss: 1.890963077545166\n",
            "Iteration 3130, Loss: 1.7362040281295776\n",
            "Iteration 3140, Loss: 1.6971228122711182\n",
            "Iteration 3150, Loss: 1.7390923500061035\n",
            "Iteration 3160, Loss: 1.8864023685455322\n",
            "Iteration 3170, Loss: 1.7746658325195312\n",
            "Iteration 3180, Loss: 1.807816743850708\n",
            "Iteration 3190, Loss: 1.8543763160705566\n",
            "Iteration 3200, Loss: 1.71609365940094\n",
            "Iteration 3200, Train Perplexity: 5.85704231262207, Validation Perplexity: 6.688436508178711\n",
            "Iteration 3210, Loss: 1.7724109888076782\n",
            "Iteration 3220, Loss: 1.8937461376190186\n",
            "Iteration 3230, Loss: 1.856524109840393\n",
            "Iteration 3240, Loss: 1.7451013326644897\n",
            "Iteration 3250, Loss: 1.8381567001342773\n",
            "Iteration 3260, Loss: 1.8108062744140625\n",
            "Iteration 3270, Loss: 1.7909698486328125\n",
            "Iteration 3280, Loss: 1.8954120874404907\n",
            "Iteration 3290, Loss: 1.8591067790985107\n",
            "Iteration 3300, Loss: 1.8131418228149414\n",
            "Iteration 3310, Loss: 1.656826376914978\n",
            "Iteration 3320, Loss: 2.0021636486053467\n",
            "Iteration 3330, Loss: 1.818697452545166\n",
            "Iteration 3340, Loss: 1.7249698638916016\n",
            "Iteration 3350, Loss: 1.6694897413253784\n",
            "Iteration 3360, Loss: 1.8263890743255615\n",
            "Iteration 3370, Loss: 1.8866899013519287\n",
            "Iteration 3380, Loss: 1.7972465753555298\n",
            "Iteration 3390, Loss: 1.7296595573425293\n",
            "Iteration 3400, Loss: 1.886970043182373\n",
            "Iteration 3400, Train Perplexity: 5.876400947570801, Validation Perplexity: 6.664870738983154\n",
            "Iteration 3410, Loss: 1.8070379495620728\n",
            "Iteration 3420, Loss: 1.5892869234085083\n",
            "Iteration 3430, Loss: 1.774811029434204\n",
            "Iteration 3440, Loss: 1.7676348686218262\n",
            "Iteration 3450, Loss: 1.8150392770767212\n",
            "Iteration 3460, Loss: 1.651654839515686\n",
            "Iteration 3470, Loss: 1.7208161354064941\n",
            "Iteration 3480, Loss: 1.8400218486785889\n",
            "Iteration 3490, Loss: 1.620588779449463\n",
            "Iteration 3500, Loss: 1.8359134197235107\n",
            "Iteration 3510, Loss: 1.720497488975525\n",
            "Iteration 3520, Loss: 1.7939975261688232\n",
            "Iteration 3530, Loss: 1.7892440557479858\n",
            "Iteration 3540, Loss: 1.8779160976409912\n",
            "Iteration 3550, Loss: 1.9118256568908691\n",
            "Iteration 3560, Loss: 1.8324278593063354\n",
            "Iteration 3570, Loss: 1.6984670162200928\n",
            "Iteration 3580, Loss: 1.7685133218765259\n",
            "Iteration 3590, Loss: 1.7653015851974487\n",
            "Iteration 3600, Loss: 1.7458462715148926\n",
            "Iteration 3600, Train Perplexity: 5.753425598144531, Validation Perplexity: 6.637969017028809\n",
            "Iteration 3610, Loss: 1.7075446844100952\n",
            "Iteration 3620, Loss: 1.89879310131073\n",
            "Iteration 3630, Loss: 1.7631608247756958\n",
            "Iteration 3640, Loss: 1.8137270212173462\n",
            "Iteration 3650, Loss: 1.689707636833191\n",
            "Iteration 3660, Loss: 1.7277989387512207\n",
            "Iteration 3670, Loss: 1.6177117824554443\n",
            "Iteration 3680, Loss: 1.7256896495819092\n",
            "Iteration 3690, Loss: 1.7798811197280884\n",
            "Iteration 3700, Loss: 1.6741008758544922\n",
            "Iteration 3710, Loss: 1.6636296510696411\n",
            "Iteration 3720, Loss: 1.754101276397705\n",
            "Iteration 3730, Loss: 1.7575570344924927\n",
            "Iteration 3740, Loss: 1.7502621412277222\n",
            "Iteration 3750, Loss: 1.7574801445007324\n",
            "Iteration 3760, Loss: 1.6647721529006958\n",
            "Iteration 3770, Loss: 1.8021650314331055\n",
            "Iteration 3780, Loss: 1.8197827339172363\n",
            "Iteration 3790, Loss: 1.6772817373275757\n",
            "Iteration 3800, Loss: 1.6458488702774048\n",
            "Iteration 3800, Train Perplexity: 5.616768836975098, Validation Perplexity: 6.612219333648682\n",
            "Iteration 3810, Loss: 1.849796175956726\n",
            "Iteration 3820, Loss: 1.7978578805923462\n",
            "Iteration 3830, Loss: 1.6941190958023071\n",
            "Iteration 3840, Loss: 1.6888097524642944\n",
            "Iteration 3850, Loss: 1.7425506114959717\n",
            "Iteration 3860, Loss: 1.5584110021591187\n",
            "Iteration 3870, Loss: 1.7572468519210815\n",
            "Iteration 3880, Loss: 1.626816749572754\n",
            "Iteration 3890, Loss: 1.8303954601287842\n",
            "Iteration 3900, Loss: 1.6869930028915405\n",
            "Iteration 3910, Loss: 1.7875417470932007\n",
            "Iteration 3920, Loss: 1.815642237663269\n",
            "Iteration 3930, Loss: 1.6930460929870605\n",
            "Iteration 3940, Loss: 1.7298492193222046\n",
            "Iteration 3950, Loss: 1.7708375453948975\n",
            "Iteration 3960, Loss: 1.765520691871643\n",
            "Iteration 3970, Loss: 1.8022027015686035\n",
            "Iteration 3980, Loss: 1.749812126159668\n",
            "Iteration 3990, Loss: 1.7746422290802002\n",
            "Iteration 4000, Loss: 1.6976662874221802\n",
            "Iteration 4000, Train Perplexity: 5.611047267913818, Validation Perplexity: 6.521458148956299\n",
            "Iteration 4010, Loss: 1.8057490587234497\n",
            "Iteration 4020, Loss: 1.6521105766296387\n",
            "Iteration 4030, Loss: 1.689391016960144\n",
            "Iteration 4040, Loss: 1.7397139072418213\n",
            "Iteration 4050, Loss: 1.7049773931503296\n",
            "Iteration 4060, Loss: 1.5374038219451904\n",
            "Iteration 4070, Loss: 1.7326796054840088\n",
            "Iteration 4080, Loss: 1.6975916624069214\n",
            "Iteration 4090, Loss: 1.8058397769927979\n",
            "Iteration 4100, Loss: 1.780380368232727\n",
            "Iteration 4110, Loss: 1.665117621421814\n",
            "Iteration 4120, Loss: 1.793148398399353\n",
            "Iteration 4130, Loss: 1.5549499988555908\n",
            "Iteration 4140, Loss: 1.7079182863235474\n",
            "Iteration 4150, Loss: 1.5955449342727661\n",
            "Iteration 4160, Loss: 1.7352964878082275\n",
            "Iteration 4170, Loss: 1.7180994749069214\n",
            "Iteration 4180, Loss: 1.6941801309585571\n",
            "Iteration 4190, Loss: 1.7124558687210083\n",
            "Iteration 4200, Loss: 1.7692651748657227\n",
            "Iteration 4200, Train Perplexity: 5.569919109344482, Validation Perplexity: 6.470437526702881\n",
            "Iteration 4210, Loss: 1.6796011924743652\n",
            "Iteration 4220, Loss: 1.5799758434295654\n",
            "Iteration 4230, Loss: 1.726157307624817\n",
            "Iteration 4240, Loss: 1.6288599967956543\n",
            "Iteration 4250, Loss: 1.6725918054580688\n",
            "Iteration 4260, Loss: 1.7276629209518433\n",
            "Iteration 4270, Loss: 1.6599832773208618\n",
            "Iteration 4280, Loss: 1.8000235557556152\n",
            "Iteration 4290, Loss: 1.6710458993911743\n",
            "Iteration 4300, Loss: 1.5713788270950317\n",
            "Iteration 4310, Loss: 1.695099949836731\n",
            "Iteration 4320, Loss: 1.750125527381897\n",
            "Iteration 4330, Loss: 1.5672369003295898\n",
            "Iteration 4340, Loss: 1.6444597244262695\n",
            "Iteration 4350, Loss: 1.6937668323516846\n",
            "Iteration 4360, Loss: 1.71334707736969\n",
            "Iteration 4370, Loss: 1.753341555595398\n",
            "Iteration 4380, Loss: 1.7074952125549316\n",
            "Iteration 4390, Loss: 1.790856957435608\n",
            "Iteration 4400, Loss: 1.8449974060058594\n",
            "Iteration 4400, Train Perplexity: 5.522732257843018, Validation Perplexity: 6.392416000366211\n",
            "Iteration 4410, Loss: 1.720072627067566\n",
            "Iteration 4420, Loss: 1.716178297996521\n",
            "Iteration 4430, Loss: 1.7931108474731445\n",
            "Iteration 4440, Loss: 1.7674537897109985\n",
            "Iteration 4450, Loss: 1.6020827293395996\n",
            "Iteration 4460, Loss: 1.6927496194839478\n",
            "Iteration 4470, Loss: 1.7787765264511108\n",
            "Iteration 4480, Loss: 1.6765222549438477\n",
            "Iteration 4490, Loss: 1.7335288524627686\n",
            "Iteration 4500, Loss: 1.7834738492965698\n",
            "Iteration 4510, Loss: 1.5930777788162231\n",
            "Iteration 4520, Loss: 1.7102844715118408\n",
            "Iteration 4530, Loss: 1.6015558242797852\n",
            "Iteration 4540, Loss: 1.6357357501983643\n",
            "Iteration 4550, Loss: 1.7026878595352173\n",
            "Iteration 4560, Loss: 1.663227915763855\n",
            "Iteration 4570, Loss: 1.6350332498550415\n",
            "Iteration 4580, Loss: 1.6740401983261108\n",
            "Iteration 4590, Loss: 1.7905256748199463\n",
            "Iteration 4600, Loss: 1.5832194089889526\n",
            "Iteration 4600, Train Perplexity: 5.444198131561279, Validation Perplexity: 6.320785999298096\n",
            "Iteration 4610, Loss: 1.8567720651626587\n",
            "Iteration 4620, Loss: 1.6940925121307373\n",
            "Iteration 4630, Loss: 1.6387666463851929\n",
            "Iteration 4640, Loss: 1.7977306842803955\n",
            "Iteration 4650, Loss: 1.545172929763794\n",
            "Iteration 4660, Loss: 1.7134336233139038\n",
            "Iteration 4670, Loss: 1.7713623046875\n",
            "Iteration 4680, Loss: 1.5025043487548828\n",
            "Iteration 4690, Loss: 1.7872987985610962\n",
            "Iteration 4700, Loss: 1.7182813882827759\n",
            "Iteration 4710, Loss: 1.5917190313339233\n",
            "Iteration 4720, Loss: 1.6795166730880737\n",
            "Iteration 4730, Loss: 1.7798289060592651\n",
            "Iteration 4740, Loss: 1.6597225666046143\n",
            "Iteration 4750, Loss: 1.7560205459594727\n",
            "Iteration 4760, Loss: 1.606436014175415\n",
            "Iteration 4770, Loss: 1.7269182205200195\n",
            "Iteration 4780, Loss: 1.7222869396209717\n",
            "Iteration 4790, Loss: 1.5784378051757812\n",
            "Iteration 4800, Loss: 1.7537426948547363\n",
            "Iteration 4800, Train Perplexity: 5.373361587524414, Validation Perplexity: 6.263513088226318\n",
            "Iteration 4810, Loss: 1.6704232692718506\n",
            "Iteration 4820, Loss: 1.6718707084655762\n",
            "Iteration 4830, Loss: 1.6572906970977783\n",
            "Iteration 4840, Loss: 1.5571805238723755\n",
            "Iteration 4850, Loss: 1.7194905281066895\n",
            "Iteration 4860, Loss: 1.7630285024642944\n",
            "Iteration 4870, Loss: 1.572435975074768\n",
            "Iteration 4880, Loss: 1.6596319675445557\n",
            "Iteration 4890, Loss: 1.6943591833114624\n",
            "Iteration 4900, Loss: 1.7086418867111206\n",
            "Iteration 4910, Loss: 1.6253249645233154\n",
            "Iteration 4920, Loss: 1.5686023235321045\n",
            "Iteration 4930, Loss: 1.75664222240448\n",
            "Iteration 4940, Loss: 1.6929892301559448\n",
            "Iteration 4950, Loss: 1.6958580017089844\n",
            "Iteration 4960, Loss: 1.6228830814361572\n",
            "Iteration 4970, Loss: 1.6346453428268433\n",
            "Iteration 4980, Loss: 1.639710545539856\n",
            "Iteration 4990, Loss: 1.742958664894104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Perplexity', marker='o')\n",
        "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Perplexity', marker='x')\n",
        "plt.title('Perplexity over Training Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "RIhyxq4-lxoK",
        "outputId": "2e708b38-0b97-45a3-89d9-be402b62596e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity was not much better than the original values, but definitely better than when I changed the number of embeddings to a smaller value."
      ],
      "metadata": {
        "id": "ROxmMM0WoJEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 8\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "model = LanguageModel().to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    x, y = get_batch('train')\n",
        "\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if iteration % eval_interval == 0:\n",
        "        print(f\"Iteration {iteration}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "    if iteration % eval_iters == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_losses_dict = estimate_loss()\n",
        "            train_loss = val_losses_dict['train']\n",
        "            val_loss = val_losses_dict['val']\n",
        "\n",
        "\n",
        "            train_perplexity = torch.exp(torch.tensor(train_loss))\n",
        "            val_perplexity = torch.exp(torch.tensor(val_loss))\n",
        "\n",
        "\n",
        "            print(f\"Iteration {iteration}, Train Perplexity: {train_perplexity}, Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "\n",
        "            train_losses.append(train_perplexity)\n",
        "            val_losses.append(val_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce3IqZzbn7ms",
        "outputId": "85a2d523-ba71-47cb-8f36-6c5992a5d819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.341314315795898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-5f4ed7914ff7>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss))\n",
            "<ipython-input-40-5f4ed7914ff7>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Train Perplexity: 56.67366409301758, Validation Perplexity: 57.14011764526367\n",
            "Iteration 10, Loss: 3.328801393508911\n",
            "Iteration 20, Loss: 3.3460378646850586\n",
            "Iteration 30, Loss: 2.9649300575256348\n",
            "Iteration 40, Loss: 2.912686824798584\n",
            "Iteration 50, Loss: 2.809502363204956\n",
            "Iteration 60, Loss: 2.6109766960144043\n",
            "Iteration 70, Loss: 2.7039194107055664\n",
            "Iteration 80, Loss: 2.659811019897461\n",
            "Iteration 90, Loss: 2.64658784866333\n",
            "Iteration 100, Loss: 2.531949758529663\n",
            "Iteration 110, Loss: 2.5962438583374023\n",
            "Iteration 120, Loss: 2.640810966491699\n",
            "Iteration 130, Loss: 2.4775969982147217\n",
            "Iteration 140, Loss: 2.5910305976867676\n",
            "Iteration 150, Loss: 2.5331077575683594\n",
            "Iteration 160, Loss: 2.5376830101013184\n",
            "Iteration 170, Loss: 2.3823370933532715\n",
            "Iteration 180, Loss: 2.5016160011291504\n",
            "Iteration 190, Loss: 2.361302375793457\n",
            "Iteration 200, Loss: 2.5239109992980957\n",
            "Iteration 200, Train Perplexity: 11.787482261657715, Validation Perplexity: 11.894285202026367\n",
            "Iteration 210, Loss: 2.4878358840942383\n",
            "Iteration 220, Loss: 2.374354839324951\n",
            "Iteration 230, Loss: 2.3472635746002197\n",
            "Iteration 240, Loss: 2.5083858966827393\n",
            "Iteration 250, Loss: 2.3797764778137207\n",
            "Iteration 260, Loss: 2.47334623336792\n",
            "Iteration 270, Loss: 2.3030970096588135\n",
            "Iteration 280, Loss: 2.337742328643799\n",
            "Iteration 290, Loss: 2.419973373413086\n",
            "Iteration 300, Loss: 2.4482061862945557\n",
            "Iteration 310, Loss: 2.3393330574035645\n",
            "Iteration 320, Loss: 2.360409736633301\n",
            "Iteration 330, Loss: 2.300638198852539\n",
            "Iteration 340, Loss: 2.4124860763549805\n",
            "Iteration 350, Loss: 2.328554630279541\n",
            "Iteration 360, Loss: 2.323547601699829\n",
            "Iteration 370, Loss: 2.2252535820007324\n",
            "Iteration 380, Loss: 2.2729172706604004\n",
            "Iteration 390, Loss: 2.376408815383911\n",
            "Iteration 400, Loss: 2.242168664932251\n",
            "Iteration 400, Train Perplexity: 10.057127952575684, Validation Perplexity: 10.16018009185791\n",
            "Iteration 410, Loss: 2.2458696365356445\n",
            "Iteration 420, Loss: 2.4084174633026123\n",
            "Iteration 430, Loss: 2.3409249782562256\n",
            "Iteration 440, Loss: 2.2372782230377197\n",
            "Iteration 450, Loss: 2.264155387878418\n",
            "Iteration 460, Loss: 2.2247416973114014\n",
            "Iteration 470, Loss: 2.3056294918060303\n",
            "Iteration 480, Loss: 2.258929491043091\n",
            "Iteration 490, Loss: 2.1562864780426025\n",
            "Iteration 500, Loss: 2.287736415863037\n",
            "Iteration 510, Loss: 2.206566572189331\n",
            "Iteration 520, Loss: 2.25370192527771\n",
            "Iteration 530, Loss: 2.1479544639587402\n",
            "Iteration 540, Loss: 2.2202224731445312\n",
            "Iteration 550, Loss: 2.2391674518585205\n",
            "Iteration 560, Loss: 2.2665886878967285\n",
            "Iteration 570, Loss: 2.1679224967956543\n",
            "Iteration 580, Loss: 2.2239460945129395\n",
            "Iteration 590, Loss: 2.1289186477661133\n",
            "Iteration 600, Loss: 2.2035436630249023\n",
            "Iteration 600, Train Perplexity: 9.007030487060547, Validation Perplexity: 9.215643882751465\n",
            "Iteration 610, Loss: 2.106873035430908\n",
            "Iteration 620, Loss: 2.062441825866699\n",
            "Iteration 630, Loss: 2.1414928436279297\n",
            "Iteration 640, Loss: 2.195154905319214\n",
            "Iteration 650, Loss: 2.1729893684387207\n",
            "Iteration 660, Loss: 2.090050458908081\n",
            "Iteration 670, Loss: 2.0716569423675537\n",
            "Iteration 680, Loss: 2.143744707107544\n",
            "Iteration 690, Loss: 2.2060959339141846\n",
            "Iteration 700, Loss: 2.1395270824432373\n",
            "Iteration 710, Loss: 2.261392831802368\n",
            "Iteration 720, Loss: 2.1743996143341064\n",
            "Iteration 730, Loss: 2.0361263751983643\n",
            "Iteration 740, Loss: 2.110287666320801\n",
            "Iteration 750, Loss: 2.1138980388641357\n",
            "Iteration 760, Loss: 2.106640100479126\n",
            "Iteration 770, Loss: 2.109269380569458\n",
            "Iteration 780, Loss: 2.097703218460083\n",
            "Iteration 790, Loss: 2.1313674449920654\n",
            "Iteration 800, Loss: 2.0423288345336914\n",
            "Iteration 800, Train Perplexity: 8.375313758850098, Validation Perplexity: 8.637544631958008\n",
            "Iteration 810, Loss: 2.0588223934173584\n",
            "Iteration 820, Loss: 2.0792152881622314\n",
            "Iteration 830, Loss: 2.1281933784484863\n",
            "Iteration 840, Loss: 2.1028683185577393\n",
            "Iteration 850, Loss: 2.123838424682617\n",
            "Iteration 860, Loss: 2.07875919342041\n",
            "Iteration 870, Loss: 2.181401252746582\n",
            "Iteration 880, Loss: 2.0887749195098877\n",
            "Iteration 890, Loss: 2.0495619773864746\n",
            "Iteration 900, Loss: 2.0960171222686768\n",
            "Iteration 910, Loss: 2.150970697402954\n",
            "Iteration 920, Loss: 2.1085972785949707\n",
            "Iteration 930, Loss: 2.0190343856811523\n",
            "Iteration 940, Loss: 1.9728378057479858\n",
            "Iteration 950, Loss: 2.1098783016204834\n",
            "Iteration 960, Loss: 2.0749645233154297\n",
            "Iteration 970, Loss: 2.074030637741089\n",
            "Iteration 980, Loss: 2.0714826583862305\n",
            "Iteration 990, Loss: 2.068098783493042\n",
            "Iteration 1000, Loss: 2.062105417251587\n",
            "Iteration 1000, Train Perplexity: 7.688152313232422, Validation Perplexity: 8.05867862701416\n",
            "Iteration 1010, Loss: 2.0339856147766113\n",
            "Iteration 1020, Loss: 1.983142375946045\n",
            "Iteration 1030, Loss: 2.0263843536376953\n",
            "Iteration 1040, Loss: 2.0523905754089355\n",
            "Iteration 1050, Loss: 1.9638876914978027\n",
            "Iteration 1060, Loss: 1.9717905521392822\n",
            "Iteration 1070, Loss: 1.9117076396942139\n",
            "Iteration 1080, Loss: 1.9956241846084595\n",
            "Iteration 1090, Loss: 2.081604480743408\n",
            "Iteration 1100, Loss: 2.007354259490967\n",
            "Iteration 1110, Loss: 2.0491256713867188\n",
            "Iteration 1120, Loss: 1.9674835205078125\n",
            "Iteration 1130, Loss: 2.062607765197754\n",
            "Iteration 1140, Loss: 1.940245270729065\n",
            "Iteration 1150, Loss: 1.9537346363067627\n",
            "Iteration 1160, Loss: 2.012563943862915\n",
            "Iteration 1170, Loss: 2.095590829849243\n",
            "Iteration 1180, Loss: 2.096761465072632\n",
            "Iteration 1190, Loss: 1.954436182975769\n",
            "Iteration 1200, Loss: 2.1073484420776367\n",
            "Iteration 1200, Train Perplexity: 7.1817827224731445, Validation Perplexity: 7.728670597076416\n",
            "Iteration 1210, Loss: 2.039443016052246\n",
            "Iteration 1220, Loss: 1.9724317789077759\n",
            "Iteration 1230, Loss: 2.0087122917175293\n",
            "Iteration 1240, Loss: 2.010172128677368\n",
            "Iteration 1250, Loss: 2.060364246368408\n",
            "Iteration 1260, Loss: 1.9472076892852783\n",
            "Iteration 1270, Loss: 2.023238182067871\n",
            "Iteration 1280, Loss: 1.9476114511489868\n",
            "Iteration 1290, Loss: 1.9715945720672607\n",
            "Iteration 1300, Loss: 2.027529716491699\n",
            "Iteration 1310, Loss: 2.018935203552246\n",
            "Iteration 1320, Loss: 1.9474831819534302\n",
            "Iteration 1330, Loss: 1.9362168312072754\n",
            "Iteration 1340, Loss: 1.9648927450180054\n",
            "Iteration 1350, Loss: 1.970207691192627\n",
            "Iteration 1360, Loss: 1.938361644744873\n",
            "Iteration 1370, Loss: 1.9022953510284424\n",
            "Iteration 1380, Loss: 1.988525152206421\n",
            "Iteration 1390, Loss: 1.9025834798812866\n",
            "Iteration 1400, Loss: 1.8968446254730225\n",
            "Iteration 1400, Train Perplexity: 6.954094886779785, Validation Perplexity: 7.490981101989746\n",
            "Iteration 1410, Loss: 1.9179883003234863\n",
            "Iteration 1420, Loss: 1.8739492893218994\n",
            "Iteration 1430, Loss: 1.9823683500289917\n",
            "Iteration 1440, Loss: 1.8203169107437134\n",
            "Iteration 1450, Loss: 1.9896806478500366\n",
            "Iteration 1460, Loss: 2.0683705806732178\n",
            "Iteration 1470, Loss: 1.8564972877502441\n",
            "Iteration 1480, Loss: 1.8467124700546265\n",
            "Iteration 1490, Loss: 1.948536992073059\n",
            "Iteration 1500, Loss: 1.9092470407485962\n",
            "Iteration 1510, Loss: 1.8782461881637573\n",
            "Iteration 1520, Loss: 1.8829212188720703\n",
            "Iteration 1530, Loss: 1.9255239963531494\n",
            "Iteration 1540, Loss: 1.8206084966659546\n",
            "Iteration 1550, Loss: 1.9755749702453613\n",
            "Iteration 1560, Loss: 1.814521074295044\n",
            "Iteration 1570, Loss: 1.754542589187622\n",
            "Iteration 1580, Loss: 1.9515022039413452\n",
            "Iteration 1590, Loss: 1.8987113237380981\n",
            "Iteration 1600, Loss: 1.9571770429611206\n",
            "Iteration 1600, Train Perplexity: 6.657447338104248, Validation Perplexity: 7.372104167938232\n",
            "Iteration 1610, Loss: 1.93512761592865\n",
            "Iteration 1620, Loss: 1.8580355644226074\n",
            "Iteration 1630, Loss: 1.8923977613449097\n",
            "Iteration 1640, Loss: 1.7963948249816895\n",
            "Iteration 1650, Loss: 1.8225287199020386\n",
            "Iteration 1660, Loss: 1.9075568914413452\n",
            "Iteration 1670, Loss: 1.9834535121917725\n",
            "Iteration 1680, Loss: 1.9159899950027466\n",
            "Iteration 1690, Loss: 1.8071672916412354\n",
            "Iteration 1700, Loss: 1.9232038259506226\n",
            "Iteration 1710, Loss: 1.7955386638641357\n",
            "Iteration 1720, Loss: 1.936081886291504\n",
            "Iteration 1730, Loss: 1.867890477180481\n",
            "Iteration 1740, Loss: 1.8869584798812866\n",
            "Iteration 1750, Loss: 1.9199503660202026\n",
            "Iteration 1760, Loss: 1.8337452411651611\n",
            "Iteration 1770, Loss: 1.827358603477478\n",
            "Iteration 1780, Loss: 1.840600609779358\n",
            "Iteration 1790, Loss: 1.866518259048462\n",
            "Iteration 1800, Loss: 1.8664612770080566\n",
            "Iteration 1800, Train Perplexity: 6.357329368591309, Validation Perplexity: 7.094796180725098\n",
            "Iteration 1810, Loss: 1.8272266387939453\n",
            "Iteration 1820, Loss: 1.9033352136611938\n",
            "Iteration 1830, Loss: 1.942456841468811\n",
            "Iteration 1840, Loss: 1.7928402423858643\n",
            "Iteration 1850, Loss: 1.6797516345977783\n",
            "Iteration 1860, Loss: 1.7962729930877686\n",
            "Iteration 1870, Loss: 1.865945816040039\n",
            "Iteration 1880, Loss: 1.8071907758712769\n",
            "Iteration 1890, Loss: 1.8467957973480225\n",
            "Iteration 1900, Loss: 1.8808940649032593\n",
            "Iteration 1910, Loss: 1.87367844581604\n",
            "Iteration 1920, Loss: 1.8195841312408447\n",
            "Iteration 1930, Loss: 1.7725392580032349\n",
            "Iteration 1940, Loss: 1.9311450719833374\n",
            "Iteration 1950, Loss: 1.893014669418335\n",
            "Iteration 1960, Loss: 1.8279225826263428\n",
            "Iteration 1970, Loss: 1.9974313974380493\n",
            "Iteration 1980, Loss: 1.9380513429641724\n",
            "Iteration 1990, Loss: 1.7421146631240845\n",
            "Iteration 2000, Loss: 1.9030731916427612\n",
            "Iteration 2000, Train Perplexity: 6.208477973937988, Validation Perplexity: 6.967390537261963\n",
            "Iteration 2010, Loss: 1.788885474205017\n",
            "Iteration 2020, Loss: 1.7208304405212402\n",
            "Iteration 2030, Loss: 1.8668400049209595\n",
            "Iteration 2040, Loss: 1.8273152112960815\n",
            "Iteration 2050, Loss: 1.996279239654541\n",
            "Iteration 2060, Loss: 1.854232907295227\n",
            "Iteration 2070, Loss: 1.899457335472107\n",
            "Iteration 2080, Loss: 1.6969027519226074\n",
            "Iteration 2090, Loss: 1.8031854629516602\n",
            "Iteration 2100, Loss: 1.68695867061615\n",
            "Iteration 2110, Loss: 1.8234690427780151\n",
            "Iteration 2120, Loss: 1.7474285364151\n",
            "Iteration 2130, Loss: 1.7248079776763916\n",
            "Iteration 2140, Loss: 1.8312184810638428\n",
            "Iteration 2150, Loss: 1.72403883934021\n",
            "Iteration 2160, Loss: 1.8295984268188477\n",
            "Iteration 2170, Loss: 1.8552454710006714\n",
            "Iteration 2180, Loss: 1.7445791959762573\n",
            "Iteration 2190, Loss: 1.8468846082687378\n",
            "Iteration 2200, Loss: 1.6445906162261963\n",
            "Iteration 2200, Train Perplexity: 6.024137020111084, Validation Perplexity: 6.82325553894043\n",
            "Iteration 2210, Loss: 1.903286099433899\n",
            "Iteration 2220, Loss: 1.8615937232971191\n",
            "Iteration 2230, Loss: 1.7583848237991333\n",
            "Iteration 2240, Loss: 1.778565526008606\n",
            "Iteration 2250, Loss: 1.7536954879760742\n",
            "Iteration 2260, Loss: 1.7057547569274902\n",
            "Iteration 2270, Loss: 1.844994306564331\n",
            "Iteration 2280, Loss: 1.6848227977752686\n",
            "Iteration 2290, Loss: 1.768187165260315\n",
            "Iteration 2300, Loss: 1.7856981754302979\n",
            "Iteration 2310, Loss: 1.8232049942016602\n",
            "Iteration 2320, Loss: 1.7776377201080322\n",
            "Iteration 2330, Loss: 1.8882598876953125\n",
            "Iteration 2340, Loss: 1.6703308820724487\n",
            "Iteration 2350, Loss: 1.8325836658477783\n",
            "Iteration 2360, Loss: 1.795233964920044\n",
            "Iteration 2370, Loss: 1.769580364227295\n",
            "Iteration 2380, Loss: 1.7536464929580688\n",
            "Iteration 2390, Loss: 1.7906438112258911\n",
            "Iteration 2400, Loss: 1.7378513813018799\n",
            "Iteration 2400, Train Perplexity: 5.9256391525268555, Validation Perplexity: 6.6556267738342285\n",
            "Iteration 2410, Loss: 1.6887023448944092\n",
            "Iteration 2420, Loss: 1.7145662307739258\n",
            "Iteration 2430, Loss: 1.6904186010360718\n",
            "Iteration 2440, Loss: 1.7796121835708618\n",
            "Iteration 2450, Loss: 1.8828521966934204\n",
            "Iteration 2460, Loss: 1.7318718433380127\n",
            "Iteration 2470, Loss: 1.791849970817566\n",
            "Iteration 2480, Loss: 1.8347746133804321\n",
            "Iteration 2490, Loss: 1.6894105672836304\n",
            "Iteration 2500, Loss: 1.6990141868591309\n",
            "Iteration 2510, Loss: 1.7079691886901855\n",
            "Iteration 2520, Loss: 1.8438633680343628\n",
            "Iteration 2530, Loss: 1.8008252382278442\n",
            "Iteration 2540, Loss: 1.7670211791992188\n",
            "Iteration 2550, Loss: 1.8273396492004395\n",
            "Iteration 2560, Loss: 1.662488341331482\n",
            "Iteration 2570, Loss: 1.7391520738601685\n",
            "Iteration 2580, Loss: 1.848130226135254\n",
            "Iteration 2590, Loss: 1.8177398443222046\n",
            "Iteration 2600, Loss: 1.753187656402588\n",
            "Iteration 2600, Train Perplexity: 5.767317295074463, Validation Perplexity: 6.538597106933594\n",
            "Iteration 2610, Loss: 1.6521977186203003\n",
            "Iteration 2620, Loss: 1.768867015838623\n",
            "Iteration 2630, Loss: 1.7013652324676514\n",
            "Iteration 2640, Loss: 1.7846729755401611\n",
            "Iteration 2650, Loss: 1.7015336751937866\n",
            "Iteration 2660, Loss: 1.6768007278442383\n",
            "Iteration 2670, Loss: 1.816400170326233\n",
            "Iteration 2680, Loss: 1.7493270635604858\n",
            "Iteration 2690, Loss: 1.5958495140075684\n",
            "Iteration 2700, Loss: 1.6886802911758423\n",
            "Iteration 2710, Loss: 1.8267230987548828\n",
            "Iteration 2720, Loss: 1.6189115047454834\n",
            "Iteration 2730, Loss: 1.6798933744430542\n",
            "Iteration 2740, Loss: 1.7447339296340942\n",
            "Iteration 2750, Loss: 1.7315900325775146\n",
            "Iteration 2760, Loss: 1.7650930881500244\n",
            "Iteration 2770, Loss: 1.8131872415542603\n",
            "Iteration 2780, Loss: 1.6445313692092896\n",
            "Iteration 2790, Loss: 1.7898473739624023\n",
            "Iteration 2800, Loss: 1.6489002704620361\n",
            "Iteration 2800, Train Perplexity: 5.652047634124756, Validation Perplexity: 6.461160659790039\n",
            "Iteration 2810, Loss: 1.749482274055481\n",
            "Iteration 2820, Loss: 1.7482515573501587\n",
            "Iteration 2830, Loss: 1.6633660793304443\n",
            "Iteration 2840, Loss: 1.6984132528305054\n",
            "Iteration 2850, Loss: 1.6296560764312744\n",
            "Iteration 2860, Loss: 1.6593599319458008\n",
            "Iteration 2870, Loss: 1.6884510517120361\n",
            "Iteration 2880, Loss: 1.7557705640792847\n",
            "Iteration 2890, Loss: 1.6183427572250366\n",
            "Iteration 2900, Loss: 1.9863260984420776\n",
            "Iteration 2910, Loss: 1.6306636333465576\n",
            "Iteration 2920, Loss: 1.7572208642959595\n",
            "Iteration 2930, Loss: 1.7001029253005981\n",
            "Iteration 2940, Loss: 1.739411473274231\n",
            "Iteration 2950, Loss: 1.7067949771881104\n",
            "Iteration 2960, Loss: 1.722612977027893\n",
            "Iteration 2970, Loss: 1.630420446395874\n",
            "Iteration 2980, Loss: 1.8854691982269287\n",
            "Iteration 2990, Loss: 1.7395118474960327\n",
            "Iteration 3000, Loss: 1.8273420333862305\n",
            "Iteration 3000, Train Perplexity: 5.654435157775879, Validation Perplexity: 6.453902244567871\n",
            "Iteration 3010, Loss: 1.7570173740386963\n",
            "Iteration 3020, Loss: 1.7930364608764648\n",
            "Iteration 3030, Loss: 1.934585690498352\n",
            "Iteration 3040, Loss: 1.6224560737609863\n",
            "Iteration 3050, Loss: 1.7499083280563354\n",
            "Iteration 3060, Loss: 1.6949777603149414\n",
            "Iteration 3070, Loss: 1.6523833274841309\n",
            "Iteration 3080, Loss: 1.7014724016189575\n",
            "Iteration 3090, Loss: 1.7454055547714233\n",
            "Iteration 3100, Loss: 1.6956777572631836\n",
            "Iteration 3110, Loss: 1.701522707939148\n",
            "Iteration 3120, Loss: 1.7019295692443848\n",
            "Iteration 3130, Loss: 1.5970211029052734\n",
            "Iteration 3140, Loss: 1.6590020656585693\n",
            "Iteration 3150, Loss: 1.6500829458236694\n",
            "Iteration 3160, Loss: 1.7383478879928589\n",
            "Iteration 3170, Loss: 1.735036849975586\n",
            "Iteration 3180, Loss: 1.8009458780288696\n",
            "Iteration 3190, Loss: 1.664571762084961\n",
            "Iteration 3200, Loss: 1.726495623588562\n",
            "Iteration 3200, Train Perplexity: 5.47498083114624, Validation Perplexity: 6.368410110473633\n",
            "Iteration 3210, Loss: 1.6774300336837769\n",
            "Iteration 3220, Loss: 1.8174052238464355\n",
            "Iteration 3230, Loss: 1.7107959985733032\n",
            "Iteration 3240, Loss: 1.7404011487960815\n",
            "Iteration 3250, Loss: 1.6765518188476562\n",
            "Iteration 3260, Loss: 1.5820282697677612\n",
            "Iteration 3270, Loss: 1.6563481092453003\n",
            "Iteration 3280, Loss: 1.723986268043518\n",
            "Iteration 3290, Loss: 1.6211411952972412\n",
            "Iteration 3300, Loss: 1.7951462268829346\n",
            "Iteration 3310, Loss: 1.6588959693908691\n",
            "Iteration 3320, Loss: 1.7595312595367432\n",
            "Iteration 3330, Loss: 1.6369633674621582\n",
            "Iteration 3340, Loss: 1.6820045709609985\n",
            "Iteration 3350, Loss: 1.7517895698547363\n",
            "Iteration 3360, Loss: 1.685449481010437\n",
            "Iteration 3370, Loss: 1.67786705493927\n",
            "Iteration 3380, Loss: 1.7173352241516113\n",
            "Iteration 3390, Loss: 1.7645031213760376\n",
            "Iteration 3400, Loss: 1.610868215560913\n",
            "Iteration 3400, Train Perplexity: 5.401742935180664, Validation Perplexity: 6.318186283111572\n",
            "Iteration 3410, Loss: 1.760471224784851\n",
            "Iteration 3420, Loss: 1.6792889833450317\n",
            "Iteration 3430, Loss: 1.729311466217041\n",
            "Iteration 3440, Loss: 1.647204875946045\n",
            "Iteration 3450, Loss: 1.7377063035964966\n",
            "Iteration 3460, Loss: 1.6374447345733643\n",
            "Iteration 3470, Loss: 1.7893306016921997\n",
            "Iteration 3480, Loss: 1.6853501796722412\n",
            "Iteration 3490, Loss: 1.685387134552002\n",
            "Iteration 3500, Loss: 1.5443452596664429\n",
            "Iteration 3510, Loss: 1.7136874198913574\n",
            "Iteration 3520, Loss: 1.6292911767959595\n",
            "Iteration 3530, Loss: 1.5790077447891235\n",
            "Iteration 3540, Loss: 1.6634471416473389\n",
            "Iteration 3550, Loss: 1.7517704963684082\n",
            "Iteration 3560, Loss: 1.5744624137878418\n",
            "Iteration 3570, Loss: 1.7582440376281738\n",
            "Iteration 3580, Loss: 1.7287101745605469\n",
            "Iteration 3590, Loss: 1.7232285737991333\n",
            "Iteration 3600, Loss: 1.6986585855484009\n",
            "Iteration 3600, Train Perplexity: 5.31748628616333, Validation Perplexity: 6.266289234161377\n",
            "Iteration 3610, Loss: 1.726575493812561\n",
            "Iteration 3620, Loss: 1.6811503171920776\n",
            "Iteration 3630, Loss: 1.7019233703613281\n",
            "Iteration 3640, Loss: 1.7458336353302002\n",
            "Iteration 3650, Loss: 1.681277871131897\n",
            "Iteration 3660, Loss: 1.6814777851104736\n",
            "Iteration 3670, Loss: 1.589518666267395\n",
            "Iteration 3680, Loss: 1.744805932044983\n",
            "Iteration 3690, Loss: 1.5850300788879395\n",
            "Iteration 3700, Loss: 1.735721230506897\n",
            "Iteration 3710, Loss: 1.7600154876708984\n",
            "Iteration 3720, Loss: 1.858298659324646\n",
            "Iteration 3730, Loss: 1.6983405351638794\n",
            "Iteration 3740, Loss: 1.7606626749038696\n",
            "Iteration 3750, Loss: 1.648488998413086\n",
            "Iteration 3760, Loss: 1.6967986822128296\n",
            "Iteration 3770, Loss: 1.6215142011642456\n",
            "Iteration 3780, Loss: 1.6657384634017944\n",
            "Iteration 3790, Loss: 1.7509878873825073\n",
            "Iteration 3800, Loss: 1.5651841163635254\n",
            "Iteration 3800, Train Perplexity: 5.318879127502441, Validation Perplexity: 6.139275074005127\n",
            "Iteration 3810, Loss: 1.5582562685012817\n",
            "Iteration 3820, Loss: 1.6862010955810547\n",
            "Iteration 3830, Loss: 1.6973400115966797\n",
            "Iteration 3840, Loss: 1.6051799058914185\n",
            "Iteration 3850, Loss: 1.6412278413772583\n",
            "Iteration 3860, Loss: 1.6409341096878052\n",
            "Iteration 3870, Loss: 1.5644201040267944\n",
            "Iteration 3880, Loss: 1.6870830059051514\n",
            "Iteration 3890, Loss: 1.5296504497528076\n",
            "Iteration 3900, Loss: 1.6065924167633057\n",
            "Iteration 3910, Loss: 1.6605300903320312\n",
            "Iteration 3920, Loss: 1.5736255645751953\n",
            "Iteration 3930, Loss: 1.717933177947998\n",
            "Iteration 3940, Loss: 1.7794108390808105\n",
            "Iteration 3950, Loss: 1.5704565048217773\n",
            "Iteration 3960, Loss: 1.7359230518341064\n",
            "Iteration 3970, Loss: 1.7810044288635254\n",
            "Iteration 3980, Loss: 1.5722225904464722\n",
            "Iteration 3990, Loss: 1.7057560682296753\n",
            "Iteration 4000, Loss: 1.6324794292449951\n",
            "Iteration 4000, Train Perplexity: 5.204222679138184, Validation Perplexity: 6.109480381011963\n",
            "Iteration 4010, Loss: 1.6269558668136597\n",
            "Iteration 4020, Loss: 1.6490753889083862\n",
            "Iteration 4030, Loss: 1.687546730041504\n",
            "Iteration 4040, Loss: 1.532789945602417\n",
            "Iteration 4050, Loss: 1.6164358854293823\n",
            "Iteration 4060, Loss: 1.7348777055740356\n",
            "Iteration 4070, Loss: 1.725983738899231\n",
            "Iteration 4080, Loss: 1.680402159690857\n",
            "Iteration 4090, Loss: 1.743890404701233\n",
            "Iteration 4100, Loss: 1.6116389036178589\n",
            "Iteration 4110, Loss: 1.6234631538391113\n",
            "Iteration 4120, Loss: 1.5077571868896484\n",
            "Iteration 4130, Loss: 1.6414326429367065\n",
            "Iteration 4140, Loss: 1.5014238357543945\n",
            "Iteration 4150, Loss: 1.596296787261963\n",
            "Iteration 4160, Loss: 1.7521981000900269\n",
            "Iteration 4170, Loss: 1.6089171171188354\n",
            "Iteration 4180, Loss: 1.6616508960723877\n",
            "Iteration 4190, Loss: 1.668614387512207\n",
            "Iteration 4200, Loss: 1.6780856847763062\n",
            "Iteration 4200, Train Perplexity: 5.121285915374756, Validation Perplexity: 6.11286735534668\n",
            "Iteration 4210, Loss: 1.6093823909759521\n",
            "Iteration 4220, Loss: 1.5998481512069702\n",
            "Iteration 4230, Loss: 1.6544300317764282\n",
            "Iteration 4240, Loss: 1.758133888244629\n",
            "Iteration 4250, Loss: 1.7246814966201782\n",
            "Iteration 4260, Loss: 1.4792613983154297\n",
            "Iteration 4270, Loss: 1.5771253108978271\n",
            "Iteration 4280, Loss: 1.6324057579040527\n",
            "Iteration 4290, Loss: 1.5872018337249756\n",
            "Iteration 4300, Loss: 1.6589149236679077\n",
            "Iteration 4310, Loss: 1.8031805753707886\n",
            "Iteration 4320, Loss: 1.6423949003219604\n",
            "Iteration 4330, Loss: 1.6254855394363403\n",
            "Iteration 4340, Loss: 1.6888172626495361\n",
            "Iteration 4350, Loss: 1.65140962600708\n",
            "Iteration 4360, Loss: 1.6330575942993164\n",
            "Iteration 4370, Loss: 1.6534991264343262\n",
            "Iteration 4380, Loss: 1.6345725059509277\n",
            "Iteration 4390, Loss: 1.548306941986084\n",
            "Iteration 4400, Loss: 1.6258540153503418\n",
            "Iteration 4400, Train Perplexity: 5.1507182121276855, Validation Perplexity: 6.049316883087158\n",
            "Iteration 4410, Loss: 1.6356134414672852\n",
            "Iteration 4420, Loss: 1.4820760488510132\n",
            "Iteration 4430, Loss: 1.5605040788650513\n",
            "Iteration 4440, Loss: 1.597058653831482\n",
            "Iteration 4450, Loss: 1.6867566108703613\n",
            "Iteration 4460, Loss: 1.6728084087371826\n",
            "Iteration 4470, Loss: 1.5493007898330688\n",
            "Iteration 4480, Loss: 1.6434797048568726\n",
            "Iteration 4490, Loss: 1.6159485578536987\n",
            "Iteration 4500, Loss: 1.6952943801879883\n",
            "Iteration 4510, Loss: 1.5921200513839722\n",
            "Iteration 4520, Loss: 1.7443879842758179\n",
            "Iteration 4530, Loss: 1.5524436235427856\n",
            "Iteration 4540, Loss: 1.7821182012557983\n",
            "Iteration 4550, Loss: 1.5991058349609375\n",
            "Iteration 4560, Loss: 1.6662672758102417\n",
            "Iteration 4570, Loss: 1.5466315746307373\n",
            "Iteration 4580, Loss: 1.370367407798767\n",
            "Iteration 4590, Loss: 1.4232293367385864\n",
            "Iteration 4600, Loss: 1.5564486980438232\n",
            "Iteration 4600, Train Perplexity: 5.079438209533691, Validation Perplexity: 6.005476474761963\n",
            "Iteration 4610, Loss: 1.560626745223999\n",
            "Iteration 4620, Loss: 1.6476153135299683\n",
            "Iteration 4630, Loss: 1.5932291746139526\n",
            "Iteration 4640, Loss: 1.6014988422393799\n",
            "Iteration 4650, Loss: 1.5722408294677734\n",
            "Iteration 4660, Loss: 1.6988943815231323\n",
            "Iteration 4670, Loss: 1.5942167043685913\n",
            "Iteration 4680, Loss: 1.5551031827926636\n",
            "Iteration 4690, Loss: 1.6092525720596313\n",
            "Iteration 4700, Loss: 1.6437567472457886\n",
            "Iteration 4710, Loss: 1.6089004278182983\n",
            "Iteration 4720, Loss: 1.597028374671936\n",
            "Iteration 4730, Loss: 1.6628235578536987\n",
            "Iteration 4740, Loss: 1.6695568561553955\n",
            "Iteration 4750, Loss: 1.6411411762237549\n",
            "Iteration 4760, Loss: 1.6292140483856201\n",
            "Iteration 4770, Loss: 1.5039840936660767\n",
            "Iteration 4780, Loss: 1.6678017377853394\n",
            "Iteration 4790, Loss: 1.6220470666885376\n",
            "Iteration 4800, Loss: 1.566139817237854\n",
            "Iteration 4800, Train Perplexity: 5.011402606964111, Validation Perplexity: 5.9873785972595215\n",
            "Iteration 4810, Loss: 1.717450737953186\n",
            "Iteration 4820, Loss: 1.5814268589019775\n",
            "Iteration 4830, Loss: 1.6165354251861572\n",
            "Iteration 4840, Loss: 1.6059602499008179\n",
            "Iteration 4850, Loss: 1.600077748298645\n",
            "Iteration 4860, Loss: 1.5758826732635498\n",
            "Iteration 4870, Loss: 1.5161961317062378\n",
            "Iteration 4880, Loss: 1.6607954502105713\n",
            "Iteration 4890, Loss: 1.5314713716506958\n",
            "Iteration 4900, Loss: 1.6467596292495728\n",
            "Iteration 4910, Loss: 1.567834734916687\n",
            "Iteration 4920, Loss: 1.532863736152649\n",
            "Iteration 4930, Loss: 1.6298116445541382\n",
            "Iteration 4940, Loss: 1.5317353010177612\n",
            "Iteration 4950, Loss: 1.5576335191726685\n",
            "Iteration 4960, Loss: 1.6640413999557495\n",
            "Iteration 4970, Loss: 1.596531629562378\n",
            "Iteration 4980, Loss: 1.5687966346740723\n",
            "Iteration 4990, Loss: 1.5716087818145752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Perplexity', marker='o')\n",
        "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Perplexity', marker='x')\n",
        "plt.title('Perplexity over Training Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "OwXTQv9PoS9Q",
        "outputId": "b219fc4a-d3bb-43b7-cc9b-2e8831efe678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we increase the number of layers, the perplexity starts EXTREMELY higher than it does for the 4 layers. However, the loss is much better, and the validation perplexity is best in the end. I would say this is the best loop overall, and this makes sense, because more layers increases the model's ability to extract complex features, patterns, etc. from the data. If we keep the number of layers as 8, now that we know it has improved the loss, we might want to try increase the number of embeddings:"
      ],
      "metadata": {
        "id": "s21aL5JGpBsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "n_embd = 128\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 8\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "model = LanguageModel().to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    x, y = get_batch('train')\n",
        "\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if iteration % eval_interval == 0:\n",
        "        print(f\"Iteration {iteration}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "    if iteration % eval_iters == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_losses_dict = estimate_loss()\n",
        "            train_loss = val_losses_dict['train']\n",
        "            val_loss = val_losses_dict['val']\n",
        "\n",
        "\n",
        "            train_perplexity = torch.exp(torch.tensor(train_loss))\n",
        "            val_perplexity = torch.exp(torch.tensor(val_loss))\n",
        "\n",
        "\n",
        "            print(f\"Iteration {iteration}, Train Perplexity: {train_perplexity}, Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "\n",
        "            train_losses.append(train_perplexity)\n",
        "            val_losses.append(val_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGmMc3RHZuJl",
        "outputId": "4d65a0b0-777c-4420-effd-b7cdb3339199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.3879194259643555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-f52c93f2d12d>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss))\n",
            "<ipython-input-16-f52c93f2d12d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Train Perplexity: 43.03614807128906, Validation Perplexity: 44.21590805053711\n",
            "Iteration 10, Loss: 3.285470724105835\n",
            "Iteration 20, Loss: 3.058086395263672\n",
            "Iteration 30, Loss: 2.781531572341919\n",
            "Iteration 40, Loss: 2.6882288455963135\n",
            "Iteration 50, Loss: 2.5535576343536377\n",
            "Iteration 60, Loss: 2.6711339950561523\n",
            "Iteration 70, Loss: 2.521289825439453\n",
            "Iteration 80, Loss: 2.5965867042541504\n",
            "Iteration 90, Loss: 2.548252582550049\n",
            "Iteration 100, Loss: 2.6937777996063232\n",
            "Iteration 110, Loss: 2.476627826690674\n",
            "Iteration 120, Loss: 2.4729135036468506\n",
            "Iteration 130, Loss: 2.4282376766204834\n",
            "Iteration 140, Loss: 2.4248557090759277\n",
            "Iteration 150, Loss: 2.3898582458496094\n",
            "Iteration 160, Loss: 2.2973978519439697\n",
            "Iteration 170, Loss: 2.452793598175049\n",
            "Iteration 180, Loss: 2.396714687347412\n",
            "Iteration 190, Loss: 2.409693956375122\n",
            "Iteration 200, Loss: 2.420456886291504\n",
            "Iteration 200, Train Perplexity: 10.591346740722656, Validation Perplexity: 10.606771469116211\n",
            "Iteration 210, Loss: 2.3910419940948486\n",
            "Iteration 220, Loss: 2.313185453414917\n",
            "Iteration 230, Loss: 2.2595560550689697\n",
            "Iteration 240, Loss: 2.2987232208251953\n",
            "Iteration 250, Loss: 2.300966739654541\n",
            "Iteration 260, Loss: 2.3717520236968994\n",
            "Iteration 270, Loss: 2.2965128421783447\n",
            "Iteration 280, Loss: 2.2952842712402344\n",
            "Iteration 290, Loss: 2.2772269248962402\n",
            "Iteration 300, Loss: 2.4138259887695312\n",
            "Iteration 310, Loss: 2.2240920066833496\n",
            "Iteration 320, Loss: 2.270430564880371\n",
            "Iteration 330, Loss: 2.2732744216918945\n",
            "Iteration 340, Loss: 2.1928532123565674\n",
            "Iteration 350, Loss: 2.257779836654663\n",
            "Iteration 360, Loss: 2.2143871784210205\n",
            "Iteration 370, Loss: 2.2528672218322754\n",
            "Iteration 380, Loss: 2.134897470474243\n",
            "Iteration 390, Loss: 2.042914867401123\n",
            "Iteration 400, Loss: 2.20512318611145\n",
            "Iteration 400, Train Perplexity: 8.709253311157227, Validation Perplexity: 8.952701568603516\n",
            "Iteration 410, Loss: 2.1036784648895264\n",
            "Iteration 420, Loss: 2.2496347427368164\n",
            "Iteration 430, Loss: 2.188239574432373\n",
            "Iteration 440, Loss: 2.2115306854248047\n",
            "Iteration 450, Loss: 2.202322483062744\n",
            "Iteration 460, Loss: 2.187089204788208\n",
            "Iteration 470, Loss: 2.1380393505096436\n",
            "Iteration 480, Loss: 2.212322235107422\n",
            "Iteration 490, Loss: 2.080671787261963\n",
            "Iteration 500, Loss: 2.0415072441101074\n",
            "Iteration 510, Loss: 2.067089080810547\n",
            "Iteration 520, Loss: 1.9742263555526733\n",
            "Iteration 530, Loss: 2.0540149211883545\n",
            "Iteration 540, Loss: 2.008930206298828\n",
            "Iteration 550, Loss: 2.0702507495880127\n",
            "Iteration 560, Loss: 2.1194467544555664\n",
            "Iteration 570, Loss: 2.037036657333374\n",
            "Iteration 580, Loss: 2.100799560546875\n",
            "Iteration 590, Loss: 2.1197423934936523\n",
            "Iteration 600, Loss: 2.028907299041748\n",
            "Iteration 600, Train Perplexity: 7.694146633148193, Validation Perplexity: 8.052651405334473\n",
            "Iteration 610, Loss: 1.9493751525878906\n",
            "Iteration 620, Loss: 1.9185924530029297\n",
            "Iteration 630, Loss: 2.1082043647766113\n",
            "Iteration 640, Loss: 2.0623650550842285\n",
            "Iteration 650, Loss: 2.0159144401550293\n",
            "Iteration 660, Loss: 2.0600597858428955\n",
            "Iteration 670, Loss: 1.8757691383361816\n",
            "Iteration 680, Loss: 2.045431137084961\n",
            "Iteration 690, Loss: 2.0718560218811035\n",
            "Iteration 700, Loss: 1.8695814609527588\n",
            "Iteration 710, Loss: 2.0770630836486816\n",
            "Iteration 720, Loss: 1.9774807691574097\n",
            "Iteration 730, Loss: 1.981897234916687\n",
            "Iteration 740, Loss: 2.0218024253845215\n",
            "Iteration 750, Loss: 2.040308952331543\n",
            "Iteration 760, Loss: 2.0645835399627686\n",
            "Iteration 770, Loss: 1.8541066646575928\n",
            "Iteration 780, Loss: 1.9380269050598145\n",
            "Iteration 790, Loss: 2.016158103942871\n",
            "Iteration 800, Loss: 1.9671651124954224\n",
            "Iteration 800, Train Perplexity: 6.886058807373047, Validation Perplexity: 7.5361647605896\n",
            "Iteration 810, Loss: 1.9353998899459839\n",
            "Iteration 820, Loss: 1.903367280960083\n",
            "Iteration 830, Loss: 1.9190165996551514\n",
            "Iteration 840, Loss: 1.8787510395050049\n",
            "Iteration 850, Loss: 1.9160388708114624\n",
            "Iteration 860, Loss: 2.028571128845215\n",
            "Iteration 870, Loss: 1.9570821523666382\n",
            "Iteration 880, Loss: 1.9292725324630737\n",
            "Iteration 890, Loss: 1.9569257497787476\n",
            "Iteration 900, Loss: 1.8659067153930664\n",
            "Iteration 910, Loss: 1.8929107189178467\n",
            "Iteration 920, Loss: 1.8114814758300781\n",
            "Iteration 930, Loss: 1.7873413562774658\n",
            "Iteration 940, Loss: 1.9503344297409058\n",
            "Iteration 950, Loss: 1.8884986639022827\n",
            "Iteration 960, Loss: 1.8816747665405273\n",
            "Iteration 970, Loss: 1.891701579093933\n",
            "Iteration 980, Loss: 1.8543680906295776\n",
            "Iteration 990, Loss: 1.801856279373169\n",
            "Iteration 1000, Loss: 1.8187693357467651\n",
            "Iteration 1000, Train Perplexity: 6.397887706756592, Validation Perplexity: 7.147303581237793\n",
            "Iteration 1010, Loss: 1.8002794981002808\n",
            "Iteration 1020, Loss: 1.9281421899795532\n",
            "Iteration 1030, Loss: 1.9109846353530884\n",
            "Iteration 1040, Loss: 1.86422860622406\n",
            "Iteration 1050, Loss: 1.8352582454681396\n",
            "Iteration 1060, Loss: 1.7936071157455444\n",
            "Iteration 1070, Loss: 1.8317992687225342\n",
            "Iteration 1080, Loss: 1.8059781789779663\n",
            "Iteration 1090, Loss: 1.7949684858322144\n",
            "Iteration 1100, Loss: 1.7601689100265503\n",
            "Iteration 1110, Loss: 1.7779550552368164\n",
            "Iteration 1120, Loss: 1.9027514457702637\n",
            "Iteration 1130, Loss: 1.8127690553665161\n",
            "Iteration 1140, Loss: 1.7965037822723389\n",
            "Iteration 1150, Loss: 1.797724962234497\n",
            "Iteration 1160, Loss: 1.7121050357818604\n",
            "Iteration 1170, Loss: 1.8987175226211548\n",
            "Iteration 1180, Loss: 1.904488205909729\n",
            "Iteration 1190, Loss: 1.7437492609024048\n",
            "Iteration 1200, Loss: 1.6622189283370972\n",
            "Iteration 1200, Train Perplexity: 6.003400802612305, Validation Perplexity: 6.867650508880615\n",
            "Iteration 1210, Loss: 1.8471001386642456\n",
            "Iteration 1220, Loss: 1.8778530359268188\n",
            "Iteration 1230, Loss: 1.6854925155639648\n",
            "Iteration 1240, Loss: 1.8453305959701538\n",
            "Iteration 1250, Loss: 1.70964777469635\n",
            "Iteration 1260, Loss: 1.7832220792770386\n",
            "Iteration 1270, Loss: 1.8380811214447021\n",
            "Iteration 1280, Loss: 1.7477353811264038\n",
            "Iteration 1290, Loss: 1.8702950477600098\n",
            "Iteration 1300, Loss: 1.6326481103897095\n",
            "Iteration 1310, Loss: 1.8633984327316284\n",
            "Iteration 1320, Loss: 1.788527011871338\n",
            "Iteration 1330, Loss: 1.9371283054351807\n",
            "Iteration 1340, Loss: 1.8833656311035156\n",
            "Iteration 1350, Loss: 1.711557149887085\n",
            "Iteration 1360, Loss: 1.753708004951477\n",
            "Iteration 1370, Loss: 1.740058183670044\n",
            "Iteration 1380, Loss: 1.7660902738571167\n",
            "Iteration 1390, Loss: 1.9411152601242065\n",
            "Iteration 1400, Loss: 1.816856026649475\n",
            "Iteration 1400, Train Perplexity: 5.865738868713379, Validation Perplexity: 6.702291488647461\n",
            "Iteration 1410, Loss: 1.7228962182998657\n",
            "Iteration 1420, Loss: 1.7226899862289429\n",
            "Iteration 1430, Loss: 1.7023990154266357\n",
            "Iteration 1440, Loss: 1.748600721359253\n",
            "Iteration 1450, Loss: 1.7417323589324951\n",
            "Iteration 1460, Loss: 1.7889273166656494\n",
            "Iteration 1470, Loss: 1.8604907989501953\n",
            "Iteration 1480, Loss: 1.6116567850112915\n",
            "Iteration 1490, Loss: 1.6862101554870605\n",
            "Iteration 1500, Loss: 1.8558382987976074\n",
            "Iteration 1510, Loss: 1.5906872749328613\n",
            "Iteration 1520, Loss: 1.8826583623886108\n",
            "Iteration 1530, Loss: 1.7431833744049072\n",
            "Iteration 1540, Loss: 1.6937700510025024\n",
            "Iteration 1550, Loss: 1.6955012083053589\n",
            "Iteration 1560, Loss: 1.6868274211883545\n",
            "Iteration 1570, Loss: 1.6395905017852783\n",
            "Iteration 1580, Loss: 1.8013346195220947\n",
            "Iteration 1590, Loss: 1.6072791814804077\n",
            "Iteration 1600, Loss: 1.7133313417434692\n",
            "Iteration 1600, Train Perplexity: 5.617686748504639, Validation Perplexity: 6.570304870605469\n",
            "Iteration 1610, Loss: 1.7085438966751099\n",
            "Iteration 1620, Loss: 1.7068278789520264\n",
            "Iteration 1630, Loss: 1.762445330619812\n",
            "Iteration 1640, Loss: 1.7229195833206177\n",
            "Iteration 1650, Loss: 1.7713638544082642\n",
            "Iteration 1660, Loss: 1.89414644241333\n",
            "Iteration 1670, Loss: 1.7595241069793701\n",
            "Iteration 1680, Loss: 1.7857943773269653\n",
            "Iteration 1690, Loss: 1.6900447607040405\n",
            "Iteration 1700, Loss: 1.5144340991973877\n",
            "Iteration 1710, Loss: 1.7403812408447266\n",
            "Iteration 1720, Loss: 1.7094954252243042\n",
            "Iteration 1730, Loss: 1.8250689506530762\n",
            "Iteration 1740, Loss: 1.7039251327514648\n",
            "Iteration 1750, Loss: 1.7257282733917236\n",
            "Iteration 1760, Loss: 1.5052012205123901\n",
            "Iteration 1770, Loss: 1.7822471857070923\n",
            "Iteration 1780, Loss: 1.7515934705734253\n",
            "Iteration 1790, Loss: 1.6562687158584595\n",
            "Iteration 1800, Loss: 1.8225198984146118\n",
            "Iteration 1800, Train Perplexity: 5.433904647827148, Validation Perplexity: 6.359748363494873\n",
            "Iteration 1810, Loss: 1.715034008026123\n",
            "Iteration 1820, Loss: 1.735809326171875\n",
            "Iteration 1830, Loss: 1.7930690050125122\n",
            "Iteration 1840, Loss: 1.5454493761062622\n",
            "Iteration 1850, Loss: 1.697428584098816\n",
            "Iteration 1860, Loss: 1.8407024145126343\n",
            "Iteration 1870, Loss: 1.6861166954040527\n",
            "Iteration 1880, Loss: 1.6655428409576416\n",
            "Iteration 1890, Loss: 1.8190165758132935\n",
            "Iteration 1900, Loss: 1.6415081024169922\n",
            "Iteration 1910, Loss: 1.7127685546875\n",
            "Iteration 1920, Loss: 1.7391210794448853\n",
            "Iteration 1930, Loss: 1.7032140493392944\n",
            "Iteration 1940, Loss: 1.7592227458953857\n",
            "Iteration 1950, Loss: 1.7053998708724976\n",
            "Iteration 1960, Loss: 1.6751456260681152\n",
            "Iteration 1970, Loss: 1.7238608598709106\n",
            "Iteration 1980, Loss: 1.6938892602920532\n",
            "Iteration 1990, Loss: 1.6978613138198853\n",
            "Iteration 2000, Loss: 1.6601289510726929\n",
            "Iteration 2000, Train Perplexity: 5.282577037811279, Validation Perplexity: 6.205750942230225\n",
            "Iteration 2010, Loss: 1.643031120300293\n",
            "Iteration 2020, Loss: 1.7710317373275757\n",
            "Iteration 2030, Loss: 1.560203194618225\n",
            "Iteration 2040, Loss: 1.6736693382263184\n",
            "Iteration 2050, Loss: 1.794024109840393\n",
            "Iteration 2060, Loss: 1.7390310764312744\n",
            "Iteration 2070, Loss: 1.6726324558258057\n",
            "Iteration 2080, Loss: 1.5903842449188232\n",
            "Iteration 2090, Loss: 1.639108657836914\n",
            "Iteration 2100, Loss: 1.7495694160461426\n",
            "Iteration 2110, Loss: 1.7093569040298462\n",
            "Iteration 2120, Loss: 1.688795566558838\n",
            "Iteration 2130, Loss: 1.6367765665054321\n",
            "Iteration 2140, Loss: 1.6398568153381348\n",
            "Iteration 2150, Loss: 1.6463513374328613\n",
            "Iteration 2160, Loss: 1.6176730394363403\n",
            "Iteration 2170, Loss: 1.560515284538269\n",
            "Iteration 2180, Loss: 1.7048193216323853\n",
            "Iteration 2190, Loss: 1.696398377418518\n",
            "Iteration 2200, Loss: 1.6984437704086304\n",
            "Iteration 2200, Train Perplexity: 5.292314052581787, Validation Perplexity: 6.255415439605713\n",
            "Iteration 2210, Loss: 1.7968448400497437\n",
            "Iteration 2220, Loss: 1.6702630519866943\n",
            "Iteration 2230, Loss: 1.69352126121521\n",
            "Iteration 2240, Loss: 1.6564130783081055\n",
            "Iteration 2250, Loss: 1.6558531522750854\n",
            "Iteration 2260, Loss: 1.695151686668396\n",
            "Iteration 2270, Loss: 1.6562031507492065\n",
            "Iteration 2280, Loss: 1.748368263244629\n",
            "Iteration 2290, Loss: 1.7295440435409546\n",
            "Iteration 2300, Loss: 1.6023154258728027\n",
            "Iteration 2310, Loss: 1.6928391456604004\n",
            "Iteration 2320, Loss: 1.5258913040161133\n",
            "Iteration 2330, Loss: 1.5421639680862427\n",
            "Iteration 2350, Loss: 1.5770187377929688\n",
            "Iteration 2360, Loss: 1.5709246397018433\n",
            "Iteration 2370, Loss: 1.574850082397461\n",
            "Iteration 2380, Loss: 1.853284478187561\n",
            "Iteration 2390, Loss: 1.60780668258667\n",
            "Iteration 2400, Loss: 1.5413247346878052\n",
            "Iteration 2400, Train Perplexity: 5.10595178604126, Validation Perplexity: 6.035630702972412\n",
            "Iteration 2410, Loss: 1.6385456323623657\n",
            "Iteration 2420, Loss: 1.5697575807571411\n",
            "Iteration 2430, Loss: 1.7425323724746704\n",
            "Iteration 2440, Loss: 1.772132396697998\n",
            "Iteration 2450, Loss: 1.6409715414047241\n",
            "Iteration 2460, Loss: 1.740319013595581\n",
            "Iteration 2470, Loss: 1.5571482181549072\n",
            "Iteration 2480, Loss: 1.4789206981658936\n",
            "Iteration 2490, Loss: 1.6260234117507935\n",
            "Iteration 2500, Loss: 1.5524859428405762\n",
            "Iteration 2510, Loss: 1.5914419889450073\n",
            "Iteration 2520, Loss: 1.5959306955337524\n",
            "Iteration 2530, Loss: 1.6723651885986328\n",
            "Iteration 2540, Loss: 1.4784066677093506\n",
            "Iteration 2550, Loss: 1.6450260877609253\n",
            "Iteration 2560, Loss: 1.603529453277588\n",
            "Iteration 2570, Loss: 1.6087045669555664\n",
            "Iteration 2580, Loss: 1.655799150466919\n",
            "Iteration 2590, Loss: 1.5885682106018066\n",
            "Iteration 2600, Loss: 1.616153359413147\n",
            "Iteration 2600, Train Perplexity: 5.064214706420898, Validation Perplexity: 5.879065036773682\n",
            "Iteration 2610, Loss: 1.634244680404663\n",
            "Iteration 2620, Loss: 1.6627223491668701\n",
            "Iteration 2630, Loss: 1.589675784111023\n",
            "Iteration 2640, Loss: 1.6929935216903687\n",
            "Iteration 2650, Loss: 1.6954853534698486\n",
            "Iteration 2660, Loss: 1.5668319463729858\n",
            "Iteration 2670, Loss: 1.6640926599502563\n",
            "Iteration 2680, Loss: 1.7451722621917725\n",
            "Iteration 2690, Loss: 1.6500383615493774\n",
            "Iteration 2700, Loss: 1.7980097532272339\n",
            "Iteration 2710, Loss: 1.749907374382019\n",
            "Iteration 2720, Loss: 1.680030345916748\n",
            "Iteration 2730, Loss: 1.6221339702606201\n",
            "Iteration 2740, Loss: 1.745161533355713\n",
            "Iteration 2750, Loss: 1.7005664110183716\n",
            "Iteration 2760, Loss: 1.5996513366699219\n",
            "Iteration 2770, Loss: 1.5654762983322144\n",
            "Iteration 2780, Loss: 1.5289244651794434\n",
            "Iteration 2790, Loss: 1.6996623277664185\n",
            "Iteration 2800, Loss: 1.5909016132354736\n",
            "Iteration 2800, Train Perplexity: 4.945454120635986, Validation Perplexity: 5.986645698547363\n",
            "Iteration 2810, Loss: 1.661522626876831\n",
            "Iteration 2820, Loss: 1.6731349229812622\n",
            "Iteration 2830, Loss: 1.6200119256973267\n",
            "Iteration 2840, Loss: 1.628833293914795\n",
            "Iteration 2850, Loss: 1.6497254371643066\n",
            "Iteration 2860, Loss: 1.5878247022628784\n",
            "Iteration 2870, Loss: 1.6497999429702759\n",
            "Iteration 2880, Loss: 1.5533069372177124\n",
            "Iteration 2890, Loss: 1.6055878400802612\n",
            "Iteration 2900, Loss: 1.6063710451126099\n",
            "Iteration 2910, Loss: 1.6010234355926514\n",
            "Iteration 2920, Loss: 1.665507435798645\n",
            "Iteration 2930, Loss: 1.61795175075531\n",
            "Iteration 2940, Loss: 1.6666773557662964\n",
            "Iteration 2950, Loss: 1.584008812904358\n",
            "Iteration 2960, Loss: 1.8080503940582275\n",
            "Iteration 2970, Loss: 1.6396876573562622\n",
            "Iteration 2980, Loss: 1.6194387674331665\n",
            "Iteration 2990, Loss: 1.6382994651794434\n",
            "Iteration 3000, Loss: 1.637507677078247\n",
            "Iteration 3000, Train Perplexity: 4.945940971374512, Validation Perplexity: 5.850175857543945\n",
            "Iteration 3010, Loss: 1.542595386505127\n",
            "Iteration 3020, Loss: 1.657370924949646\n",
            "Iteration 3030, Loss: 1.5897448062896729\n",
            "Iteration 3040, Loss: 1.605282187461853\n",
            "Iteration 3050, Loss: 1.7734596729278564\n",
            "Iteration 3060, Loss: 1.644216775894165\n",
            "Iteration 3070, Loss: 1.5926332473754883\n",
            "Iteration 3080, Loss: 1.6781339645385742\n",
            "Iteration 3090, Loss: 1.6274164915084839\n",
            "Iteration 3100, Loss: 1.628511667251587\n",
            "Iteration 3110, Loss: 1.755427360534668\n",
            "Iteration 3120, Loss: 1.5628585815429688\n",
            "Iteration 3130, Loss: 1.46530020236969\n",
            "Iteration 3140, Loss: 1.6882293224334717\n",
            "Iteration 3150, Loss: 1.5021001100540161\n",
            "Iteration 3160, Loss: 1.6752842664718628\n",
            "Iteration 3170, Loss: 1.5355937480926514\n",
            "Iteration 3180, Loss: 1.8332380056381226\n",
            "Iteration 3190, Loss: 1.614809274673462\n",
            "Iteration 3200, Loss: 1.555455207824707\n",
            "Iteration 3200, Train Perplexity: 4.802622318267822, Validation Perplexity: 5.725876331329346\n",
            "Iteration 3210, Loss: 1.624546766281128\n",
            "Iteration 3220, Loss: 1.4959944486618042\n",
            "Iteration 3230, Loss: 1.5336542129516602\n",
            "Iteration 3240, Loss: 1.6854743957519531\n",
            "Iteration 3250, Loss: 1.5960261821746826\n",
            "Iteration 3260, Loss: 1.5847601890563965\n",
            "Iteration 3270, Loss: 1.6043256521224976\n",
            "Iteration 3280, Loss: 1.573197364807129\n",
            "Iteration 3290, Loss: 1.5896081924438477\n",
            "Iteration 3300, Loss: 1.6445035934448242\n",
            "Iteration 3310, Loss: 1.6122769117355347\n",
            "Iteration 3320, Loss: 1.449269413948059\n",
            "Iteration 3330, Loss: 1.5993760824203491\n",
            "Iteration 3340, Loss: 1.6092585325241089\n",
            "Iteration 3350, Loss: 1.6544854640960693\n",
            "Iteration 3360, Loss: 1.5419161319732666\n",
            "Iteration 3370, Loss: 1.6420892477035522\n",
            "Iteration 3380, Loss: 1.4179439544677734\n",
            "Iteration 3390, Loss: 1.6066919565200806\n",
            "Iteration 3400, Loss: 1.5294355154037476\n",
            "Iteration 3400, Train Perplexity: 4.810410499572754, Validation Perplexity: 5.729031085968018\n",
            "Iteration 3410, Loss: 1.567691683769226\n",
            "Iteration 3420, Loss: 1.6501150131225586\n",
            "Iteration 3430, Loss: 1.5902111530303955\n",
            "Iteration 3440, Loss: 1.4401509761810303\n",
            "Iteration 3450, Loss: 1.6184704303741455\n",
            "Iteration 3460, Loss: 1.6298664808273315\n",
            "Iteration 3470, Loss: 1.4776157140731812\n",
            "Iteration 3480, Loss: 1.5545408725738525\n",
            "Iteration 3490, Loss: 1.5025086402893066\n",
            "Iteration 3500, Loss: 1.6294547319412231\n",
            "Iteration 3510, Loss: 1.5962411165237427\n",
            "Iteration 3520, Loss: 1.6390734910964966\n",
            "Iteration 3530, Loss: 1.5059232711791992\n",
            "Iteration 3540, Loss: 1.467673659324646\n",
            "Iteration 3550, Loss: 1.6555238962173462\n",
            "Iteration 3560, Loss: 1.5984402894973755\n",
            "Iteration 3570, Loss: 1.555971622467041\n",
            "Iteration 3580, Loss: 1.6642810106277466\n",
            "Iteration 3590, Loss: 1.5437953472137451\n",
            "Iteration 3600, Loss: 1.5992406606674194\n",
            "Iteration 3600, Train Perplexity: 4.751794338226318, Validation Perplexity: 5.665069580078125\n",
            "Iteration 3610, Loss: 1.5118153095245361\n",
            "Iteration 3620, Loss: 1.5920238494873047\n",
            "Iteration 3630, Loss: 1.5672661066055298\n",
            "Iteration 3640, Loss: 1.6398426294326782\n",
            "Iteration 3650, Loss: 1.5343775749206543\n",
            "Iteration 3660, Loss: 1.485258936882019\n",
            "Iteration 3670, Loss: 1.601462483406067\n",
            "Iteration 3680, Loss: 1.431445598602295\n",
            "Iteration 3690, Loss: 1.4810062646865845\n",
            "Iteration 3700, Loss: 1.506234884262085\n",
            "Iteration 3710, Loss: 1.5553224086761475\n",
            "Iteration 3720, Loss: 1.5320528745651245\n",
            "Iteration 3730, Loss: 1.4892109632492065\n",
            "Iteration 3740, Loss: 1.4667093753814697\n",
            "Iteration 3750, Loss: 1.640118956565857\n",
            "Iteration 3760, Loss: 1.475338339805603\n",
            "Iteration 3770, Loss: 1.5007609128952026\n",
            "Iteration 3780, Loss: 1.4260526895523071\n",
            "Iteration 3790, Loss: 1.7085802555084229\n",
            "Iteration 3800, Loss: 1.452719807624817\n",
            "Iteration 3800, Train Perplexity: 4.7971625328063965, Validation Perplexity: 5.6784234046936035\n",
            "Iteration 3810, Loss: 1.5918693542480469\n",
            "Iteration 3820, Loss: 1.4823272228240967\n",
            "Iteration 3830, Loss: 1.525309443473816\n",
            "Iteration 3840, Loss: 1.573488473892212\n",
            "Iteration 3850, Loss: 1.561442494392395\n",
            "Iteration 3860, Loss: 1.6208676099777222\n",
            "Iteration 3870, Loss: 1.471591830253601\n",
            "Iteration 3880, Loss: 1.525437831878662\n",
            "Iteration 3890, Loss: 1.510247826576233\n",
            "Iteration 3900, Loss: 1.447756052017212\n",
            "Iteration 3910, Loss: 1.4843231439590454\n",
            "Iteration 3920, Loss: 1.584075927734375\n",
            "Iteration 3930, Loss: 1.5539233684539795\n",
            "Iteration 3940, Loss: 1.5926539897918701\n",
            "Iteration 3950, Loss: 1.4975197315216064\n",
            "Iteration 3960, Loss: 1.5498266220092773\n",
            "Iteration 3970, Loss: 1.505298137664795\n",
            "Iteration 3980, Loss: 1.6369115114212036\n",
            "Iteration 3990, Loss: 1.4868226051330566\n",
            "Iteration 4000, Loss: 1.4853949546813965\n",
            "Iteration 4000, Train Perplexity: 4.67598819732666, Validation Perplexity: 5.597718238830566\n",
            "Iteration 4010, Loss: 1.4293930530548096\n",
            "Iteration 4020, Loss: 1.5711464881896973\n",
            "Iteration 4030, Loss: 1.5422720909118652\n",
            "Iteration 4040, Loss: 1.5880452394485474\n",
            "Iteration 4050, Loss: 1.400713562965393\n",
            "Iteration 4060, Loss: 1.4298609495162964\n",
            "Iteration 4070, Loss: 1.4409418106079102\n",
            "Iteration 4080, Loss: 1.5823912620544434\n",
            "Iteration 4090, Loss: 1.5737167596817017\n",
            "Iteration 4100, Loss: 1.53632390499115\n",
            "Iteration 4110, Loss: 1.649886965751648\n",
            "Iteration 4120, Loss: 1.5864574909210205\n",
            "Iteration 4130, Loss: 1.5710023641586304\n",
            "Iteration 4140, Loss: 1.6117316484451294\n",
            "Iteration 4150, Loss: 1.39382004737854\n",
            "Iteration 4160, Loss: 1.5751253366470337\n",
            "Iteration 4170, Loss: 1.5480889081954956\n",
            "Iteration 4180, Loss: 1.4405808448791504\n",
            "Iteration 4190, Loss: 1.3791955709457397\n",
            "Iteration 4200, Loss: 1.348254680633545\n",
            "Iteration 4200, Train Perplexity: 4.602262496948242, Validation Perplexity: 5.562556266784668\n",
            "Iteration 4210, Loss: 1.523854374885559\n",
            "Iteration 4220, Loss: 1.5635769367218018\n",
            "Iteration 4230, Loss: 1.6973862648010254\n",
            "Iteration 4240, Loss: 1.4121156930923462\n",
            "Iteration 4250, Loss: 1.5310142040252686\n",
            "Iteration 4260, Loss: 1.4540561437606812\n",
            "Iteration 4270, Loss: 1.43105947971344\n",
            "Iteration 4280, Loss: 1.5223959684371948\n",
            "Iteration 4290, Loss: 1.4712005853652954\n",
            "Iteration 4300, Loss: 1.5805237293243408\n",
            "Iteration 4310, Loss: 1.420019268989563\n",
            "Iteration 4320, Loss: 1.497223973274231\n",
            "Iteration 4330, Loss: 1.5950310230255127\n",
            "Iteration 4340, Loss: 1.5614750385284424\n",
            "Iteration 4350, Loss: 1.5309799909591675\n",
            "Iteration 4360, Loss: 1.5386487245559692\n",
            "Iteration 4370, Loss: 1.7187516689300537\n",
            "Iteration 4380, Loss: 1.5908985137939453\n",
            "Iteration 4390, Loss: 1.4600896835327148\n",
            "Iteration 4400, Loss: 1.6189517974853516\n",
            "Iteration 4400, Train Perplexity: 4.6664581298828125, Validation Perplexity: 5.567027568817139\n",
            "Iteration 4410, Loss: 1.5976189374923706\n",
            "Iteration 4420, Loss: 1.5572094917297363\n",
            "Iteration 4430, Loss: 1.5170867443084717\n",
            "Iteration 4440, Loss: 1.456176996231079\n",
            "Iteration 4450, Loss: 1.487122654914856\n",
            "Iteration 4460, Loss: 1.589442253112793\n",
            "Iteration 4470, Loss: 1.44879949092865\n",
            "Iteration 4480, Loss: 1.4866900444030762\n",
            "Iteration 4490, Loss: 1.5619608163833618\n",
            "Iteration 4500, Loss: 1.4936660528182983\n",
            "Iteration 4510, Loss: 1.602225661277771\n",
            "Iteration 4520, Loss: 1.4881690740585327\n",
            "Iteration 4530, Loss: 1.4344090223312378\n",
            "Iteration 4540, Loss: 1.5664199590682983\n",
            "Iteration 4550, Loss: 1.4192923307418823\n",
            "Iteration 4560, Loss: 1.5504117012023926\n",
            "Iteration 4570, Loss: 1.551766276359558\n",
            "Iteration 4580, Loss: 1.5139631032943726\n",
            "Iteration 4590, Loss: 1.4334131479263306\n",
            "Iteration 4600, Loss: 1.5344618558883667\n",
            "Iteration 4600, Train Perplexity: 4.610272407531738, Validation Perplexity: 5.4793806076049805\n",
            "Iteration 4610, Loss: 1.5590057373046875\n",
            "Iteration 4620, Loss: 1.504818081855774\n",
            "Iteration 4630, Loss: 1.586776852607727\n",
            "Iteration 4640, Loss: 1.6443161964416504\n",
            "Iteration 4650, Loss: 1.54026460647583\n",
            "Iteration 4660, Loss: 1.670638084411621\n",
            "Iteration 4670, Loss: 1.6079325675964355\n",
            "Iteration 4680, Loss: 1.5709458589553833\n",
            "Iteration 4690, Loss: 1.561449408531189\n",
            "Iteration 4700, Loss: 1.5214321613311768\n",
            "Iteration 4710, Loss: 1.5228033065795898\n",
            "Iteration 4720, Loss: 1.5536596775054932\n",
            "Iteration 4730, Loss: 1.4268202781677246\n",
            "Iteration 4740, Loss: 1.456964135169983\n",
            "Iteration 4750, Loss: 1.4651590585708618\n",
            "Iteration 4760, Loss: 1.6440176963806152\n",
            "Iteration 4770, Loss: 1.446424126625061\n",
            "Iteration 4780, Loss: 1.6162123680114746\n",
            "Iteration 4790, Loss: 1.5230531692504883\n",
            "Iteration 4800, Loss: 1.5693973302841187\n",
            "Iteration 4800, Train Perplexity: 4.54358434677124, Validation Perplexity: 5.373610496520996\n",
            "Iteration 4810, Loss: 1.6848015785217285\n",
            "Iteration 4820, Loss: 1.5197829008102417\n",
            "Iteration 4830, Loss: 1.4192978143692017\n",
            "Iteration 4840, Loss: 1.5799866914749146\n",
            "Iteration 4850, Loss: 1.44802725315094\n",
            "Iteration 4860, Loss: 1.4626497030258179\n",
            "Iteration 4870, Loss: 1.4083049297332764\n",
            "Iteration 4880, Loss: 1.4939393997192383\n",
            "Iteration 4890, Loss: 1.506916880607605\n",
            "Iteration 4900, Loss: 1.4262969493865967\n",
            "Iteration 4910, Loss: 1.4418506622314453\n",
            "Iteration 4920, Loss: 1.583636999130249\n",
            "Iteration 4930, Loss: 1.5521814823150635\n",
            "Iteration 4940, Loss: 1.4713202714920044\n",
            "Iteration 4950, Loss: 1.5362181663513184\n",
            "Iteration 4960, Loss: 1.4111729860305786\n",
            "Iteration 4970, Loss: 1.5554931163787842\n",
            "Iteration 4980, Loss: 1.4097355604171753\n",
            "Iteration 4990, Loss: 1.350497841835022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Perplexity', marker='o')\n",
        "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Perplexity', marker='x')\n",
        "plt.title('Perplexity over Training Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "2eg-5Fv3YjOM",
        "outputId": "a2fc4c67-9107-48c6-89b6-ca3b9497c10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This definitely makes a wild difference in terms of the change in perplexity. It makes sense though, because with a wildly larger number of embeddings, the model has more data to learn from and would naturally be more confused / less confident in the beginning of the training procedure. Something that I would be concerned about with the increased number of embeddings would be overfitting."
      ],
      "metadata": {
        "id": "HI3-3LTffQAI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}