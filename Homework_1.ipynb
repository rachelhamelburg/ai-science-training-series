{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachelhamelburg/ai-science-training-series/blob/main/Homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SqCuHnP7Jxz"
      },
      "source": [
        "### Let's write an elementary tokenizer that uses words as tokens.\n",
        "\n",
        "We will use Mark Twain's _Life On The Mississippi_ as a test bed. The text is in the accompanying file 'Life_On_The_Mississippi.txt'\n",
        "\n",
        "Here's a not-terribly-good such tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBlJhxxW7Jx0",
        "outputId": "c23c046e-b5c6-4e84-f9b3-d183824ba1be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\ufeffThe', 1)\n",
            "('Project', 79)\n",
            "('Gutenberg', 22)\n",
            "('eBook', 4)\n",
            "('of', 4469)\n",
            "('Life', 5)\n",
            "('on', 856)\n",
            "('the', 8443)\n",
            "('Mississippi', 104)\n",
            "('This', 127)\n",
            "('ebook', 2)\n",
            "('is', 1076)\n",
            "('for', 1017)\n",
            "('use', 34)\n",
            "('anyone', 4)\n",
            "('anywhere', 8)\n",
            "('in', 2381)\n",
            "('United', 36)\n",
            "('States', 26)\n",
            "('and', 5692)\n",
            "('most', 119)\n",
            "('other', 223)\n",
            "('parts', 5)\n",
            "('world', 40)\n",
            "('at', 676)\n",
            "('no', 325)\n",
            "('cost', 18)\n",
            "('with', 1053)\n",
            "('almost', 37)\n",
            "('restrictions', 2)\n",
            "('whatsoever.', 2)\n",
            "('You', 92)\n",
            "('may', 85)\n",
            "('copy', 12)\n",
            "('it,', 199)\n",
            "('give', 67)\n",
            "('it', 1382)\n",
            "('away', 107)\n",
            "('or', 561)\n",
            "('re-use', 2)\n",
            "('under', 112)\n",
            "('terms', 22)\n",
            "('License', 8)\n",
            "('included', 2)\n",
            "('this', 591)\n",
            "('online', 4)\n",
            "('www.gutenberg.org.', 4)\n",
            "('If', 85)\n",
            "('you', 813)\n",
            "('are', 361)\n",
            "('not', 680)\n",
            "('located', 9)\n",
            "('States,', 8)\n",
            "('will', 287)\n",
            "('have', 557)\n",
            "('to', 3518)\n",
            "('check', 4)\n",
            "('laws', 13)\n",
            "('country', 50)\n",
            "('where', 152)\n",
            "('before', 150)\n",
            "('using', 10)\n",
            "('eBook.', 2)\n",
            "('Title:', 1)\n",
            "('Author:', 1)\n",
            "('Mark', 2)\n",
            "('Twain', 2)\n",
            "('Release', 1)\n",
            "('date:', 1)\n",
            "('July', 7)\n",
            "('10,', 2)\n",
            "('2004', 1)\n",
            "('[eBook', 1)\n",
            "('#245]', 1)\n",
            "('Most', 4)\n",
            "('recently', 3)\n",
            "('updated:', 1)\n",
            "('January', 2)\n",
            "('1,', 2)\n",
            "('2021', 1)\n",
            "('Language:', 1)\n",
            "('English', 7)\n",
            "('Credits:', 1)\n",
            "('Produced', 2)\n",
            "('by', 623)\n",
            "('David', 2)\n",
            "('Widger.', 2)\n",
            "('Earliest', 2)\n",
            "('PG', 3)\n",
            "('text', 4)\n",
            "('edition', 3)\n",
            "('produced', 15)\n",
            "('Graham', 2)\n",
            "('Allan', 2)\n",
            "('***', 4)\n",
            "('START', 1)\n",
            "('OF', 16)\n",
            "('THE', 29)\n",
            "('PROJECT', 4)\n",
            "('GUTENBERG', 3)\n"
          ]
        }
      ],
      "source": [
        "wdict = {}\n",
        "with open('sample_data/Life_On_The_Mississippi.txt', 'r') as L:\n",
        "    line = L.readline()\n",
        "    nlines = 1\n",
        "    while line:\n",
        "\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if wdict.get(word) is not None:\n",
        "                wdict[word] += 1\n",
        "            else:\n",
        "                wdict[word] = 1\n",
        "        line = L.readline()\n",
        "        nlines += 1\n",
        "\n",
        "nitem = 0 ; maxitems = 100\n",
        "for item in wdict.items():\n",
        "    nitem += 1\n",
        "    print(item)\n",
        "    if nitem == maxitems: break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqj8OEl27g5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuMUgd6p7Jx0"
      },
      "source": [
        "This is unsatisfactory for a few reasons:\n",
        "\n",
        "* There are non-ASCII (Unicode) characters that should be stripped (the so-called \"Byte-Order Mark\" or BOM \\ufeff at the beginning of the text);\n",
        "\n",
        "* There are punctuation marks, which we don't want to concern ourselves with;\n",
        "\n",
        "* The same word can appear capitalized, or lower-case, or with its initial letter upper-cased, whereas we want them all to be normalized to lower-case.\n",
        "\n",
        "Part 1 of this assignment: insert code in this loop to operate on the str variable 'line' so as to fix these problems before 'line' is split into words.\n",
        "\n",
        "A hint to one possible way to do this: use the 'punctuation' character definition in the Python 'string' module, the 'maketrans' and 'translate' methods of Python's str class, to eliminate punctuation, and the regular expression ('re') Python module to eliminate any Unicode---it is useful to know that the regular expression r'[^\\x00-x7f]' means \"any character not in the vanilla ASCII set.\n",
        "\n",
        "Part 2: Add code to sort the contents of wdict by word occurrence frequency.  What are the top 100 most frequent word tokens?  Adding up occurrence frequencies starting from the most frequent words, how many distinct words make up the top 90% of word occurrences in this \"corpus\"?\n",
        "\n",
        "For this part, the docs of Python's 'sorted' and of the helper 'itemgetter' from 'operator' reward study.\n",
        "\n",
        "Write your modified code in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll8ifZpS7Jx0",
        "outputId": "282740ab-9111-4d68-8c43-3a86c1b7bd02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('the', 9255)\n",
            "('project', 90)\n",
            "('gutenberg', 87)\n",
            "('ebook', 13)\n",
            "('of', 4532)\n",
            "('life', 89)\n",
            "('on', 947)\n",
            "('mississippi', 159)\n",
            "('this', 781)\n",
            "('is', 1148)\n",
            "('for', 1095)\n",
            "('use', 48)\n",
            "('anyone', 5)\n",
            "('anywhere', 18)\n",
            "('in', 2593)\n",
            "('united', 37)\n",
            "('states', 54)\n",
            "('and', 5892)\n",
            "('most', 124)\n",
            "('other', 270)\n",
            "('parts', 9)\n",
            "('world', 68)\n",
            "('at', 750)\n",
            "('no', 422)\n",
            "('cost', 25)\n",
            "('with', 1081)\n",
            "('almost', 38)\n",
            "('restrictions', 2)\n",
            "('whatsoever', 2)\n",
            "('you', 1033)\n",
            "('may', 89)\n",
            "('copy', 17)\n",
            "('it', 2293)\n",
            "('give', 81)\n",
            "('away', 172)\n",
            "('or', 581)\n",
            "('reuse', 2)\n",
            "('under', 119)\n",
            "('terms', 26)\n",
            "('license', 24)\n",
            "('included', 3)\n",
            "('online', 4)\n",
            "('wwwgutenbergorg', 5)\n",
            "('if', 381)\n",
            "('are', 387)\n",
            "('not', 722)\n",
            "('located', 9)\n",
            "('will', 301)\n",
            "('have', 571)\n",
            "('to', 3592)\n",
            "('check', 4)\n",
            "('laws', 17)\n",
            "('country', 77)\n",
            "('where', 174)\n",
            "('before', 208)\n",
            "('using', 11)\n",
            "('title', 3)\n",
            "('author', 3)\n",
            "('mark', 24)\n",
            "('twain', 26)\n",
            "('release', 1)\n",
            "('date', 18)\n",
            "('july', 7)\n",
            "('10', 10)\n",
            "('2004', 1)\n",
            "('245', 1)\n",
            "('recently', 4)\n",
            "('updated', 2)\n",
            "('january', 3)\n",
            "('1', 13)\n",
            "('2021', 1)\n",
            "('language', 12)\n",
            "('english', 11)\n",
            "('credits', 1)\n",
            "('produced', 22)\n",
            "('by', 713)\n",
            "('david', 2)\n",
            "('widger', 2)\n",
            "('earliest', 7)\n",
            "('pg', 3)\n",
            "('text', 4)\n",
            "('edition', 4)\n",
            "('graham', 2)\n",
            "('allan', 2)\n",
            "('start', 31)\n",
            "('table', 6)\n",
            "('contents', 6)\n",
            "('chapter', 125)\n",
            "('i', 2205)\n",
            "('well', 191)\n",
            "('worth', 37)\n",
            "('reading', 13)\n",
            "('aboutit', 1)\n",
            "('remarkableinstead', 1)\n",
            "('widening', 2)\n",
            "('towards', 9)\n",
            "('its', 323)\n",
            "('mouth', 53)\n",
            "('grows', 3)\n",
            "('narrowerit', 1)\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "wdict = {}\n",
        "\n",
        "with open('sample_data/Life_On_The_Mississippi.txt', 'r') as L:\n",
        "    line = L.readline()\n",
        "    nlines = 1\n",
        "    while line:\n",
        "        line = line.lstrip('\\ufeff')\n",
        "\n",
        "        line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        line = re.sub(r'[^\\x00-\\x7F]+', '', line)\n",
        "\n",
        "        line = line.lower()\n",
        "\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if wdict.get(word) is not None:\n",
        "                wdict[word] += 1\n",
        "            else:\n",
        "                wdict[word] = 1\n",
        "        line = L.readline()\n",
        "        nlines += 1\n",
        "\n",
        "nitem = 0\n",
        "maxitems = 100\n",
        "for item in wdict.items():\n",
        "    nitem += 1\n",
        "    print(item)\n",
        "    if nitem == maxitems:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "sorted_wdict = sorted(wdict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "top_100_words = sorted_wdict[:100]\n",
        "\n",
        "total_occurrences = 0\n",
        "for word, count in sorted_wdict:\n",
        "    total_occurrences += count\n",
        "\n",
        "top_90 = total_occurrences * 0.9\n",
        "occurrences = 0\n",
        "distinct_words = 0\n",
        "\n",
        "for word, count in sorted_wdict:\n",
        "    occurrences += count\n",
        "    distinct_words += 1\n",
        "    if occurrences >= top_90:\n",
        "        break\n",
        "\n",
        "print(\"Top 100:\")\n",
        "for word, count in top_100_words:\n",
        "    print(word, \"-\", count)\n",
        "\n",
        "print(\"\\nDistinct words making up 90% of word occurrences:\", distinct_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw9rkRDI7nV5",
        "outputId": "b98fd59a-d4b2-4de6-9e66-96f3977f5502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100:\n",
            "the - 9255\n",
            "and - 5892\n",
            "of - 4532\n",
            "a - 4053\n",
            "to - 3592\n",
            "in - 2593\n",
            "it - 2293\n",
            "i - 2205\n",
            "was - 2093\n",
            "that - 1724\n",
            "he - 1402\n",
            "is - 1148\n",
            "for - 1095\n",
            "with - 1081\n",
            "you - 1033\n",
            "his - 961\n",
            "had - 961\n",
            "but - 952\n",
            "on - 947\n",
            "as - 881\n",
            "this - 781\n",
            "they - 758\n",
            "at - 750\n",
            "not - 722\n",
            "all - 720\n",
            "by - 713\n",
            "one - 686\n",
            "there - 627\n",
            "were - 625\n",
            "be - 617\n",
            "my - 582\n",
            "or - 581\n",
            "from - 577\n",
            "have - 571\n",
            "out - 541\n",
            "so - 536\n",
            "up - 529\n",
            "him - 523\n",
            "we - 519\n",
            "me - 516\n",
            "when - 505\n",
            "would - 478\n",
            "which - 476\n",
            "river - 457\n",
            "an - 440\n",
            "them - 425\n",
            "no - 422\n",
            "then - 405\n",
            "said - 399\n",
            "are - 387\n",
            "if - 381\n",
            "their - 378\n",
            "now - 369\n",
            "about - 346\n",
            "time - 337\n",
            "been - 335\n",
            "down - 328\n",
            "its - 323\n",
            "could - 313\n",
            "has - 305\n",
            "will - 301\n",
            "into - 300\n",
            "what - 285\n",
            "her - 278\n",
            "two - 273\n",
            "do - 271\n",
            "other - 270\n",
            "some - 269\n",
            "man - 260\n",
            "new - 259\n",
            "any - 238\n",
            "got - 234\n",
            "these - 233\n",
            "she - 233\n",
            "who - 229\n",
            "more - 226\n",
            "water - 222\n",
            "did - 214\n",
            "before - 208\n",
            "over - 202\n",
            "way - 202\n",
            "hundred - 200\n",
            "upon - 200\n",
            "here - 199\n",
            "after - 195\n",
            "day - 193\n",
            "than - 192\n",
            "well - 191\n",
            "through - 191\n",
            "get - 190\n",
            "old - 186\n",
            "every - 186\n",
            "can - 185\n",
            "boat - 184\n",
            "went - 183\n",
            "never - 182\n",
            "good - 181\n",
            "years - 181\n",
            "see - 176\n",
            "know - 175\n",
            "\n",
            "Distinct words making up 90% of word occurrences: 3732\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch.venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}